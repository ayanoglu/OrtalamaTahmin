{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayanoglu/OrtalamaTahmin/blob/main/REDGPA_2022_NEWandOLDDATA_18COMB_OCSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "nQKeJo4fqzcT",
        "outputId": "eee68364-ca69-4d00-cccc-3dc691a850f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e7cbf95-9acb-4485-8e52-8b8fe266c478\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e7cbf95-9acb-4485-8e52-8b8fe266c478\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving EE post spring 22.csv to EE post spring 22.csv\n",
            "Saving EE pretest fall 22.csv to EE pretest fall 22.csv\n",
            "Saving EE Seniors.csv to EE Seniors.csv\n",
            "Saving EE Students Spring 2021 from PAUL.csv to EE Students Spring 2021 from PAUL.csv\n",
            "Saving Engineering Evaluation Spring 2021.csv to Engineering Evaluation Spring 2021.csv\n",
            "Saving Engineering Freshmen Fall 21 - January 31 22 from PAUL.csv to Engineering Freshmen Fall 21 - January 31 22 from PAUL.csv\n",
            "Saving Engineering Freshmen Spring 2021 from PAUL.csv to Engineering Freshmen Spring 2021 from PAUL.csv\n",
            "Saving Engineering Freshmen Spring 2021.csv to Engineering Freshmen Spring 2021.csv\n",
            "Saving Engineering Freshmen Survey.csv to Engineering Freshmen Survey.csv\n",
            "Saving Ferekides post fall21.csv to Ferekides post fall21.csv\n",
            "Saving Ferekides post spring 22.csv to Ferekides post spring 22.csv\n",
            "Saving Ferekides pre fall21.csv to Ferekides pre fall21.csv\n",
            "Saving Ferekides pre sp22.csv to Ferekides pre sp22.csv\n",
            "Saving Jeong post fall21.csv to Jeong post fall21.csv\n",
            "Saving Jeong pretest fall21.csv to Jeong pretest fall21.csv\n",
            "Saving Psychology Student Experience.csv to Psychology Student Experience.csv\n",
            "Saving Psychology Subject Pool May 2021 - Jan 31 2022 from PAUL.csv to Psychology Subject Pool May 2021 - Jan 31 2022 from PAUL.csv\n",
            "Saving Psychology Subject Pool Spring 2021 from PAUL.csv to Psychology Subject Pool Spring 2021 from PAUL.csv\n",
            "Saving Summer 21 Psychology Student Experience.csv to Summer 21 Psychology Student Experience.csv\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from numpy import array\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.set_printoptions(linewidth=160)\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import *\n",
        "from google.colab import files\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import itertools\n",
        "from itertools import combinations\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD DATASETS FROM PAUL\n",
        "\n",
        "DF_EEStudentsSpring2021fromPAUL = pd.read_csv(io.BytesIO(uploaded['EE Students Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EngFreshmenFall2021fromPAUL = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Fall 21 - January 31 22 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EngFreshmenSpring2021fromPAUL = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_PsychologyMay2021fromPAUL = pd.read_csv(io.BytesIO(uploaded['Psychology Subject Pool May 2021 - Jan 31 2022 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_PsychologySpring2021fromPAUL = pd.read_csv(io.BytesIO(uploaded['Psychology Subject Pool Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n"
      ],
      "metadata": {
        "id": "8HqUEftAF8_1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW RECENTLY DOWNLOADED DATASETS\n",
        "\n",
        "DF_EE_post_spring_22 = pd.read_csv(io.BytesIO(uploaded['EE post spring 22.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EE_pretest_fall_22 = pd.read_csv(io.BytesIO(uploaded['EE pretest fall 22.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EE_Seniors = pd.read_csv(io.BytesIO(uploaded['EE Seniors.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Engineering_Evaluation_Spring_2021 = pd.read_csv(io.BytesIO(uploaded['Engineering Evaluation Spring 2021.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Engineering_Freshmen_Spring_2021 = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Spring 2021.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Engineering_Freshmen_Survey = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Survey.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Psychology_Student_Experience = pd.read_csv(io.BytesIO(uploaded['Psychology Student Experience.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Summer_21_Psychology_Student_Experience = pd.read_csv(io.BytesIO(uploaded['Summer 21 Psychology Student Experience.csv']), header=None, skip_blank_lines=True)\n"
      ],
      "metadata": {
        "id": "a5-XcYbvHi7T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 3 suspected datasets are same\n",
        "\n",
        "print(f'Dataframes equal? .. {DF_EEStudentsSpring2021fromPAUL.equals(DF_Engineering_Evaluation_Spring_2021)}')\n",
        "print(f'Dataframes equal? .. {DF_EngFreshmenSpring2021fromPAUL.equals(DF_Engineering_Freshmen_Spring_2021)}')\n",
        "print(f'Dataframes equal? .. {DF_PsychologySpring2021fromPAUL.equals(DF_Psychology_Student_Experience)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JULHyeLoIo4A",
        "outputId": "ebef51b7-b28e-4e0e-a440-7d19084d7dd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframes equal? .. False\n",
            "Dataframes equal? .. False\n",
            "Dataframes equal? .. False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW RECENTLEY DOWNLOADED DATASETS \n",
        "# Question Title Check\n",
        "DF_EE_pretest_fall_22_TT = DF_EE_pretest_fall_22.iloc[0:1,18:80]\n",
        "DF_EE_Seniors_TT = DF_EE_Seniors.iloc[0:1,18:80]\n",
        "DF_Engineering_Evaluation_Spring_2021_TT = DF_Engineering_Evaluation_Spring_2021.iloc[0:1,18:80]\n",
        "DF_Engineering_Freshmen_Spring_2021_TT = DF_Engineering_Freshmen_Spring_2021.iloc[0:1,18:80]\n",
        "DF_Engineering_Freshmen_Survey_TT = DF_Engineering_Freshmen_Survey.iloc[0:1,18:80]\n",
        "DF_Psychology_Student_Experience_TT = DF_Psychology_Student_Experience.iloc[0:1,18:80]\n",
        "DF_Summer_21_Psychology_Student_Experience_TT = DF_Summer_21_Psychology_Student_Experience.iloc[0:1,18:80]\n",
        "\n",
        "#only one seemed to be different\n",
        "DF_EE_post_spring_22_TT = DF_EE_post_spring_22.iloc[0:1,18:78]\n",
        "DF_EE_post_spring_22_TT = pd.concat([DF_EE_post_spring_22_TT, DF_EE_post_spring_22.iloc[0:1,93:95]], axis = 1)\n",
        "\n",
        "DF_EE_post_spring_22_TT.columns = range(DF_EE_post_spring_22_TT.columns.size)\n",
        "DF_EE_pretest_fall_22_TT.columns = range(DF_EE_pretest_fall_22_TT.columns.size)\n",
        "DF_EE_Seniors_TT.columns = range(DF_EE_Seniors_TT.columns.size)\n",
        "DF_Engineering_Evaluation_Spring_2021_TT.columns = range(DF_Engineering_Evaluation_Spring_2021_TT.columns.size)\n",
        "DF_Engineering_Freshmen_Spring_2021_TT.columns = range(DF_Engineering_Freshmen_Spring_2021_TT.columns.size)\n",
        "DF_Engineering_Freshmen_Survey_TT.columns = range(DF_Engineering_Freshmen_Survey_TT.columns.size)\n",
        "DF_Psychology_Student_Experience_TT.columns = range(DF_Psychology_Student_Experience_TT.columns.size)\n",
        "DF_Summer_21_Psychology_Student_Experience_TT.columns = range(DF_Summer_21_Psychology_Student_Experience_TT.columns.size)\n",
        "\n",
        "print(f'Dataframes equal? .. {DF_EE_post_spring_22_TT.equals(DF_EE_pretest_fall_22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_post_spring_22_TT.equals(DF_EE_Seniors_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_pretest_fall_22_TT.equals(DF_EE_Seniors_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_Seniors_TT.equals(DF_Engineering_Evaluation_Spring_2021_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Evaluation_Spring_2021_TT.equals(DF_Engineering_Freshmen_Spring_2021_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Freshmen_Spring_2021_TT.equals(DF_Engineering_Freshmen_Survey_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Freshmen_Survey_TT.equals(DF_Psychology_Student_Experience_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Psychology_Student_Experience_TT.equals(DF_Summer_21_Psychology_Student_Experience_TT)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v9-X7ddREtl",
        "outputId": "bdb27aec-58e6-4d8e-8c95-72ff5b0ab12b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW RECENTLEY DOWNLOADED DATASETS \n",
        "\n",
        "DF1_EE_pretest_fall_22 = DF_EE_pretest_fall_22.iloc[3:,18:80]\n",
        "DF1_EE_Seniors = DF_EE_Seniors.iloc[3:,18:80]\n",
        "DF1_Engineering_Evaluation_Spring_2021 = DF_Engineering_Evaluation_Spring_2021.iloc[3:,18:80]\n",
        "DF1_Engineering_Freshmen_Spring_2021 = DF_Engineering_Freshmen_Spring_2021.iloc[3:,18:80]\n",
        "DF1_Engineering_Freshmen_Survey = DF_Engineering_Freshmen_Survey.iloc[3:,18:80]\n",
        "DF1_Psychology_Student_Experience = DF_Psychology_Student_Experience.iloc[3:,18:80]\n",
        "DF1_Summer_21_Psychology_Student_Experience = DF_Summer_21_Psychology_Student_Experience.iloc[3:,18:80]\n",
        "\n",
        "#only one seemed to be different\n",
        "DF1_EE_post_spring_22 = DF_EE_post_spring_22.iloc[3:,18:78]\n",
        "DF1_EE_post_spring_22 = pd.concat([DF1_EE_post_spring_22, DF_EE_post_spring_22.iloc[3:,93:95]], axis = 1)\n",
        "\n",
        "DF1_EE_pretest_fall_22.columns = range(DF1_EE_pretest_fall_22.columns.size)\n",
        "DF1_EE_Seniors.columns = range(DF1_EE_Seniors.columns.size)\n",
        "DF1_Engineering_Evaluation_Spring_2021.columns = range(DF1_Engineering_Evaluation_Spring_2021.columns.size)\n",
        "DF1_Engineering_Freshmen_Spring_2021.columns = range(DF1_Engineering_Freshmen_Spring_2021.columns.size)\n",
        "DF1_Engineering_Freshmen_Survey.columns = range(DF1_Engineering_Freshmen_Survey.columns.size)\n",
        "DF1_Psychology_Student_Experience.columns = range(DF1_Psychology_Student_Experience.columns.size)\n",
        "DF1_Summer_21_Psychology_Student_Experience.columns = range(DF1_Summer_21_Psychology_Student_Experience.columns.size)\n",
        "DF1_EE_post_spring_22.columns = range(DF1_EE_post_spring_22.columns.size)"
      ],
      "metadata": {
        "id": "ekmnu3d0Dq3P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(DF_Engineering_Freshmen_Survey_TT.iloc[:,:] == DF_Psychology_Student_Experience_TT.iloc[:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "IRSPYDx9Vchg",
        "outputId": "bcab0e0a-701b-464a-8eea-6e6f3bb4846d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0     1     2     3     4     5     6     7     8     9   ...    52  \\\n",
              "0  True  True  True  True  True  True  True  True  True  True  ...  True   \n",
              "\n",
              "     53    54    55    56    57    58    59    60    61  \n",
              "0  True  True  True  True  True  True  True  True  True  \n",
              "\n",
              "[1 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-118f7d8a-3775-4280-a704-33aaa665b24d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-118f7d8a-3775-4280-a704-33aaa665b24d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-118f7d8a-3775-4280-a704-33aaa665b24d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-118f7d8a-3775-4280-a704-33aaa665b24d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FREKIDES AND JEONG PAIR DATASETS\n",
        "\n",
        "DF_Frekides_Post_FALL21 = pd.read_csv(io.BytesIO(uploaded['Ferekides post fall21.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Frekides_Post_SPRING22 = pd.read_csv(io.BytesIO(uploaded['Ferekides post spring 22.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Frekides_Pre_FALL21 = pd.read_csv(io.BytesIO(uploaded['Ferekides pre fall21.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Frekides_Pre_SPRING22 = pd.read_csv(io.BytesIO(uploaded['Ferekides pre sp22.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Jeong_Pre_FALL21 = pd.read_csv(io.BytesIO(uploaded['Jeong pretest fall21.csv']), header=None, skip_blank_lines=True)\n",
        "DF_Jeong_Post_FALL21 = pd.read_csv(io.BytesIO(uploaded['Jeong post fall21.csv']), header=None, skip_blank_lines=True)\n",
        "\n",
        "# Question Title Check\n",
        "DF1_Fre_PRE_FALL21_TT = DF_Frekides_Pre_FALL21.iloc[0:1,18:80]\n",
        "DF1_Fre_PRE_SPRING22_TT = DF_Frekides_Pre_SPRING22.iloc[0:1,18:80]\n",
        "DF1_Jeong_Pre_FALL21_TT = DF_Jeong_Pre_FALL21.iloc[0:1,18:80]\n",
        "\n",
        "DF1_Fre_POST_FALL21_TT = DF_Frekides_Post_FALL21.iloc[0:1,11:71]\n",
        "DF1_Fre_POST_FALL21_TT = pd.concat([DF1_Fre_POST_FALL21_TT,DF_Frekides_Post_FALL21.iloc[0:1,86:88]], axis = 1)\n",
        "DF1_Fre_POST_SPRING22_TT = DF_Frekides_Post_SPRING22.iloc[0:1,18:78]\n",
        "DF1_Fre_POST_SPRING22_TT = pd.concat([DF1_Fre_POST_SPRING22_TT,DF_Frekides_Post_SPRING22.iloc[0:1,93:95]], axis = 1)\n",
        "DF1_Jeong_Post_FALL21_TT = DF_Jeong_Post_FALL21.iloc[0:1,18:78]\n",
        "DF1_Jeong_Post_FALL21_TT = pd.concat([DF1_Jeong_Post_FALL21_TT,DF_Jeong_Post_FALL21.iloc[0:1,93:95]], axis = 1)\n",
        "\n",
        "DF1_Fre_PRE_FALL21_TT.columns = range(DF1_Fre_PRE_FALL21_TT.columns.size)\n",
        "DF1_Fre_PRE_SPRING22_TT.columns = range(DF1_Fre_PRE_SPRING22_TT.columns.size)\n",
        "DF1_Jeong_Pre_FALL21_TT.columns = range(DF1_Jeong_Pre_FALL21_TT.columns.size)\n",
        "DF1_Fre_POST_FALL21_TT.columns = range(DF1_Fre_POST_FALL21_TT.columns.size)\n",
        "DF1_Fre_POST_SPRING22_TT.columns = range(DF1_Fre_POST_SPRING22_TT.columns.size)\n",
        "DF1_Jeong_Post_FALL21_TT.columns = range(DF1_Jeong_Post_FALL21_TT.columns.size)\n"
      ],
      "metadata": {
        "id": "28wq4fqOIEZo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FREKIDES AND JEONG PAIR DATASETS\n",
        "\n",
        "# Pairs have same questions?\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_SPRING22_TT.equals(DF1_Fre_PRE_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Jeong_Post_FALL21_TT.equals(DF1_Jeong_Pre_FALL21_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Fre_PRE_FALL21_TT)}')\n",
        "\n",
        "# \"PRE\" have same questions?\n",
        "print(f'Dataframes equal? .. {DF1_Fre_PRE_FALL21_TT.equals(DF1_Fre_PRE_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_PRE_FALL21_TT.equals(DF1_Jeong_Pre_FALL21_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_PRE_SPRING22_TT.equals(DF1_Jeong_Pre_FALL21_TT)}')\n",
        "\n",
        "# \"POST\" have same questions?\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Fre_POST_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Jeong_Post_FALL21_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_SPRING22_TT.equals(DF1_Jeong_Post_FALL21_TT)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMKP8y4naOsx",
        "outputId": "be72ac9f-4956-4baa-9da3-a45c575c7b33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF1_Fre_PRE_FALL21 = DF_Frekides_Pre_FALL21.iloc[3:,18:80]\n",
        "DF1_Fre_PRE_SPRING22 = DF_Frekides_Pre_SPRING22.iloc[3:,18:80]\n",
        "DF1_Jeong_Pre_FALL21 = DF_Jeong_Pre_FALL21.iloc[3:,18:80]\n",
        "\n",
        "DF1_Fre_POST_FALL21 = DF_Frekides_Post_FALL21.iloc[3:,11:71]\n",
        "DF1_Fre_POST_FALL21 = pd.concat([DF1_Fre_POST_FALL21,DF_Frekides_Post_FALL21.iloc[3:,86:88]], axis = 1)\n",
        "DF1_Fre_POST_SPRING22 = DF_Frekides_Post_SPRING22.iloc[3:,18:78]\n",
        "DF1_Fre_POST_SPRING22 = pd.concat([DF1_Fre_POST_SPRING22,DF_Frekides_Post_SPRING22.iloc[3:,93:95]], axis = 1)\n",
        "DF1_Jeong_Post_FALL21 = DF_Jeong_Post_FALL21.iloc[3:,18:78]\n",
        "DF1_Jeong_Post_FALL21 = pd.concat([DF1_Jeong_Post_FALL21,DF_Jeong_Post_FALL21.iloc[3:,93:95]], axis = 1)\n",
        "\n",
        "DF1_Fre_PRE_FALL21.columns = range(DF1_Fre_PRE_FALL21.columns.size)\n",
        "DF1_Fre_PRE_SPRING22.columns = range(DF1_Fre_PRE_SPRING22.columns.size)\n",
        "DF1_Jeong_Pre_FALL21.columns = range(DF1_Jeong_Pre_FALL21.columns.size)\n",
        "DF1_Fre_POST_FALL21.columns = range(DF1_Fre_POST_FALL21.columns.size)\n",
        "DF1_Fre_POST_SPRING22.columns = range(DF1_Fre_POST_SPRING22.columns.size)\n",
        "DF1_Jeong_Post_FALL21.columns = range(DF1_Jeong_Post_FALL21.columns.size)\n",
        "\n",
        "DF1FreJeoPre = pd.concat([DF1_Fre_PRE_FALL21, DF1_Fre_PRE_SPRING22, DF1_Jeong_Pre_FALL21], axis = 0)\n",
        "DF1FreJeoPost = pd.concat([DF1_Fre_POST_FALL21, DF1_Fre_POST_SPRING22, DF1_Jeong_Post_FALL21], axis = 0)\n",
        "\n",
        "print(f'Dataframe DF1FreJeoPre Shape before cleaning the data is .. {DF1FreJeoPre.shape}')\n",
        "print(f'Dataframe DF1FreJeoPost Shape before cleaning the data is .. {DF1FreJeoPost.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUDZiyTr1cgf",
        "outputId": "5432f3cd-05ab-4572-b90d-53b7f89cced2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe DF1FreJeoPre Shape before cleaning the data is .. (541, 62)\n",
            "Dataframe DF1FreJeoPost Shape before cleaning the data is .. (484, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD DATASETS FROM PAUL\n",
        "\n",
        "DF_EEStudentsSpring2021 = pd.read_csv(io.BytesIO(uploaded['EE Students Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EngFreshmenFall2021 = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Fall 21 - January 31 22 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_EngFreshmenSpring2021 = pd.read_csv(io.BytesIO(uploaded['Engineering Freshmen Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_PsychologyMay2021 = pd.read_csv(io.BytesIO(uploaded['Psychology Subject Pool May 2021 - Jan 31 2022 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "DF_PsychologySpring2021 = pd.read_csv(io.BytesIO(uploaded['Psychology Subject Pool Spring 2021 from PAUL.csv']), header=None, skip_blank_lines=True)\n",
        "\n",
        "DF1EE = DF_EEStudentsSpring2021.iloc[3:,18:80]\n",
        "DF1ENGF = DF_EngFreshmenFall2021.iloc[3:,18:80]\n",
        "DF1ENGS = DF_EngFreshmenSpring2021.iloc[3:,18:80]\n",
        "DF1PM = DF_PsychologyMay2021.iloc[3:,18:80]\n",
        "DF1PS = DF_PsychologySpring2021.iloc[3:,18:80]\n",
        "\n",
        "DF1EEtt = DF_EEStudentsSpring2021.iloc[0:1,18:80]\n",
        "DF1ENGFtt = DF_EngFreshmenFall2021.iloc[0:1,18:80]\n",
        "DF1ENGStt = DF_EngFreshmenSpring2021.iloc[0:1,18:80]\n",
        "DF1PMtt = DF_PsychologyMay2021.iloc[0:1,18:80]\n",
        "DF1PStt = DF_PsychologySpring2021.iloc[0:1,18:80]\n",
        "\n",
        "DF1EEtt.columns = range(DF1EEtt.columns.size)\n",
        "DF1ENGFtt.columns = range(DF1ENGFtt.columns.size)\n",
        "DF1ENGStt.columns = range(DF1ENGStt.columns.size)\n",
        "DF1PMtt.columns = range(DF1PMtt.columns.size)\n",
        "DF1PStt.columns = range(DF1PStt.columns.size)\n",
        "\n",
        "# Check for questions in Dtaframes. Same? Same order?\n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF1ENGFtt)}')\n",
        "print(f'Dataframes equal? .. {DF1ENGFtt.equals(DF1ENGStt)}')\n",
        "print(f'Dataframes equal? .. {DF1ENGStt.equals(DF1PMtt)}')\n",
        "print(f'Dataframes equal? .. {DF1PMtt.equals(DF1PStt)}')\n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF1_Fre_POST_SPRING22_TT)}')"
      ],
      "metadata": {
        "id": "tE8lLg_cyvjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da0a870-5b29-4bc1-c132-c24dcd4d3d55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some of the datasets, 3 is actually 2, and 7 is actually 3, for the questions 51-54.\n",
        "# ENG FALL DATASET HAS THE PROBLEM.\n",
        "# do i = 51 to 54;\t1) if x(i) = 3 then x(i) = 2; \t2) if x(i) = 7 then x(i) = 3; end; \n",
        "\n",
        "DF1ENGF.iloc[:,50] = np.where(DF1ENGF.iloc[:,50]== 3, 2, DF1ENGF.iloc[:,50])\n",
        "DF1ENGF.iloc[:,51] = np.where(DF1ENGF.iloc[:,51]== 3, 2, DF1ENGF.iloc[:,51])\n",
        "DF1ENGF.iloc[:,52] = np.where(DF1ENGF.iloc[:,52]== 3, 2, DF1ENGF.iloc[:,52])\n",
        "DF1ENGF.iloc[:,53] = np.where(DF1ENGF.iloc[:,53]== 3, 2, DF1ENGF.iloc[:,53])\n",
        "\n",
        "DF1ENGF.iloc[:,50] = np.where(DF1ENGF.iloc[:,50]== 7, 3, DF1ENGF.iloc[:,50])\n",
        "DF1ENGF.iloc[:,51] = np.where(DF1ENGF.iloc[:,51]== 7, 3, DF1ENGF.iloc[:,51])\n",
        "DF1ENGF.iloc[:,52] = np.where(DF1ENGF.iloc[:,52]== 7, 3, DF1ENGF.iloc[:,52])\n",
        "DF1ENGF.iloc[:,53] = np.where(DF1ENGF.iloc[:,53]== 7, 3, DF1ENGF.iloc[:,53])\n",
        "\n",
        "\n",
        "# ENG SPRING DATASET HAS THE PROBLEM.\n",
        "# do i = 51 to 54;\t1) if x(i) = 3 then x(i) = 2; \t2) if x(i) = 7 then x(i) = 3; end; \n",
        "\n",
        "DF1ENGS.iloc[:,50] = np.where(DF1ENGS.iloc[:,50]== 3, 2, DF1ENGS.iloc[:,50])\n",
        "DF1ENGS.iloc[:,51] = np.where(DF1ENGS.iloc[:,51]== 3, 2, DF1ENGS.iloc[:,51])\n",
        "DF1ENGS.iloc[:,52] = np.where(DF1ENGS.iloc[:,52]== 3, 2, DF1ENGS.iloc[:,52])\n",
        "DF1ENGS.iloc[:,53] = np.where(DF1ENGS.iloc[:,53]== 3, 2, DF1ENGS.iloc[:,53])\n",
        "\n",
        "DF1ENGS.iloc[:,50] = np.where(DF1ENGS.iloc[:,50]== 7, 3, DF1ENGS.iloc[:,50])\n",
        "DF1ENGS.iloc[:,51] = np.where(DF1ENGS.iloc[:,51]== 7, 3, DF1ENGS.iloc[:,51])\n",
        "DF1ENGS.iloc[:,52] = np.where(DF1ENGS.iloc[:,52]== 7, 3, DF1ENGS.iloc[:,52])\n",
        "DF1ENGS.iloc[:,53] = np.where(DF1ENGS.iloc[:,53]== 7, 3, DF1ENGS.iloc[:,53])\n",
        "\n",
        "DF1EE.columns = range(DF1EE.columns.size)\n",
        "DF1ENGF.columns = range(DF1ENGF.columns.size)\n",
        "DF1ENGS.columns = range(DF1ENGS.columns.size)\n",
        "DF1PM.columns = range(DF1PM.columns.size)\n",
        "DF1PS.columns = range(DF1PS.columns.size)"
      ],
      "metadata": {
        "id": "Zx5Zoate5mJ7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for questions in Dataframes. Same? Same order?\n",
        "# Older from Paul\n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF1ENGFtt)}')\n",
        "print(f'Dataframes equal? .. {DF1ENGFtt.equals(DF1ENGStt)}')\n",
        "print(f'Dataframes equal? .. {DF1ENGStt.equals(DF1PMtt)}')\n",
        "print(f'Dataframes equal? .. {DF1PMtt.equals(DF1PStt)}')\n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF1_Fre_POST_SPRING22_TT)}')\n",
        "\n",
        "# Newer Downloaded\n",
        "print(f'Dataframes equal? .. {DF_EE_post_spring_22_TT.equals(DF_EE_pretest_fall_22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_post_spring_22_TT.equals(DF_EE_Seniors_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_pretest_fall_22_TT.equals(DF_EE_Seniors_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_Seniors_TT.equals(DF_Engineering_Evaluation_Spring_2021_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Evaluation_Spring_2021_TT.equals(DF_Engineering_Freshmen_Spring_2021_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Freshmen_Spring_2021_TT.equals(DF_Engineering_Freshmen_Survey_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Engineering_Freshmen_Survey_TT.equals(DF_Psychology_Student_Experience_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_Psychology_Student_Experience_TT.equals(DF_Summer_21_Psychology_Student_Experience_TT)}')\n",
        "\n",
        "# Pairs have same questions?\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_SPRING22_TT.equals(DF1_Fre_PRE_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Jeong_Post_FALL21_TT.equals(DF1_Jeong_Pre_FALL21_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Fre_PRE_FALL21_TT)}')\n",
        "\n",
        "# \"POST\" have same questions?\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Fre_POST_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_FALL21_TT.equals(DF1_Jeong_Post_FALL21_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1_Fre_POST_SPRING22_TT.equals(DF1_Jeong_Post_FALL21_TT)}')\n",
        "\n",
        "# Compare all 3 types of Datasets to each other \n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF_EE_post_spring_22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF1EEtt.equals(DF1_Fre_POST_SPRING22_TT)}')\n",
        "print(f'Dataframes equal? .. {DF_EE_post_spring_22_TT.equals(DF1_Fre_POST_SPRING22_TT)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifb-zyde9FlZ",
        "outputId": "75e4fc25-417c-4a8b-e4cd-417820478b77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n",
            "Dataframes equal? .. True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF1Old = pd.concat([DF1EE, DF1ENGF, DF1ENGS, DF1PM, DF1PS], axis = 0)\n",
        "DF1New = pd.concat([DF1_EE_pretest_fall_22, DF1_EE_Seniors, DF1_Engineering_Evaluation_Spring_2021, DF1_Engineering_Freshmen_Spring_2021, DF1_Engineering_Freshmen_Survey, DF1_Psychology_Student_Experience, DF1_Summer_21_Psychology_Student_Experience, DF1_EE_post_spring_22], axis = 0)\n",
        "print(f'Dataframe DF1Old Shape before cleaning the data is .. {DF1Old.shape}')\n",
        "print(f'Dataframe DF1New Shape before cleaning the data is .. {DF1New.shape}')\n",
        "print(f'Dataframe DF1FreJeoPre Shape before cleaning the data is .. {DF1FreJeoPre.shape}')\n",
        "print(f'Dataframe DF1FreJeoPost Shape before cleaning the data is .. {DF1FreJeoPost.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_29grNB5-w1",
        "outputId": "6165f6da-3e65-4ef6-c1f4-cbbf5992d4b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe DF1Old Shape before cleaning the data is .. (3855, 62)\n",
            "Dataframe DF1New Shape before cleaning the data is .. (6217, 62)\n",
            "Dataframe DF1FreJeoPre Shape before cleaning the data is .. (541, 62)\n",
            "Dataframe DF1FreJeoPost Shape before cleaning the data is .. (484, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD DATA Remove columns with nans or non numerical chars\n",
        "\n",
        "DF1Old.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF2Old = DF1Old.dropna(axis=0) # Drop rows with NaNs\n",
        "DF2Old.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF3Old = DF2Old.apply(pd.to_numeric, errors='coerce') # change object type to numeric, errors will be NaNs\n",
        "DF3Old.isnull().any(axis=1).sum()\n",
        "DF4Old = DF3Old.dropna(axis=0) # Drop rows with NaNs\n",
        "DF4Old.isnull().any(axis=1).sum()\n",
        "DF4Old.columns = range(DF4Old.columns.size) # re index column numbers\n",
        "(DF4Old.iloc[:,-1] == 0).sum() #number of rows on the last column that are equal to 0\n",
        "DF4Old.iloc[:,-1].min() #min of last column\n",
        "DF4Old.iloc[:,-1].idxmin() #idx of the min of last column\n",
        "DF4Old = DF4Old[(DF4Old.iloc[:,-1] > 0)] #drop the GPA values that are smaller than 0\n",
        "DF4Old = DF4Old.reset_index() # reset row index with a new index column\n",
        "DF4Old = DF4Old.drop(labels='index', axis=1) #drop the old index column\n",
        "print(f'Cleaned Dataframe DF4Old Shape is .. {DF4Old.shape}')"
      ],
      "metadata": {
        "id": "pgMUEBZD930V",
        "outputId": "26218b72-6c6d-45fe-c26a-bc33849ded74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Dataframe DF4Old Shape is .. (2592, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New DATA Remove columns with nans or non numerical chars\n",
        "\n",
        "DF1New.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF2New = DF1New.dropna(axis=0) # Drop rows with NaNs\n",
        "DF2New.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF3New = DF2New.apply(pd.to_numeric, errors='coerce') # change object type to numeric, errors will be NaNs\n",
        "DF3New.isnull().any(axis=1).sum()\n",
        "DF4New = DF3New.dropna(axis=0) # Drop rows with NaNs\n",
        "DF4New.isnull().any(axis=1).sum()\n",
        "DF4New.columns = range(DF4New.columns.size) # re index column numbers\n",
        "(DF4New.iloc[:,-1] == 0).sum() #number of rows on the last column that are equal to 0\n",
        "DF4New.iloc[:,-1].min() #min of last column\n",
        "DF4New.iloc[:,-1].idxmin() #idx of the min of last column\n",
        "DF4New = DF4New[(DF4New.iloc[:,-1] > 0)] #drop the GPA values that are smaller than 0\n",
        "DF4New = DF4New.reset_index() # reset row index with a new index column\n",
        "DF4New = DF4New.drop(labels='index', axis=1) #drop the old index column\n",
        "print(f'Cleaned Dataframe DF4New Shape is .. {DF4New.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2moPyGav9-64",
        "outputId": "d85ad865-ccb6-4261-d5fb-7de93f84d372"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Dataframe DF4New Shape is .. (4157, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FREKIDES Remove columns with nans or non numerical chars\n",
        "\n",
        "DF1FreJeoPre.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF2FreJeoPre = DF1FreJeoPre.dropna(axis=0) # Drop rows with NaNs\n",
        "DF2FreJeoPre.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF3FreJeoPre = DF2FreJeoPre.apply(pd.to_numeric, errors='coerce') # change object type to numeric, errors will be NaNs\n",
        "DF3FreJeoPre.isnull().any(axis=1).sum()\n",
        "DF4FreJeoPre = DF3FreJeoPre.dropna(axis=0) # Drop rows with NaNs\n",
        "DF4FreJeoPre.isnull().any(axis=1).sum()\n",
        "DF4FreJeoPre.columns = range(DF4FreJeoPre.columns.size) # re index column numbers\n",
        "(DF4FreJeoPre.iloc[:,-1] == 0).sum() #number of rows on the last column that are equal to 0\n",
        "DF4FreJeoPre.iloc[:,-1].min() #min of last column\n",
        "DF4FreJeoPre.iloc[:,-1].idxmin() #idx of the min of last column\n",
        "DF4FreJeoPre = DF4FreJeoPre[(DF4FreJeoPre.iloc[:,-1] > 0)] #drop the GPA values that are smaller than 0\n",
        "DF4FreJeoPre = DF4FreJeoPre.reset_index() # reset row index with a new index column\n",
        "DF4FreJeoPre = DF4FreJeoPre.drop(labels='index', axis=1) #drop the old index column\n",
        "print(f'Cleaned Dataframe DF4FreJeoPre Shape is .. {DF4FreJeoPre.shape}')\n",
        "\n",
        "DF1FreJeoPost.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF2FreJeoPost = DF1FreJeoPost.dropna(axis=0) # Drop rows with NaNs\n",
        "DF2FreJeoPost.isnull().any(axis=1).sum() #number of columns with NaNs\n",
        "DF3FreJeoPost = DF2FreJeoPost.apply(pd.to_numeric, errors='coerce') # change object type to numeric, errors will be NaNs\n",
        "DF3FreJeoPost.isnull().any(axis=1).sum()\n",
        "DF4FreJeoPost = DF3FreJeoPost.dropna(axis=0) # Drop rows with NaNs\n",
        "DF4FreJeoPost.isnull().any(axis=1).sum()\n",
        "DF4FreJeoPost.columns = range(DF4FreJeoPost.columns.size) # re index column numbers\n",
        "(DF4FreJeoPost.iloc[:,-1] == 0).sum() #number of rows on the last column that are equal to 0\n",
        "DF4FreJeoPost.iloc[:,-1].min() #min of last column\n",
        "DF4FreJeoPost.iloc[:,-1].idxmin() #idx of the min of last column\n",
        "DF4FreJeoPost = DF4FreJeoPost[(DF4FreJeoPost.iloc[:,-1] > 0)] #drop the GPA values that are smaller than 0\n",
        "DF4FreJeoPost = DF4FreJeoPost.reset_index() # reset row index with a new index column\n",
        "DF4FreJeoPost = DF4FreJeoPost.drop(labels='index', axis=1) #drop the old index column\n",
        "print(f'Cleaned Dataframe DF4FreJeoPost Shape is .. {DF4FreJeoPost.shape}')"
      ],
      "metadata": {
        "outputId": "61f6ff66-4c97-4001-8273-fbdd7ae0d2ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcFxacp6PZMW"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Dataframe DF4FreJeoPre Shape is .. (484, 62)\n",
            "Cleaned Dataframe DF4FreJeoPost Shape is .. (431, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "START MODYFYING SOME COLUMNS AND ADDING THE ADDITIONAL FUNCTIONS"
      ],
      "metadata": {
        "id": "gXda_0SndHNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#If gpa > 4 then gpa = 4;\n",
        "DF4FreJeoPost.iloc[:,-1] = np.where(DF4FreJeoPost.iloc[:,-1] > 4, 4, DF4FreJeoPost.iloc[:,-1]) #GPA = DF4FreJeoPost.iloc[:,-1]\n",
        "\n",
        "#do i = 1 to 7; efficacy = efficacy + x(i); end;\n",
        "DF4FreJeoPost['efficacy']= DF4FreJeoPost.iloc[:, 0:7].sum(axis=1)\n",
        "\n",
        "#do i = 8 to 29; habits = habits + x(i); end;\n",
        "DF4FreJeoPost['habbits']= DF4FreJeoPost.iloc[:, 7:29].sum(axis=1)\n",
        "\n",
        "#do i = 30 to 37; preocc = preocc + x(i); end;\n",
        "DF4FreJeoPost['preocc']= DF4FreJeoPost.iloc[:, 29:37].sum(axis=1)\n",
        "\n",
        "#do i = 38 to 45; hesitat = hesitat + x(i); end;\n",
        "DF4FreJeoPost['hesitat']= DF4FreJeoPost.iloc[:, 37:45].sum(axis=1)\n",
        "\n",
        "#do i = 46 to 50; volatil = volatil + x(i);\n",
        "DF4FreJeoPost['volatil']= DF4FreJeoPost.iloc[:, 45:50].sum(axis=1)\n",
        "\n",
        "#do i = 51 to 54; engagecurric = engagecurric + x(i); end;\n",
        "DF4FreJeoPost['engagecurric']= DF4FreJeoPost.iloc[:, 50:54].sum(axis=1)\n",
        "\n",
        "#do i = 55 to 59; engageextra = engageextra+x(i);\n",
        "DF4FreJeoPost['engageextra']= DF4FreJeoPost.iloc[:, 54:59].sum(axis=1)\n",
        "\n",
        "DF4FreJeoPost.head()\n",
        "\n",
        "#########################################################################################################\n",
        "#If gpa > 4 then gpa = 4;\n",
        "DF4FreJeoPre.iloc[:,-1] = np.where(DF4FreJeoPre.iloc[:,-1] > 4, 4, DF4FreJeoPre.iloc[:,-1]) #GPA = DF4FreJeoPre.iloc[:,-1]\n",
        "\n",
        "#do i = 1 to 7; efficacy = efficacy + x(i); end;\n",
        "DF4FreJeoPre['efficacy']= DF4FreJeoPre.iloc[:, 0:7].sum(axis=1)\n",
        "\n",
        "#do i = 8 to 29; habits = habits + x(i); end;\n",
        "DF4FreJeoPre['habbits']= DF4FreJeoPre.iloc[:, 7:29].sum(axis=1)\n",
        "\n",
        "#do i = 30 to 37; preocc = preocc + x(i); end;\n",
        "DF4FreJeoPre['preocc']= DF4FreJeoPre.iloc[:, 29:37].sum(axis=1)\n",
        "\n",
        "#do i = 38 to 45; hesitat = hesitat + x(i); end;\n",
        "DF4FreJeoPre['hesitat']= DF4FreJeoPre.iloc[:, 37:45].sum(axis=1)\n",
        "\n",
        "#do i = 46 to 50; volatil = volatil + x(i);\n",
        "DF4FreJeoPre['volatil']= DF4FreJeoPre.iloc[:, 45:50].sum(axis=1)\n",
        "\n",
        "#do i = 51 to 54; engagecurric = engagecurric + x(i); end;\n",
        "DF4FreJeoPre['engagecurric']= DF4FreJeoPre.iloc[:, 50:54].sum(axis=1)\n",
        "\n",
        "#do i = 55 to 59; engageextra = engageextra+x(i);\n",
        "DF4FreJeoPre['engageextra']= DF4FreJeoPre.iloc[:, 54:59].sum(axis=1)\n",
        "\n",
        "DF4FreJeoPre.head()"
      ],
      "metadata": {
        "id": "Zft77wK2hglr",
        "outputId": "366a94ae-b3c7-431a-e9a9-703b2ca69377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  ...  59  60    61  efficacy  habbits  preocc  \\\n",
              "0  6  6  6  6  6  6  7  5  3  3  ...   4   1  3.30        43      109      12   \n",
              "1  7  7  6  6  6  7  7  7  5  6  ...   4   4  3.21        46      110      12   \n",
              "2  7  7  7  7  7  7  7  7  6  6  ...   4   4  2.70        49      134      14   \n",
              "3  7  7  7  7  7  7  7  5  4  4  ...   2   4  3.01        49      104      12   \n",
              "4  4  4  4  4  4  4  4  4  4  4  ...   3   3  2.80        28       88      13   \n",
              "\n",
              "   hesitat  volatil  engagecurric  engageextra  \n",
              "0       13        9            12            9  \n",
              "1       13        9            19           10  \n",
              "2       14       10            13            9  \n",
              "3       15        8            20            6  \n",
              "4       12        8             8            6  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-709656ab-0d39-404e-9c10-c764cde29d75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>efficacy</th>\n",
              "      <th>habbits</th>\n",
              "      <th>preocc</th>\n",
              "      <th>hesitat</th>\n",
              "      <th>volatil</th>\n",
              "      <th>engagecurric</th>\n",
              "      <th>engageextra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3.30</td>\n",
              "      <td>43</td>\n",
              "      <td>109</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3.21</td>\n",
              "      <td>46</td>\n",
              "      <td>110</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2.70</td>\n",
              "      <td>49</td>\n",
              "      <td>134</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3.01</td>\n",
              "      <td>49</td>\n",
              "      <td>104</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2.80</td>\n",
              "      <td>28</td>\n",
              "      <td>88</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-709656ab-0d39-404e-9c10-c764cde29d75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-709656ab-0d39-404e-9c10-c764cde29d75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-709656ab-0d39-404e-9c10-c764cde29d75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If gpa > 4 then gpa = 4;\n",
        "DF4New.iloc[:,-1] = np.where(DF4New.iloc[:,-1] > 4, 4, DF4New.iloc[:,-1]) #GPA = DF4New.iloc[:,-1]\n",
        "\n",
        "#do i = 1 to 7; efficacy = efficacy + x(i); end;\n",
        "DF4New['efficacy']= DF4New.iloc[:, 0:7].sum(axis=1)\n",
        "\n",
        "#do i = 8 to 29; habits = habits + x(i); end;\n",
        "DF4New['habbits']= DF4New.iloc[:, 7:29].sum(axis=1)\n",
        "\n",
        "#do i = 30 to 37; preocc = preocc + x(i); end;\n",
        "DF4New['preocc']= DF4New.iloc[:, 29:37].sum(axis=1)\n",
        "\n",
        "#do i = 38 to 45; hesitat = hesitat + x(i); end;\n",
        "DF4New['hesitat']= DF4New.iloc[:, 37:45].sum(axis=1)\n",
        "\n",
        "#do i = 46 to 50; volatil = volatil + x(i);\n",
        "DF4New['volatil']= DF4New.iloc[:, 45:50].sum(axis=1)\n",
        "\n",
        "#do i = 51 to 54; engagecurric = engagecurric + x(i); end;\n",
        "DF4New['engagecurric']= DF4New.iloc[:, 50:54].sum(axis=1)\n",
        "\n",
        "#do i = 55 to 59; engageextra = engageextra+x(i);\n",
        "DF4New['engageextra']= DF4New.iloc[:, 54:59].sum(axis=1)\n",
        "\n",
        "DF4New.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OHfzCxwV-ntL",
        "outputId": "1fec514f-8b04-4b79-81c3-ea88b07c8900"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  ...  59  60    61  efficacy  habbits  preocc  \\\n",
              "0  7  6  6  6  6  6  6  6  2  6  ...   5   2  3.60        43      108      11   \n",
              "1  7  7  7  7  7  7  7  7  7  7  ...   5   5  3.82        49      154      11   \n",
              "2  6  7  5  6  6  5  7  2  5  4  ...   4   1  3.54        42       97      13   \n",
              "3  7  7  7  7  7  7  7  5  6  5  ...   4   3  3.79        49      121      10   \n",
              "4  7  7  7  7  7  7  7  6  2  3  ...   5   5  2.88        49       91      13   \n",
              "\n",
              "   hesitat  volatil  engagecurric  engageextra  \n",
              "0       13        8            16           13  \n",
              "1       13        5            28           15  \n",
              "2       11        8            18            6  \n",
              "3        8        5            17           17  \n",
              "4       15        8            15            5  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bab85eb1-958c-4cdd-9b0b-67bac0d3c97a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>efficacy</th>\n",
              "      <th>habbits</th>\n",
              "      <th>preocc</th>\n",
              "      <th>hesitat</th>\n",
              "      <th>volatil</th>\n",
              "      <th>engagecurric</th>\n",
              "      <th>engageextra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3.60</td>\n",
              "      <td>43</td>\n",
              "      <td>108</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3.82</td>\n",
              "      <td>49</td>\n",
              "      <td>154</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3.54</td>\n",
              "      <td>42</td>\n",
              "      <td>97</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3.79</td>\n",
              "      <td>49</td>\n",
              "      <td>121</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2.88</td>\n",
              "      <td>49</td>\n",
              "      <td>91</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bab85eb1-958c-4cdd-9b0b-67bac0d3c97a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bab85eb1-958c-4cdd-9b0b-67bac0d3c97a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bab85eb1-958c-4cdd-9b0b-67bac0d3c97a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If gpa > 4 then gpa = 4;\n",
        "DF4Old.iloc[:,-1] = np.where(DF4Old.iloc[:,-1] > 4, 4, DF4Old.iloc[:,-1]) #GPA = DF4Old.iloc[:,-1]\n",
        "\n",
        "#### PAUL SAID THESE ISSUES WERE FIXED IN QUALTRICS FOR THE NEW DATA ################################\n",
        "\n",
        "#If x(33) = 4 then x(33) = 2; \n",
        "DF4Old.iloc[:,32] = np.where(DF4Old.iloc[:,32]== 4, 2, DF4Old.iloc[:,32])\n",
        "\n",
        "# do i = 9, 11, 18, 22, 28, 29; x(i) = 8-x(i);\n",
        "# do i = 31, 33, 37, 41, 43, 45, 47, 50; *action-state; x(i) = 3 - x(i);\n",
        "DF4Old.iloc[:,8] = 8 - DF4Old.iloc[:,8]\n",
        "DF4Old.iloc[:,10] = 8 - DF4Old.iloc[:,10]\n",
        "DF4Old.iloc[:,17] = 8 - DF4Old.iloc[:,17]\n",
        "DF4Old.iloc[:,21] = 8 - DF4Old.iloc[:,21]\n",
        "DF4Old.iloc[:,27] = 8 - DF4Old.iloc[:,27]\n",
        "DF4Old.iloc[:,28] = 8 - DF4Old.iloc[:,28]\n",
        "\n",
        "DF4Old.iloc[:,30] = 3 - DF4Old.iloc[:,30]\n",
        "DF4Old.iloc[:,32] = 3 - DF4Old.iloc[:,32]\n",
        "DF4Old.iloc[:,36] = 3 - DF4Old.iloc[:,36]\n",
        "DF4Old.iloc[:,40] = 3 - DF4Old.iloc[:,40]\n",
        "DF4Old.iloc[:,42] = 3 - DF4Old.iloc[:,42]\n",
        "DF4Old.iloc[:,44] = 3 - DF4Old.iloc[:,44]\n",
        "DF4Old.iloc[:,46] = 3 - DF4Old.iloc[:,46]\n",
        "DF4Old.iloc[:,49] = 3 - DF4Old.iloc[:,49]\n",
        "\n",
        "#########################################################################################################\n",
        "\n",
        "#do i = 1 to 7; efficacy = efficacy + x(i); end;\n",
        "DF4Old['efficacy']= DF4Old.iloc[:, 0:7].sum(axis=1)\n",
        "\n",
        "#do i = 8 to 29; habits = habits + x(i); end;\n",
        "DF4Old['habbits']= DF4Old.iloc[:, 7:29].sum(axis=1)\n",
        "\n",
        "#do i = 30 to 37; preocc = preocc + x(i); end;\n",
        "DF4Old['preocc']= DF4Old.iloc[:, 29:37].sum(axis=1)\n",
        "\n",
        "#do i = 38 to 45; hesitat = hesitat + x(i); end;\n",
        "DF4Old['hesitat']= DF4Old.iloc[:, 37:45].sum(axis=1)\n",
        "\n",
        "#do i = 46 to 50; volatil = volatil + x(i);\n",
        "DF4Old['volatil']= DF4Old.iloc[:, 45:50].sum(axis=1)\n",
        "\n",
        "#do i = 51 to 54; engagecurric = engagecurric + x(i); end;\n",
        "DF4Old['engagecurric']= DF4Old.iloc[:, 50:54].sum(axis=1)\n",
        "\n",
        "#do i = 55 to 59; engageextra = engageextra+x(i);\n",
        "DF4Old['engageextra']= DF4Old.iloc[:, 54:59].sum(axis=1)\n",
        "\n",
        "DF4Old.head()"
      ],
      "metadata": {
        "outputId": "b1d6cd20-a168-480f-bd6a-3f8b5185f496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BNU6hn9TQU0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  ...  59  60    61  efficacy  habbits  preocc  \\\n",
              "0  7  7  7  7  7  7  7  7  1  7  ...   5   2  3.00        49      118      10   \n",
              "1  7  7  6  6  7  4  7  4  4  5  ...   5   1  3.60        44      111      11   \n",
              "2  5  4  5  4  5  4  5  6  6  5  ...   2   5  2.80        32      121       9   \n",
              "3  6  7  6  6  7  7  6  6  2  2  ...   4   2  3.78        45      104       8   \n",
              "4  6  7  5  6  7  7  7  5  4  4  ...   5   3  3.85        45       96      11   \n",
              "\n",
              "   hesitat  volatil  engagecurric  engageextra  \n",
              "0       11        7            20           25  \n",
              "1       14       10            14            5  \n",
              "2        9        9             9            6  \n",
              "3       15        9            11            9  \n",
              "4       15       10            16           10  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18126141-7dff-48af-bd05-716a4bedaf84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>efficacy</th>\n",
              "      <th>habbits</th>\n",
              "      <th>preocc</th>\n",
              "      <th>hesitat</th>\n",
              "      <th>volatil</th>\n",
              "      <th>engagecurric</th>\n",
              "      <th>engageextra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3.00</td>\n",
              "      <td>49</td>\n",
              "      <td>118</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3.60</td>\n",
              "      <td>44</td>\n",
              "      <td>111</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2.80</td>\n",
              "      <td>32</td>\n",
              "      <td>121</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3.78</td>\n",
              "      <td>45</td>\n",
              "      <td>104</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3.85</td>\n",
              "      <td>45</td>\n",
              "      <td>96</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18126141-7dff-48af-bd05-716a4bedaf84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18126141-7dff-48af-bd05-716a4bedaf84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18126141-7dff-48af-bd05-716a4bedaf84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF4_ALL = pd.concat([DF4Old, DF4New, DF4FreJeoPre, DF4FreJeoPost], axis = 0)"
      ],
      "metadata": {
        "id": "jVSWEdfLR-Fn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF4_ALL.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "r5IjvPiBiAAI",
        "outputId": "b0b0eea0-254a-49b5-d98e-175c8ef029b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  ...  59  60    61  efficacy  habbits  preocc  \\\n",
              "0  7  7  7  7  7  7  7  7  1  7  ...   5   2  3.00        49      118      10   \n",
              "1  7  7  6  6  7  4  7  4  4  5  ...   5   1  3.60        44      111      11   \n",
              "2  5  4  5  4  5  4  5  6  6  5  ...   2   5  2.80        32      121       9   \n",
              "3  6  7  6  6  7  7  6  6  2  2  ...   4   2  3.78        45      104       8   \n",
              "4  6  7  5  6  7  7  7  5  4  4  ...   5   3  3.85        45       96      11   \n",
              "\n",
              "   hesitat  volatil  engagecurric  engageextra  \n",
              "0       11        7            20           25  \n",
              "1       14       10            14            5  \n",
              "2        9        9             9            6  \n",
              "3       15        9            11            9  \n",
              "4       15       10            16           10  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f9d8e28-1ac2-4bc3-b78b-1eaec05143bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>efficacy</th>\n",
              "      <th>habbits</th>\n",
              "      <th>preocc</th>\n",
              "      <th>hesitat</th>\n",
              "      <th>volatil</th>\n",
              "      <th>engagecurric</th>\n",
              "      <th>engageextra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3.00</td>\n",
              "      <td>49</td>\n",
              "      <td>118</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3.60</td>\n",
              "      <td>44</td>\n",
              "      <td>111</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2.80</td>\n",
              "      <td>32</td>\n",
              "      <td>121</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3.78</td>\n",
              "      <td>45</td>\n",
              "      <td>104</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3.85</td>\n",
              "      <td>45</td>\n",
              "      <td>96</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f9d8e28-1ac2-4bc3-b78b-1eaec05143bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f9d8e28-1ac2-4bc3-b78b-1eaec05143bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f9d8e28-1ac2-4bc3-b78b-1eaec05143bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cormat = DF4_ALL.corr()\n",
        "round(cormat,2)\n",
        "import seaborn as sns\n",
        "kot = cormat[cormat>=.6]\n",
        "plt.figure(figsize=(18,12))\n",
        "sns.heatmap(kot, cmap=\"Greens\")"
      ],
      "metadata": {
        "outputId": "c3d05f49-a6bb-43dc-97e8-c3465b7e3639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "GqeF5ee0jCqK"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f150b306550>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF4FreJeoPost.iloc[:,61]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aadJT7Oja__",
        "outputId": "f176fe5f-6d6a-4b21-ffb6-104369f0c803"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      3.40\n",
              "1      3.79\n",
              "2      3.40\n",
              "3      2.50\n",
              "4      3.40\n",
              "       ... \n",
              "426    3.00\n",
              "427    3.40\n",
              "428    3.93\n",
              "429    3.99\n",
              "430    3.00\n",
              "Name: 61, Length: 431, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPAFreJeoPost = DF4FreJeoPost.iloc[:,61]\n",
        "DF4FreJeoPost.drop(DF4FreJeoPost.columns[61], axis=1, inplace=True)\n",
        "DF4FreJeoPost.columns = range(DF4FreJeoPost.columns.size) # re index column numbers\n",
        "# to get numbers > k\n",
        "count2 = sum(i < 2 for i in GPAFreJeoPost)\n",
        "count25 = sum(i < 2.5 for i in GPAFreJeoPost)\n",
        "count3 = sum(i < 3 for i in GPAFreJeoPost)\n",
        "count4 = sum(i <= 4 for i in GPAFreJeoPost)\n",
        "# printing the intersection \n",
        "print(f'Out of {len(GPAFreJeoPost)} students, GPAFreJeoPost < 2: {count2}, GPAFreJeoPost < 2.5: {count25}, GPAFreJeoPost < 3: {count3}, GPAFreJeoPost <= 4: {count4}')\n",
        "fig = px.histogram(GPAFreJeoPost, nbins=6)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "PNGYi66wsoZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "a2bd8948-93c0-4979-b10d-b22e41c6c905"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 431 students, GPAFreJeoPost < 2: 3, GPAFreJeoPost < 2.5: 11, GPAFreJeoPost < 3: 75, GPAFreJeoPost < 4: 427\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a16a6770-515d-4919-85a0-d748b9c41a3e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a16a6770-515d-4919-85a0-d748b9c41a3e\")) {                    Plotly.newPlot(                        \"a16a6770-515d-4919-85a0-d748b9c41a3e\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=61<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"61\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"61\",\"nbinsx\":6,\"offsetgroup\":\"61\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.4,3.79,3.4,2.5,3.4,3.79,3.58,3.82,3.1,3.3,3.57,3.2,2.96,3.9,2.8,3.2,3.38,3.9,3.35,3.95,3.5,3.2,3.2,3.62,3.89,3.97,3.47,3.52,3.5,3.92,3.24,3.4,2.2,3.46,3.5,3.5,3.92,3.57,3.9,3.75,3.8,3.7,3.29,3.5,2.4,3.92,3.81,2.8,2.8,3.63,3.6,3.9,2.19,3.5,3.9,3.14,3.0,3.2,2.7,3.12,3.94,3.0,3.3,3.0,2.8,2.6,3.6,3.85,3.2,2.94,3.44,3.75,2.9,3.6,3.5,3.7,3.67,3.96,3.2,3.52,3.67,3.52,3.3,3.14,3.45,3.8,3.1,3.91,3.98,3.46,3.28,3.7,3.54,3.22,2.0,3.66,3.47,3.75,3.8,3.5,3.93,3.54,3.57,3.3,3.07,3.5,3.3,3.71,3.7,3.26,2.9,3.9,3.8,2.93,3.45,3.48,3.92,3.69,3.3,2.82,3.2,3.78,3.18,3.8,3.41,2.98,3.8,3.7,3.1,2.26,3.2,3.4,3.2,3.3,2.8,3.54,3.2,3.2,1.76,3.55,3.02,3.19,3.6,3.64,3.6,3.0,2.89,3.01,1.78,3.4,3.04,3.1,2.41,3.3,2.8,2.7,2.5,2.8,3.4,2.78,2.6,3.74,3.74,3.4,3.25,2.7,3.1,3.8,3.8,2.99,3.83,3.45,3.5,3.56,3.48,2.66,3.97,3.44,3.3,4.0,3.41,3.12,3.48,2.57,3.79,3.2,3.98,3.61,3.3,3.4,3.14,2.56,3.72,2.9,3.7,3.7,3.36,3.3,3.79,3.61,2.8,3.12,3.32,3.2,2.66,2.92,3.8,3.2,3.89,3.51,3.12,2.7,3.72,3.35,3.6,3.21,3.18,2.87,3.1,3.66,3.74,3.73,2.6,3.86,3.42,4.0,3.64,3.95,2.87,2.8,3.17,3.0,3.42,2.74,3.19,3.79,3.7,3.65,2.66,3.79,3.15,3.14,3.8,3.6,4.0,3.2,3.6,3.7,3.81,3.13,2.01,2.98,3.35,2.8,2.9,3.5,3.69,3.2,3.09,3.04,3.18,3.24,2.8,3.43,2.9,3.91,3.3,3.8,3.5,3.67,3.78,3.3,3.2,3.19,3.2,2.8,3.92,3.64,3.3,3.5,3.06,3.05,3.06,2.7,3.45,3.01,2.6,3.42,2.7,3.79,3.6,3.4,3.93,3.59,3.9,3.21,3.27,3.34,3.7,2.92,3.96,3.266,3.3,3.07,3.0,3.47,3.0,3.0,3.87,3.9,3.85,2.6,3.56,2.97,2.7,3.65,3.66,3.5,3.86,3.84,3.12,3.0,3.0,3.28,3.74,2.5,3.64,3.6,3.4,3.8,3.85,3.36,3.23,2.93,3.3,3.62,3.77,3.0,3.0,2.6,2.64,3.0,3.3,3.26,3.34,3.5,3.22,3.57,3.6,3.8,3.54,3.1,2.6,2.87,3.45,3.0,3.88,3.0,2.49,3.2,3.91,3.11,3.93,3.21,3.7,3.5,3.21,3.02,2.85,3.5,3.6,3.6,3.0,2.99,3.0,3.43,3.2,2.98,3.5,3.0,3.1,2.5,3.5,3.0,3.37,3.89,3.0,2.99,3.85,3.73,3.0,3.23,3.2,2.8,3.8,4.0,3.43,3.3,3.97,3.7,3.26,3.57,1.78,3.65,3.16,3.3,3.25,3.56,3.38,3.77,3.96,3.4,3.0,3.51,3.95,3.7,3.14,3.92,3.83,3.5,3.4,3.3,2.85,3.73,3.0,3.25,3.0,3.4,3.93,3.99,3.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a16a6770-515d-4919-85a0-d748b9c41a3e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPAFreJeoPre = DF4FreJeoPre.iloc[:,61]\n",
        "DF4FreJeoPre.drop(DF4FreJeoPre.columns[61], axis=1, inplace=True)\n",
        "DF4FreJeoPre.columns = range(DF4FreJeoPre.columns.size) # re index column numbers\n",
        "# to get numbers > k\n",
        "count2 = sum(i < 2 for i in GPAFreJeoPre)\n",
        "count25 = sum(i < 2.5 for i in GPAFreJeoPre)\n",
        "count3 = sum(i < 3 for i in GPAFreJeoPre)\n",
        "count4 = sum(i <= 4 for i in GPAFreJeoPre)\n",
        "# printing the intersection \n",
        "print(f'Out of {len(GPAFreJeoPre)} students, GPAFreJeoPre < 2: {count2}, GPAFreJeoPre < 2.5: {count25}, GPAFreJeoPre < 3: {count3}, GPAFreJeoPre <= 4: {count4}')\n",
        "\n",
        "fig = px.histogram(GPAFreJeoPre, nbins=6)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ohZ7zfcUjM6j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "57818c95-ef09-4af3-8b67-0ef866d0dca4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 484 students, GPAFreJeoPre < 2: 3, GPAFreJeoPre < 2.5: 12, GPAFreJeoPre < 3: 98, GPAFreJeoPre <= 4: 484\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ee3649cc-5b02-4853-842a-817dbd0a7219\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ee3649cc-5b02-4853-842a-817dbd0a7219\")) {                    Plotly.newPlot(                        \"ee3649cc-5b02-4853-842a-817dbd0a7219\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=61<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"61\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"61\",\"nbinsx\":6,\"offsetgroup\":\"61\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.3,3.21,2.7,3.01,2.8,3.2,3.5,3.2,3.64,2.8,1.76,3.5,3.79,3.29,2.8,2.5,3.8,3.84,3.14,3.6,2.9,3.48,3.6,3.8,3.58,3.47,3.3,3.25,3.82,2.9,4.0,3.49,3.2,3.71,3.5,2.8,3.26,3.26,3.4,3.67,2.7,3.5,3.52,3.76,3.54,2.99,3.64,2.9,3.16,3.79,3.3,3.46,2.57,3.07,3.8,3.6,3.0,3.8,3.57,2.9,3.63,3.6,2.94,3.9,2.8,3.95,3.6,2.94,3.98,3.4,3.4,3.81,3.8,3.0,3.2,3.6,2.7,3.2,3.0,3.46,2.4,3.18,3.9,3.2,3.04,3.49,3.0,2.9,3.21,3.98,3.62,3.4,3.35,3.8,3.3,3.7,3.94,3.89,3.47,3.1,3.56,3.2,3.4,2.82,3.15,2.9,3.07,3.2,3.7,2.1,3.7,2.3,3.69,2.75,3.3,3.4,3.4,3.96,3.1,2.98,3.91,3.6,3.71,3.44,3.8,2.6,3.15,3.9,3.92,2.8,2.7,3.8,3.1,3.93,3.3,3.0,3.12,2.93,3.65,3.95,2.77,3.4,2.7,3.3,3.34,3.47,3.92,3.0,3.2,3.35,2.9,3.5,3.52,2.26,2.7,3.42,3.4,2.7,3.73,3.41,3.69,3.09,3.5,3.54,4.0,3.82,3.0,3.79,3.7,3.0,2.68,3.87,3.2,3.14,3.3,2.7,2.9,3.72,3.96,3.0,3.4,3.27,3.19,3.14,3.01,3.12,3.72,3.8,2.75,3.65,3.44,3.37,3.42,3.12,2.57,3.0,3.5,3.92,3.5,3.3,4.0,3.2,2.8,4.0,4.0,2.66,3.9,2.5,3.07,3.55,3.4,3.53,3.16,3.18,2.54,3.3,2.98,3.3,3.45,3.3,3.36,3.09,3.4,3.3,3.5,3.64,2.8,3.1,3.6,2.9,3.48,4.0,3.32,3.08,3.87,3.5,3.78,2.64,3.65,3.0,3.2,3.85,3.19,3.2,3.5,3.3,2.84,2.98,3.0,3.47,3.6,3.74,3.18,3.05,3.01,3.4,2.95,3.12,3.0,2.4,3.3,3.61,3.42,3.79,3.69,3.2,2.87,3.79,3.9,3.0,3.64,2.71,3.86,3.2,3.98,3.63,2.9,3.95,3.42,3.47,2.8,3.66,3.74,3.4,3.1,3.91,2.9,3.36,3.24,2.6,3.87,3.64,2.95,3.61,3.84,3.27,3.57,2.92,3.79,3.76,3.77,3.4,3.98,3.8,3.67,3.88,2.84,3.5,3.0,3.77,3.48,3.15,3.12,3.8,3.85,3.45,2.5,2.84,3.82,3.5,3.93,3.34,3.7,3.81,3.34,3.8,2.6,3.11,3.7,3.86,3.53,4.0,3.0,2.94,2.8,2.7,3.54,3.2,3.83,3.41,3.18,3.23,3.7,3.67,3.01,3.6,3.0,3.51,3.3,3.81,3.86,2.4,3.1,3.46,3.0,2.8,2.6,2.0,3.6,2.49,3.5,2.86,3.4,3.0,2.6,3.69,3.96,3.25,2.66,3.87,2.7,3.58,3.2,2.91,3.15,3.5,2.98,2.79,3.53,3.55,3.26,2.9,3.73,3.5,3.87,3.6,3.1,2.71,3.1,3.28,2.8,3.79,3.65,3.4,3.49,3.16,3.5,3.0,2.9,3.0,3.5,2.85,3.91,3.6,3.5,3.6,3.29,3.77,3.21,3.88,2.81,2.95,3.97,3.67,3.8,3.02,4.0,2.5,4.0,3.39,3.07,3.37,3.14,3.88,3.12,3.43,3.6,3.1,3.0,3.0,3.4,2.89,3.0,3.69,3.7,3.65,3.4,3.83,3.8,3.21,3.57,3.93,3.96,3.73,3.15,3.94,3.56,1.78,2.86,3.9,3.4,3.72,2.82,3.6,3.17,2.3,3.7,2.95,3.0,3.52,3.0,3.27,3.16,3.9,3.81,3.2,2.79,3.5,3.25,2.96,3.5,3.0,3.4,1.78,3.7,2.98,3.09,3.85,3.93,3.4,3.7,3.92,3.09,3.5],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ee3649cc-5b02-4853-842a-817dbd0a7219');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPAOld = DF4Old.iloc[:,61]\n",
        "DF4Old.drop(DF4Old.columns[61], axis=1, inplace=True)\n",
        "DF4Old.columns = range(DF4Old.columns.size) # re index column numbers\n",
        "# to get numbers > k\n",
        "count2 = sum(i < 2 for i in GPAOld)\n",
        "count25 = sum(i < 2.5 for i in GPAOld)\n",
        "count3 = sum(i < 3 for i in GPAOld)\n",
        "count4 = sum(i <= 4 for i in GPAOld)\n",
        "# printing the intersection \n",
        "print(f'Out of {len(GPAOld)} students, GPAOld < 2: {count2}, GPAOld < 2.5: {count25}, GPAOld < 3: {count3}, GPAOld <= 4: {count4}')\n",
        "fig = px.histogram(GPAOld, nbins=6)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "dd57d946-85bf-4c56-dd12-3cb432441b41",
        "id": "P41l7A8IRPG0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 2592 students, GPAOld < 2: 16, GPAOld < 2.5: 79, GPAOld < 3: 312, GPAOld <= 4: 2592\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a8aa19f5-1c0c-43cf-bfc9-86e173658ca0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a8aa19f5-1c0c-43cf-bfc9-86e173658ca0\")) {                    Plotly.newPlot(                        \"a8aa19f5-1c0c-43cf-bfc9-86e173658ca0\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=61<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"61\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"61\",\"nbinsx\":6,\"offsetgroup\":\"61\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.0,3.6,2.8,3.78,3.85,2.92,2.97,3.12,3.01,3.9,3.23,3.08,3.42,3.58,3.96,3.6,3.6,3.5,4.0,3.9,3.72,3.72,2.96,3.51,3.9,3.5,3.2,4.0,3.8,3.76,4.0,3.13,3.91,3.98,3.41,3.2,3.45,2.9,2.5,3.85,3.92,3.63,3.96,2.8,3.6,3.96,3.96,3.4,3.2,3.5,3.5,3.94,1.76,3.3,2.64,3.0,3.4,3.92,3.1,3.79,3.9,3.94,3.97,3.33,3.7,3.47,4.0,3.6,3.08,4.0,3.5,3.8,4.0,3.5,4.0,4.0,3.8,2.5,4.0,3.84,3.5,4.0,4.0,4.0,4.0,4.0,3.9,3.9,4.0,4.0,4.0,3.0,4.0,3.88,3.8,4.0,3.7,4.0,3.4,3.5,4.0,3.6,4.0,4.0,4.0,3.7,3.15,4.0,3.3,4.0,4.0,2.8,4.0,3.5,3.77,4.0,4.0,3.71,4.0,3.2,3.3,4.0,3.7,3.0,4.0,4.0,4.0,4.0,3.5,2.45,2.0,4.0,4.0,4.0,3.8,3.75,3.5,3.0,4.0,4.0,3.5,4.0,3.9,3.7,3.98,3.67,3.62,3.33,3.61,4.0,3.8,4.0,3.0,4.0,3.0,4.0,4.0,4.0,3.81,3.92,4.0,2.5,4.0,3.63,3.2,3.2,3.5,3.8,4.0,3.0,3.9,3.1,3.9,3.7,3.34,3.9,2.97,3.7,2.8,3.2,4.0,4.0,3.5,3.12,4.0,4.0,3.8,4.0,3.64,2.0,3.8,4.0,3.0,3.4,4.0,4.0,4.0,4.0,4.0,3.8,3.5,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.3,3.0,4.0,3.95,4.0,3.5,4.0,3.0,3.5,4.0,4.0,4.0,4.0,4.0,4.0,3.57,4.0,3.17,3.3,4.0,3.94,3.8,4.0,2.8,4.0,4.0,3.0,4.0,3.77,4.0,3.0,3.6,4.0,4.0,4.0,4.0,4.0,4.0,3.5,3.83,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.0,4.0,3.7,3.9,3.04,3.5,3.5,4.0,4.0,3.45,3.9,3.7,3.7,3.4,4.0,3.5,3.9,3.5,3.87,2.0,3.8,4.0,2.9,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.8,3.8,4.0,3.78,3.0,3.6,4.0,3.0,4.0,3.8,4.0,3.3,3.64,4.0,3.5,3.6,3.3,3.83,3.6,3.75,3.5,3.5,3.97,4.0,3.93,3.5,4.0,4.0,3.8,1.0,3.5,4.0,3.55,3.3,4.0,4.0,3.85,3.82,3.96,3.53,3.2,3.7,4.0,4.0,3.0,3.5,1.9,3.48,3.7,3.8,3.5,3.2,3.4,4.0,3.5,3.54,4.0,3.36,3.49,3.15,3.8,3.8,3.0,3.5,4.0,3.79,4.0,3.7,3.85,4.0,4.0,3.98,4.0,3.66,3.84,3.84,3.76,2.94,3.6,4.0,3.6,4.0,3.61,3.91,2.8,3.46,3.94,3.03,3.33,2.8,3.6,3.5,3.2,3.2,3.89,3.43,3.8,3.6,3.92,3.95,3.3,3.71,3.6,3.1,3.0,3.2,3.75,3.3,3.01,2.82,3.4,3.5,3.1,3.5,3.41,3.68,2.8,2.8,4.0,3.8,3.2,3.33,3.0,3.02,2.69,3.2,2.6,3.8,3.18,3.44,3.2,3.5,3.1,3.3,3.2,3.06,2.8,3.4,3.8,2.67,3.38,3.8,3.334,3.78,3.7,2.6,2.3,3.5,2.7,3.4,3.912,3.76,3.2,3.7,3.2,3.22,3.4,4.0,2.99,3.7,3.5,3.8,3.2,3.8,4.0,3.0,3.5,3.55,2.9,2.74,3.34,3.0,3.3,2.81,2.81,3.73,3.65,2.8,3.6,3.7,3.9,2.4,3.48,3.2,3.7,3.3,3.43,2.9,3.29,3.0,2.51,3.0,3.5,3.92,3.8,3.36,3.07,3.03,3.6,3.95,3.42,3.57,1.6,3.21,2.6,2.7,2.8,3.93,3.8,3.9,3.0,3.7,3.8,2.88,3.7,3.95,3.76,3.72,4.0,3.25,3.1,3.6,3.41,3.5,3.6,3.25,3.1,3.91,2.6,4.0,3.4,3.8,3.4,3.0,3.3,3.0,3.0,3.26,3.2,3.94,3.333,4.0,3.0,4.0,3.9,3.4,3.65,3.74,3.5,3.1,3.42,3.52,3.0,3.6,3.8,3.92,3.1,2.81,3.05,3.7,4.0,2.86,2.8,3.89,2.8,4.0,3.62,3.54,3.44,2.7,3.0,3.14,2.9,3.5,3.2,3.3,3.2,3.8,3.2,4.0,3.25,4.0,3.5,3.94,4.0,3.2,2.0,2.91,3.44,3.27,3.8,3.92,4.0,3.7,2.57,3.4,4.0,3.1,3.8,3.8,3.8,3.69,3.92,3.0,2.8,3.4,3.67,3.0,3.65,3.0,3.0,4.0,3.3,3.8,3.79,3.87,3.2,3.67,3.0,4.0,4.0,3.36,3.7,3.98,4.0,3.65,3.3,3.2,3.1,2.6,3.8,3.8,4.0,3.8,3.85,3.2,3.5,3.73,3.5,3.19,3.78,3.66,3.52,4.0,4.0,3.6,2.5,3.71,1.9,3.66,3.87,3.4,2.75,3.3,2.8,3.4,3.94,4.0,3.89,3.1,2.95,3.4,3.69,3.87,3.8,3.62,3.1,3.56,3.2,3.5,3.3,2.0,3.0,3.5,2.98,3.0,3.2,3.8,3.7,3.8,3.84,3.3,3.29,3.86,3.2,3.5,3.6,3.2,3.0,3.1,3.02,3.0,4.0,3.5,3.81,4.0,3.3,3.85,3.6,3.5,3.2,3.64,3.66,3.51,3.91,3.98,3.1,3.4,3.0,3.2,4.0,2.9,2.1,3.5,3.77,2.6,1.69,3.5,3.0,3.32,4.0,3.0,3.52,2.6,2.1,3.64,3.6,3.91,3.56,2.01,3.5,3.3,2.7,3.6,3.1,3.75,3.0,3.4,2.49,3.03,3.4,3.38,3.0,4.0,3.2,3.18,3.66,3.61,3.86,3.9,3.15,3.2,4.0,3.2,3.6,3.79,2.85,3.22,3.53,3.8,3.9,2.98,3.66,3.78,3.7,3.2,3.68,2.73,3.8,2.95,3.95,3.9,3.2,3.1,3.07,3.95,3.7,3.0,2.57,3.5,3.75,3.57,2.7,3.4,3.2,3.1,3.36,3.0,3.2,3.01,3.65,3.3,3.34,3.33,3.7,4.0,3.3,3.14,3.3,3.0,3.95,3.33,2.83,3.23,2.9,2.96,3.3,3.35,3.0,3.18,3.11,3.31,3.3,3.36,3.0,3.9,3.12,3.7,2.72,3.26,2.02,3.4,3.1,3.3,1.5,2.28,3.93,3.7,3.4,3.8,3.91,2.8,3.0,3.6,2.6,3.35,2.74,3.24,3.78,3.67,3.9,4.0,2.44,3.93,3.9,2.9,3.47,3.95,3.9,3.67,2.83,3.79,3.67,3.47,3.5,3.26,3.76,3.6,3.5,3.7,2.7,2.8,3.9,3.5,3.6,4.0,3.1,3.9,4.0,3.98,3.16,3.47,3.3,3.67,2.8,3.47,3.19,3.65,3.5,4.0,2.83,3.8,3.67,3.8,3.93,2.95,2.99,3.02,3.8,3.4,2.69,3.845,3.95,3.57,2.9,3.8,3.86,3.77,3.0,3.8,3.68,3.9,3.25,3.75,3.2,3.9,3.1,3.5,3.87,3.4,3.8,3.96,3.8,3.43,3.7,3.2,4.0,4.0,3.6,3.93,3.46,3.67,3.2,3.18,3.38,3.82,3.91,4.0,3.92,4.0,4.0,3.4,2.57,2.89,2.7,2.89,3.5,4.0,3.44,4.0,3.98,3.98,3.98,3.04,3.73,3.5,3.3,3.8,3.7,2.88,3.9,3.7,3.9,2.53,4.0,3.2,3.2,2.8,3.45,3.84,2.6,3.7,4.0,3.02,3.6,3.1,3.8,3.76,3.97,3.74,2.99,3.68,3.3,3.7,3.25,3.84,3.7,2.9,4.0,3.47,3.06,3.75,3.66,3.0,3.42,3.96,3.2,3.9,3.1,3.6,3.91,3.4,3.02,3.92,3.75,3.74,3.23,3.95,4.0,3.59,3.1,3.0,4.0,3.8,3.5,2.97,2.97,3.2,2.87,3.45,3.32,3.4,1.0,3.75,3.5,3.23,3.0,2.6,3.75,3.5,2.5,2.56,4.0,3.88,3.1,3.49,2.8,3.35,3.5,3.98,4.0,3.9,3.83,2.2,3.96,3.8,2.0,4.0,3.4,3.12,3.42,3.2,3.2,2.9,3.32,3.3,4.0,4.0,3.25,4.0,2.5,3.9,3.5,3.27,3.8,2.4,4.0,3.71,3.9,3.81,3.62,3.94,4.0,4.0,2.9,3.65,2.4,3.75,3.33,3.8,3.94,3.5,3.85,3.62,2.94,3.96,3.75,3.55,3.98,4.0,4.0,3.64,3.6,2.9,3.25,3.5,3.66,3.1,3.83,3.29,4.0,2.57,3.55,3.54,3.0,3.96,3.6,2.91,2.64,2.8,3.9,2.8,3.84,2.5,3.77,3.5,3.8,3.96,4.0,3.2,3.0,3.0,2.88,3.95,3.0,3.69,3.2,2.6,1.9,3.6,3.5,3.5,3.5,3.96,3.0,3.5,2.84,3.49,4.0,4.0,4.0,2.6,2.6,4.0,3.2,2.85,3.33,3.92,3.98,3.66,3.3,3.9,3.5,4.0,3.1,4.0,3.08,3.7,4.0,2.3,4.0,3.8,3.1,4.0,4.0,3.8,4.0,3.75,3.0,3.4,4.0,3.8,3.79,2.71,3.8,4.0,3.7,3.83,3.7,3.91,4.0,4.0,3.96,3.97,3.3,3.5,3.95,3.77,3.8,3.6,3.5,3.8,4.0,4.0,3.8,4.0,3.8,3.7,4.0,3.38,3.32,3.6,3.6,3.7,3.36,3.67,4.0,3.67,3.01,3.92,3.3,3.7,3.27,3.59,3.5,2.8,3.96,2.8,4.0,3.9,3.6,3.33,3.69,3.86,3.0,3.64,3.76,3.9,3.0,3.6,3.76,3.2,3.2,3.54,3.6,4.0,4.0,3.2,3.5,3.5,3.84,3.7,3.4,4.0,3.2,4.0,3.41,4.0,3.7,3.9,3.8,3.8,3.5,1.0,3.8,4.0,3.8,4.0,3.3,3.97,3.6,3.3,3.94,3.9,3.9,3.69,3.8,3.5,4.0,4.0,3.2,3.6,2.9,3.53,2.5,3.24,4.0,3.2,3.0,3.0,3.5,3.6,3.9,3.43,3.86,3.4,3.8,3.6,4.0,3.9,3.7,3.6,3.5,3.76,3.17,3.3,4.0,2.9,3.8,3.6,4.0,3.4,2.84,3.5,3.4,4.0,3.3,3.86,3.5,4.0,3.95,3.5,3.5,3.04,2.8,4.0,3.9,3.76,3.45,3.6,2.8,2.81,3.1,4.0,3.9,3.69,3.0,3.8,2.97,3.7,4.0,3.46,2.9,3.5,2.0,3.1,4.0,3.6,4.0,3.5,3.62,3.4,4.0,4.0,3.6,4.0,3.7,3.6,3.04,4.0,3.33,3.6,4.0,3.0,3.49,3.5,2.16,3.03,2.4,4.0,3.5,2.5,3.34,3.4,4.0,3.5,3.33,3.1,3.85,3.9,3.8,3.5,3.7,3.0,3.7,3.33,3.7,2.83,3.0,3.2,3.1,3.0,3.97,3.0,3.51,3.5,3.6,4.0,4.0,4.0,3.97,2.8,3.8,3.41,4.0,4.0,4.0,3.81,3.92,3.7,2.3,3.64,4.0,3.5,3.44,3.92,2.9,3.04,4.0,3.48,3.5,3.5,3.3,3.5,3.95,4.0,3.65,3.7,3.78,2.3,2.5,3.4,3.8,3.7,3.7,4.0,3.7,2.88,3.64,3.74,3.0,3.97,2.3,4.0,2.7,3.4,3.77,3.69,3.9,3.56,3.66,3.75,3.6,3.95,2.9,3.8,2.45,3.4,4.0,3.94,3.2,3.89,3.87,3.7,3.5,3.88,3.9,3.9,2.5,3.8,3.35,3.15,3.18,4.0,3.63,3.2,3.57,4.0,2.87,3.7,3.2,3.93,4.0,3.6,3.5,3.78,3.97,3.4,3.2,3.23,3.5,3.2,3.2,3.8,3.8,4.0,3.81,3.27,3.38,4.0,3.2,3.8,3.7,3.4,4.0,3.8,3.64,3.46,4.0,3.5,3.6,3.0,3.7,3.81,3.9,3.0,3.0,3.44,3.0,3.9,2.95,3.9,3.5,3.8,4.0,3.6,3.96,3.4,3.93,3.5,3.7,4.0,3.97,3.6,3.02,3.96,4.0,3.6,3.7,3.8,3.83,3.8,3.33,3.95,3.94,3.3,1.9,3.67,3.93,3.0,3.66,3.85,3.2,3.79,3.95,2.75,3.4,3.46,3.59,3.56,3.75,4.0,3.5,3.3,3.6,3.9,3.97,2.85,4.0,4.0,3.5,4.0,4.0,3.9,4.0,3.7,3.6,3.64,2.9,2.31,3.0,3.5,3.22,3.13,4.0,3.95,3.79,4.0,3.8,4.0,3.6,3.33,3.6,3.8,3.95,3.3,3.25,3.2,3.6,3.0,1.14,3.56,3.5,3.76,3.8,3.1,4.0,3.8,3.01,3.98,3.6,3.9,3.78,3.3,3.04,3.38,3.27,3.4,2.5,2.7,3.5,3.9,3.85,3.9,3.6,3.82,4.0,3.1,3.0,3.83,3.5,3.1,3.7,3.9,3.98,3.6,3.91,3.4,3.8,3.5,3.2,3.45,3.76,3.6,3.6,3.4,3.5,3.49,3.7,3.5,2.8,3.9,3.2,3.2,4.0,3.49,3.1,3.22,3.7,3.03,3.6,3.85,3.3,3.94,3.0,4.0,3.8,2.0,3.9,3.8,3.49,4.0,2.9,3.01,3.4,3.8,3.75,3.0,3.97,3.2,2.69,3.82,2.61,3.0,4.0,1.9,3.5,2.5,3.75,3.77,3.1,3.0,2.71,3.73,3.55,3.58,3.95,3.3,3.5,2.1,3.95,3.39,3.1,3.6,3.47,2.9,2.6,3.0,3.44,3.81,3.5,2.7,3.39,2.78,3.5,3.8,3.3,3.8,3.28,3.87,2.99,3.23,3.75,3.94,3.5,2.8,4.0,3.4,3.25,3.5,3.83,3.0,3.79,3.54,3.76,4.0,3.73,3.3,4.0,3.95,3.0,3.0,3.8,3.3,2.5,3.5,3.57,3.0,3.6,3.6,3.2,2.3,3.7,4.0,3.89,3.5,3.2,3.21,3.89,4.0,2.8,3.2,4.0,3.56,3.3,3.0,3.77,3.7,2.84,3.03,4.0,3.7,3.7,3.72,4.0,3.7,3.0,3.6,4.0,2.6,3.75,3.0,3.8,3.74,3.4,3.3,2.9,2.7,2.8,3.8,3.72,3.5,3.92,3.71,3.92,3.91,3.6,3.97,3.6,3.4,3.45,3.68,2.78,2.81,3.97,3.6,4.0,3.3,3.4,3.82,3.72,3.01,4.0,2.34,3.77,3.0,3.0,3.8,3.8,3.8,3.95,3.8,3.41,3.82,4.0,4.0,3.94,3.9,3.89,3.75,3.7,3.4,3.44,3.7,3.95,3.14,3.8,3.89,3.78,3.91,4.0,3.7,4.0,2.8,3.4,3.53,2.89,3.4,3.6,3.37,3.9,4.0,1.0,3.2,3.0,3.81,3.5,3.56,2.9,3.9,3.0,3.93,3.92,3.03,3.7,3.8,3.5,4.0,3.4,4.0,3.3,3.3,3.61,3.61,3.61,3.6,3.45,3.4,3.4,3.4,3.4,4.0,4.0,3.95,4.0,4.0,4.0,2.7,3.3,3.3,3.7,4.0,3.4,3.83,3.2,3.25,3.5,3.8,3.93,3.8,3.91,4.0,4.0,3.3,3.1,3.1,4.0,4.0,4.0,3.4,4.0,2.3,3.8,3.8,3.84,3.2,3.89,3.89,2.5,4.0,3.5,3.4,4.0,3.66,3.0,3.0,4.0,3.62,3.8,3.0,3.92,4.0,3.92,3.4,3.73,4.0,4.0,3.86,4.0,4.0,3.34,3.6,2.95,3.88,3.4,3.94,3.75,3.2,3.78,3.0,3.88,3.9,3.9,3.35,3.2,3.3,3.5,3.8,3.4,3.54,3.83,3.83,2.74,3.93,3.6,3.8,3.86,3.78,4.0,4.0,3.6,3.0,4.0,4.0,4.0,4.0,4.0,3.11,1.83,4.0,3.7,3.85,3.37,3.53,3.7,3.7,4.0,3.76,3.32,3.32,3.29,3.98,4.0,3.6,3.2,3.0,3.85,3.96,3.9,3.95,3.95,3.7,3.8,2.17,3.89,3.8,3.85,3.25,3.5,2.6,3.9,3.81,3.81,3.5,3.9,3.7,3.7,3.43,3.6,3.0,4.0,3.8,3.89,3.34,3.55,4.0,4.0,3.19,3.77,3.1,4.0,3.68,3.65,3.3,3.9,2.26,3.68,3.8,3.8,3.8,2.99,3.4,3.8,3.53,3.9,3.2,4.0,3.0,2.7,3.71,3.34,3.5,4.0,4.0,3.88,4.0,3.5,3.5,3.8,3.5,3.5,3.8,3.34,4.0,3.87,3.7,3.0,3.7,4.0,3.7,4.0,3.4,3.4,2.79,3.6,3.73,3.86,3.7,3.6,3.66,3.6,3.7,3.8,3.5,3.7,2.6,3.6,3.98,3.5,4.0,3.2,4.0,3.5,2.9,3.36,3.4,2.94,3.5,3.2,3.75,3.4,3.72,3.9,3.0,3.79,3.79,3.3,4.0,3.4,3.4,2.5,2.5,2.8,3.7,3.0,3.0,4.0,3.86,3.71,3.93,3.71,3.71,2.8,3.4,3.91,3.5,3.66,3.7,3.7,3.72,3.6,2.97,3.2,3.6,3.27,3.56,3.5,3.11,3.11,3.11,3.2,3.9,2.66,3.0,2.0,3.92,3.73,3.85,3.87,3.49,2.8,2.8,3.55,3.34,3.34,3.73,3.3,4.0,3.2,3.15,3.95,3.7,3.5,2.5,3.75,2.4,2.4,3.75,3.3,3.2,2.1,3.6,4.0,4.0,3.02,3.41,3.01,2.35,3.87,3.2,3.2,3.12,4.0,3.4,3.61,3.69,3.7,3.7,3.3,3.4,3.51,3.5,3.4,3.5,3.86,3.4,3.87,3.8,3.8,3.8,3.2,3.5,4.0,3.4,3.2,3.34,4.0,3.5,3.4,2.71,2.0,3.8,3.8,3.57,3.93,3.7,3.7,1.48,3.4,3.6,3.3,3.3,3.5,3.7,4.0,3.69,3.4,2.5,2.92,3.5,3.71,3.0,4.0,3.4,2.89,3.0,3.77,4.0,3.53,3.33,3.57,3.0,3.0,3.88,3.03,3.8,3.7,4.0,3.6,3.8,3.15,3.15,3.8,2.5,3.34,3.34,3.64,2.8,3.91,3.78,3.73,4.0,3.89,4.0,3.9,3.6,3.93,3.69,3.14,4.0,3.85,3.85,3.54,2.7,3.72,3.72,3.54,3.56,3.47,3.7,4.0,2.7,3.2,2.8,3.86,3.68,3.68,4.0,4.0,3.9,3.77,3.68,3.35,3.7,3.76,2.86,3.6,3.93,3.93,3.4,3.99,2.995,3.1,2.62,3.3,3.3,3.3,3.0,2.8,4.0,4.0,3.4,4.0,3.64,2.0,3.7,3.6,3.7,3.4,3.8,3.8,3.71,3.57,3.85,3.1,3.1,3.65,3.0,3.65,3.65,2.0,3.78,3.0,3.7,3.5,3.57,3.57,3.5,3.7,3.3,3.3,3.3,3.66,3.95,3.3,3.79,3.93,3.79,3.9,3.97,3.31,3.31,2.5,2.5,3.89,3.9,3.48,4.0,3.95,3.9,4.0,2.8,3.08,3.8,3.75,3.1,2.7,3.3,3.81,3.68,3.87,3.51,3.6,3.0,2.57,3.81,3.9,4.0,3.94,3.7,3.7,3.4,4.0,3.95,3.7,3.83,2.7,3.8,3.27,3.8,3.5,3.5,3.5,3.88,2.9,2.61,3.6,3.6,3.69,3.3,3.4,2.5,3.88,2.85,2.4,3.98,3.62,3.6,3.7,2.8,4.0,3.8,3.3,2.7,3.27,3.1,3.86,3.3,3.32,3.8,3.6,3.21,2.0,2.6,3.77,3.96,3.33,3.9,2.7,3.87,3.76,3.6,3.37,3.8,3.86,3.83,2.58,3.7,3.18,3.25,3.25,3.3,3.3,3.86,3.3,3.4,3.8,4.0,2.04,2.8,2.04,3.6,3.98,3.73,3.8,2.9,3.48,3.37,3.0,3.42,3.86,3.0,3.0,4.0,4.0,3.5,3.6,2.9,3.0,3.6,3.0,3.8,3.4,3.3,3.58,3.2,4.0,2.83,3.5,3.0,2.4,2.4,3.9,3.75,3.0,3.6,4.0,3.9,2.5,3.3,3.0,3.78,3.0,2.8,2.09,2.7,3.2,3.79,3.2,3.58,2.3,3.4,3.21,3.87,3.21,3.0,3.1,3.7,3.61,3.55,3.89,3.18,3.7,3.7,3.96,3.7,3.0,3.2,3.02,3.02,3.0,3.87,3.29,3.8,3.89,3.02,3.5,3.0,2.88,3.1,3.1,3.32,2.9,3.89,3.47,2.8,3.8,3.3,2.4,3.3,4.0,3.85,3.12,3.2,2.4,3.8,3.8,3.59,3.8,3.65,3.6,3.2,2.8,3.0,3.5,3.82,3.68,3.5,3.7,3.0,2.4,3.02,3.73,3.1,3.45,3.4,2.6,3.78,3.05,3.83,2.76,3.75,2.0,2.85,3.0,3.92,2.4,3.75,3.0,3.91,3.8,3.0,3.2,3.82,4.0,3.0,2.7,3.91,3.68,2.9,3.0,3.58,3.0,3.25,2.3,3.4,2.3,3.25,3.4,3.4,3.25,3.93,2.1,3.93,3.4,3.0,4.0,3.3,3.5,2.7,3.08,3.0,3.8,2.3,3.71,3.5,2.3,2.4,3.68,2.4,3.3,3.92,3.81],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a8aa19f5-1c0c-43cf-bfc9-86e173658ca0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPAALL = DF4_ALL.iloc[:,61]\n",
        "DF4_ALL.drop(DF4_ALL.columns[61], axis=1, inplace=True)\n",
        "DF4_ALL.columns = range(DF4_ALL.columns.size) # re index column numbers\n",
        "# to get numbers > k\n",
        "count2 = sum(i < 2 for i in GPAALL)\n",
        "count25 = sum(i < 2.5 for i in GPAALL)\n",
        "count3 = sum(i < 3 for i in GPAALL)\n",
        "count4 = sum(i <= 4 for i in GPAALL)\n",
        "# printing the intersection \n",
        "print(f'Out of {len(GPAALL)} students, GPAALL < 2: {count2}, GPAALL < 2.5: {count25}, GPAALL < 3: {count3}, GPAALL < 4: {count4}')\n",
        "\n",
        "fig = px.histogram(GPAALL, nbins=6)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "d30d57ec-040f-4606-b227-72fdb66152dc",
        "id": "OM7V8n4ERPG1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 7664 students, GPAALL < 2: 43, GPAALL < 2.5: 230, GPAALL < 3: 1021, GPAALL < 4: 7664\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"efb45daa-855f-4568-89f0-753f52fe1379\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"efb45daa-855f-4568-89f0-753f52fe1379\")) {                    Plotly.newPlot(                        \"efb45daa-855f-4568-89f0-753f52fe1379\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=61<br>value=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"61\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"61\",\"nbinsx\":6,\"offsetgroup\":\"61\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.0,3.6,2.8,3.78,3.85,2.92,2.97,3.12,3.01,3.9,3.23,3.08,3.42,3.58,3.96,3.6,3.6,3.5,4.0,3.9,3.72,3.72,2.96,3.51,3.9,3.5,3.2,4.0,3.8,3.76,4.0,3.13,3.91,3.98,3.41,3.2,3.45,2.9,2.5,3.85,3.92,3.63,3.96,2.8,3.6,3.96,3.96,3.4,3.2,3.5,3.5,3.94,1.76,3.3,2.64,3.0,3.4,3.92,3.1,3.79,3.9,3.94,3.97,3.33,3.7,3.47,4.0,3.6,3.08,4.0,3.5,3.8,4.0,3.5,4.0,4.0,3.8,2.5,4.0,3.84,3.5,4.0,4.0,4.0,4.0,4.0,3.9,3.9,4.0,4.0,4.0,3.0,4.0,3.88,3.8,4.0,3.7,4.0,3.4,3.5,4.0,3.6,4.0,4.0,4.0,3.7,3.15,4.0,3.3,4.0,4.0,2.8,4.0,3.5,3.77,4.0,4.0,3.71,4.0,3.2,3.3,4.0,3.7,3.0,4.0,4.0,4.0,4.0,3.5,2.45,2.0,4.0,4.0,4.0,3.8,3.75,3.5,3.0,4.0,4.0,3.5,4.0,3.9,3.7,3.98,3.67,3.62,3.33,3.61,4.0,3.8,4.0,3.0,4.0,3.0,4.0,4.0,4.0,3.81,3.92,4.0,2.5,4.0,3.63,3.2,3.2,3.5,3.8,4.0,3.0,3.9,3.1,3.9,3.7,3.34,3.9,2.97,3.7,2.8,3.2,4.0,4.0,3.5,3.12,4.0,4.0,3.8,4.0,3.64,2.0,3.8,4.0,3.0,3.4,4.0,4.0,4.0,4.0,4.0,3.8,3.5,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.3,3.0,4.0,3.95,4.0,3.5,4.0,3.0,3.5,4.0,4.0,4.0,4.0,4.0,4.0,3.57,4.0,3.17,3.3,4.0,3.94,3.8,4.0,2.8,4.0,4.0,3.0,4.0,3.77,4.0,3.0,3.6,4.0,4.0,4.0,4.0,4.0,4.0,3.5,3.83,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.0,4.0,3.7,3.9,3.04,3.5,3.5,4.0,4.0,3.45,3.9,3.7,3.7,3.4,4.0,3.5,3.9,3.5,3.87,2.0,3.8,4.0,2.9,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.8,3.8,4.0,3.78,3.0,3.6,4.0,3.0,4.0,3.8,4.0,3.3,3.64,4.0,3.5,3.6,3.3,3.83,3.6,3.75,3.5,3.5,3.97,4.0,3.93,3.5,4.0,4.0,3.8,1.0,3.5,4.0,3.55,3.3,4.0,4.0,3.85,3.82,3.96,3.53,3.2,3.7,4.0,4.0,3.0,3.5,1.9,3.48,3.7,3.8,3.5,3.2,3.4,4.0,3.5,3.54,4.0,3.36,3.49,3.15,3.8,3.8,3.0,3.5,4.0,3.79,4.0,3.7,3.85,4.0,4.0,3.98,4.0,3.66,3.84,3.84,3.76,2.94,3.6,4.0,3.6,4.0,3.61,3.91,2.8,3.46,3.94,3.03,3.33,2.8,3.6,3.5,3.2,3.2,3.89,3.43,3.8,3.6,3.92,3.95,3.3,3.71,3.6,3.1,3.0,3.2,3.75,3.3,3.01,2.82,3.4,3.5,3.1,3.5,3.41,3.68,2.8,2.8,4.0,3.8,3.2,3.33,3.0,3.02,2.69,3.2,2.6,3.8,3.18,3.44,3.2,3.5,3.1,3.3,3.2,3.06,2.8,3.4,3.8,2.67,3.38,3.8,3.334,3.78,3.7,2.6,2.3,3.5,2.7,3.4,3.912,3.76,3.2,3.7,3.2,3.22,3.4,4.0,2.99,3.7,3.5,3.8,3.2,3.8,4.0,3.0,3.5,3.55,2.9,2.74,3.34,3.0,3.3,2.81,2.81,3.73,3.65,2.8,3.6,3.7,3.9,2.4,3.48,3.2,3.7,3.3,3.43,2.9,3.29,3.0,2.51,3.0,3.5,3.92,3.8,3.36,3.07,3.03,3.6,3.95,3.42,3.57,1.6,3.21,2.6,2.7,2.8,3.93,3.8,3.9,3.0,3.7,3.8,2.88,3.7,3.95,3.76,3.72,4.0,3.25,3.1,3.6,3.41,3.5,3.6,3.25,3.1,3.91,2.6,4.0,3.4,3.8,3.4,3.0,3.3,3.0,3.0,3.26,3.2,3.94,3.333,4.0,3.0,4.0,3.9,3.4,3.65,3.74,3.5,3.1,3.42,3.52,3.0,3.6,3.8,3.92,3.1,2.81,3.05,3.7,4.0,2.86,2.8,3.89,2.8,4.0,3.62,3.54,3.44,2.7,3.0,3.14,2.9,3.5,3.2,3.3,3.2,3.8,3.2,4.0,3.25,4.0,3.5,3.94,4.0,3.2,2.0,2.91,3.44,3.27,3.8,3.92,4.0,3.7,2.57,3.4,4.0,3.1,3.8,3.8,3.8,3.69,3.92,3.0,2.8,3.4,3.67,3.0,3.65,3.0,3.0,4.0,3.3,3.8,3.79,3.87,3.2,3.67,3.0,4.0,4.0,3.36,3.7,3.98,4.0,3.65,3.3,3.2,3.1,2.6,3.8,3.8,4.0,3.8,3.85,3.2,3.5,3.73,3.5,3.19,3.78,3.66,3.52,4.0,4.0,3.6,2.5,3.71,1.9,3.66,3.87,3.4,2.75,3.3,2.8,3.4,3.94,4.0,3.89,3.1,2.95,3.4,3.69,3.87,3.8,3.62,3.1,3.56,3.2,3.5,3.3,2.0,3.0,3.5,2.98,3.0,3.2,3.8,3.7,3.8,3.84,3.3,3.29,3.86,3.2,3.5,3.6,3.2,3.0,3.1,3.02,3.0,4.0,3.5,3.81,4.0,3.3,3.85,3.6,3.5,3.2,3.64,3.66,3.51,3.91,3.98,3.1,3.4,3.0,3.2,4.0,2.9,2.1,3.5,3.77,2.6,1.69,3.5,3.0,3.32,4.0,3.0,3.52,2.6,2.1,3.64,3.6,3.91,3.56,2.01,3.5,3.3,2.7,3.6,3.1,3.75,3.0,3.4,2.49,3.03,3.4,3.38,3.0,4.0,3.2,3.18,3.66,3.61,3.86,3.9,3.15,3.2,4.0,3.2,3.6,3.79,2.85,3.22,3.53,3.8,3.9,2.98,3.66,3.78,3.7,3.2,3.68,2.73,3.8,2.95,3.95,3.9,3.2,3.1,3.07,3.95,3.7,3.0,2.57,3.5,3.75,3.57,2.7,3.4,3.2,3.1,3.36,3.0,3.2,3.01,3.65,3.3,3.34,3.33,3.7,4.0,3.3,3.14,3.3,3.0,3.95,3.33,2.83,3.23,2.9,2.96,3.3,3.35,3.0,3.18,3.11,3.31,3.3,3.36,3.0,3.9,3.12,3.7,2.72,3.26,2.02,3.4,3.1,3.3,1.5,2.28,3.93,3.7,3.4,3.8,3.91,2.8,3.0,3.6,2.6,3.35,2.74,3.24,3.78,3.67,3.9,4.0,2.44,3.93,3.9,2.9,3.47,3.95,3.9,3.67,2.83,3.79,3.67,3.47,3.5,3.26,3.76,3.6,3.5,3.7,2.7,2.8,3.9,3.5,3.6,4.0,3.1,3.9,4.0,3.98,3.16,3.47,3.3,3.67,2.8,3.47,3.19,3.65,3.5,4.0,2.83,3.8,3.67,3.8,3.93,2.95,2.99,3.02,3.8,3.4,2.69,3.845,3.95,3.57,2.9,3.8,3.86,3.77,3.0,3.8,3.68,3.9,3.25,3.75,3.2,3.9,3.1,3.5,3.87,3.4,3.8,3.96,3.8,3.43,3.7,3.2,4.0,4.0,3.6,3.93,3.46,3.67,3.2,3.18,3.38,3.82,3.91,4.0,3.92,4.0,4.0,3.4,2.57,2.89,2.7,2.89,3.5,4.0,3.44,4.0,3.98,3.98,3.98,3.04,3.73,3.5,3.3,3.8,3.7,2.88,3.9,3.7,3.9,2.53,4.0,3.2,3.2,2.8,3.45,3.84,2.6,3.7,4.0,3.02,3.6,3.1,3.8,3.76,3.97,3.74,2.99,3.68,3.3,3.7,3.25,3.84,3.7,2.9,4.0,3.47,3.06,3.75,3.66,3.0,3.42,3.96,3.2,3.9,3.1,3.6,3.91,3.4,3.02,3.92,3.75,3.74,3.23,3.95,4.0,3.59,3.1,3.0,4.0,3.8,3.5,2.97,2.97,3.2,2.87,3.45,3.32,3.4,1.0,3.75,3.5,3.23,3.0,2.6,3.75,3.5,2.5,2.56,4.0,3.88,3.1,3.49,2.8,3.35,3.5,3.98,4.0,3.9,3.83,2.2,3.96,3.8,2.0,4.0,3.4,3.12,3.42,3.2,3.2,2.9,3.32,3.3,4.0,4.0,3.25,4.0,2.5,3.9,3.5,3.27,3.8,2.4,4.0,3.71,3.9,3.81,3.62,3.94,4.0,4.0,2.9,3.65,2.4,3.75,3.33,3.8,3.94,3.5,3.85,3.62,2.94,3.96,3.75,3.55,3.98,4.0,4.0,3.64,3.6,2.9,3.25,3.5,3.66,3.1,3.83,3.29,4.0,2.57,3.55,3.54,3.0,3.96,3.6,2.91,2.64,2.8,3.9,2.8,3.84,2.5,3.77,3.5,3.8,3.96,4.0,3.2,3.0,3.0,2.88,3.95,3.0,3.69,3.2,2.6,1.9,3.6,3.5,3.5,3.5,3.96,3.0,3.5,2.84,3.49,4.0,4.0,4.0,2.6,2.6,4.0,3.2,2.85,3.33,3.92,3.98,3.66,3.3,3.9,3.5,4.0,3.1,4.0,3.08,3.7,4.0,2.3,4.0,3.8,3.1,4.0,4.0,3.8,4.0,3.75,3.0,3.4,4.0,3.8,3.79,2.71,3.8,4.0,3.7,3.83,3.7,3.91,4.0,4.0,3.96,3.97,3.3,3.5,3.95,3.77,3.8,3.6,3.5,3.8,4.0,4.0,3.8,4.0,3.8,3.7,4.0,3.38,3.32,3.6,3.6,3.7,3.36,3.67,4.0,3.67,3.01,3.92,3.3,3.7,3.27,3.59,3.5,2.8,3.96,2.8,4.0,3.9,3.6,3.33,3.69,3.86,3.0,3.64,3.76,3.9,3.0,3.6,3.76,3.2,3.2,3.54,3.6,4.0,4.0,3.2,3.5,3.5,3.84,3.7,3.4,4.0,3.2,4.0,3.41,4.0,3.7,3.9,3.8,3.8,3.5,1.0,3.8,4.0,3.8,4.0,3.3,3.97,3.6,3.3,3.94,3.9,3.9,3.69,3.8,3.5,4.0,4.0,3.2,3.6,2.9,3.53,2.5,3.24,4.0,3.2,3.0,3.0,3.5,3.6,3.9,3.43,3.86,3.4,3.8,3.6,4.0,3.9,3.7,3.6,3.5,3.76,3.17,3.3,4.0,2.9,3.8,3.6,4.0,3.4,2.84,3.5,3.4,4.0,3.3,3.86,3.5,4.0,3.95,3.5,3.5,3.04,2.8,4.0,3.9,3.76,3.45,3.6,2.8,2.81,3.1,4.0,3.9,3.69,3.0,3.8,2.97,3.7,4.0,3.46,2.9,3.5,2.0,3.1,4.0,3.6,4.0,3.5,3.62,3.4,4.0,4.0,3.6,4.0,3.7,3.6,3.04,4.0,3.33,3.6,4.0,3.0,3.49,3.5,2.16,3.03,2.4,4.0,3.5,2.5,3.34,3.4,4.0,3.5,3.33,3.1,3.85,3.9,3.8,3.5,3.7,3.0,3.7,3.33,3.7,2.83,3.0,3.2,3.1,3.0,3.97,3.0,3.51,3.5,3.6,4.0,4.0,4.0,3.97,2.8,3.8,3.41,4.0,4.0,4.0,3.81,3.92,3.7,2.3,3.64,4.0,3.5,3.44,3.92,2.9,3.04,4.0,3.48,3.5,3.5,3.3,3.5,3.95,4.0,3.65,3.7,3.78,2.3,2.5,3.4,3.8,3.7,3.7,4.0,3.7,2.88,3.64,3.74,3.0,3.97,2.3,4.0,2.7,3.4,3.77,3.69,3.9,3.56,3.66,3.75,3.6,3.95,2.9,3.8,2.45,3.4,4.0,3.94,3.2,3.89,3.87,3.7,3.5,3.88,3.9,3.9,2.5,3.8,3.35,3.15,3.18,4.0,3.63,3.2,3.57,4.0,2.87,3.7,3.2,3.93,4.0,3.6,3.5,3.78,3.97,3.4,3.2,3.23,3.5,3.2,3.2,3.8,3.8,4.0,3.81,3.27,3.38,4.0,3.2,3.8,3.7,3.4,4.0,3.8,3.64,3.46,4.0,3.5,3.6,3.0,3.7,3.81,3.9,3.0,3.0,3.44,3.0,3.9,2.95,3.9,3.5,3.8,4.0,3.6,3.96,3.4,3.93,3.5,3.7,4.0,3.97,3.6,3.02,3.96,4.0,3.6,3.7,3.8,3.83,3.8,3.33,3.95,3.94,3.3,1.9,3.67,3.93,3.0,3.66,3.85,3.2,3.79,3.95,2.75,3.4,3.46,3.59,3.56,3.75,4.0,3.5,3.3,3.6,3.9,3.97,2.85,4.0,4.0,3.5,4.0,4.0,3.9,4.0,3.7,3.6,3.64,2.9,2.31,3.0,3.5,3.22,3.13,4.0,3.95,3.79,4.0,3.8,4.0,3.6,3.33,3.6,3.8,3.95,3.3,3.25,3.2,3.6,3.0,1.14,3.56,3.5,3.76,3.8,3.1,4.0,3.8,3.01,3.98,3.6,3.9,3.78,3.3,3.04,3.38,3.27,3.4,2.5,2.7,3.5,3.9,3.85,3.9,3.6,3.82,4.0,3.1,3.0,3.83,3.5,3.1,3.7,3.9,3.98,3.6,3.91,3.4,3.8,3.5,3.2,3.45,3.76,3.6,3.6,3.4,3.5,3.49,3.7,3.5,2.8,3.9,3.2,3.2,4.0,3.49,3.1,3.22,3.7,3.03,3.6,3.85,3.3,3.94,3.0,4.0,3.8,2.0,3.9,3.8,3.49,4.0,2.9,3.01,3.4,3.8,3.75,3.0,3.97,3.2,2.69,3.82,2.61,3.0,4.0,1.9,3.5,2.5,3.75,3.77,3.1,3.0,2.71,3.73,3.55,3.58,3.95,3.3,3.5,2.1,3.95,3.39,3.1,3.6,3.47,2.9,2.6,3.0,3.44,3.81,3.5,2.7,3.39,2.78,3.5,3.8,3.3,3.8,3.28,3.87,2.99,3.23,3.75,3.94,3.5,2.8,4.0,3.4,3.25,3.5,3.83,3.0,3.79,3.54,3.76,4.0,3.73,3.3,4.0,3.95,3.0,3.0,3.8,3.3,2.5,3.5,3.57,3.0,3.6,3.6,3.2,2.3,3.7,4.0,3.89,3.5,3.2,3.21,3.89,4.0,2.8,3.2,4.0,3.56,3.3,3.0,3.77,3.7,2.84,3.03,4.0,3.7,3.7,3.72,4.0,3.7,3.0,3.6,4.0,2.6,3.75,3.0,3.8,3.74,3.4,3.3,2.9,2.7,2.8,3.8,3.72,3.5,3.92,3.71,3.92,3.91,3.6,3.97,3.6,3.4,3.45,3.68,2.78,2.81,3.97,3.6,4.0,3.3,3.4,3.82,3.72,3.01,4.0,2.34,3.77,3.0,3.0,3.8,3.8,3.8,3.95,3.8,3.41,3.82,4.0,4.0,3.94,3.9,3.89,3.75,3.7,3.4,3.44,3.7,3.95,3.14,3.8,3.89,3.78,3.91,4.0,3.7,4.0,2.8,3.4,3.53,2.89,3.4,3.6,3.37,3.9,4.0,1.0,3.2,3.0,3.81,3.5,3.56,2.9,3.9,3.0,3.93,3.92,3.03,3.7,3.8,3.5,4.0,3.4,4.0,3.3,3.3,3.61,3.61,3.61,3.6,3.45,3.4,3.4,3.4,3.4,4.0,4.0,3.95,4.0,4.0,4.0,2.7,3.3,3.3,3.7,4.0,3.4,3.83,3.2,3.25,3.5,3.8,3.93,3.8,3.91,4.0,4.0,3.3,3.1,3.1,4.0,4.0,4.0,3.4,4.0,2.3,3.8,3.8,3.84,3.2,3.89,3.89,2.5,4.0,3.5,3.4,4.0,3.66,3.0,3.0,4.0,3.62,3.8,3.0,3.92,4.0,3.92,3.4,3.73,4.0,4.0,3.86,4.0,4.0,3.34,3.6,2.95,3.88,3.4,3.94,3.75,3.2,3.78,3.0,3.88,3.9,3.9,3.35,3.2,3.3,3.5,3.8,3.4,3.54,3.83,3.83,2.74,3.93,3.6,3.8,3.86,3.78,4.0,4.0,3.6,3.0,4.0,4.0,4.0,4.0,4.0,3.11,1.83,4.0,3.7,3.85,3.37,3.53,3.7,3.7,4.0,3.76,3.32,3.32,3.29,3.98,4.0,3.6,3.2,3.0,3.85,3.96,3.9,3.95,3.95,3.7,3.8,2.17,3.89,3.8,3.85,3.25,3.5,2.6,3.9,3.81,3.81,3.5,3.9,3.7,3.7,3.43,3.6,3.0,4.0,3.8,3.89,3.34,3.55,4.0,4.0,3.19,3.77,3.1,4.0,3.68,3.65,3.3,3.9,2.26,3.68,3.8,3.8,3.8,2.99,3.4,3.8,3.53,3.9,3.2,4.0,3.0,2.7,3.71,3.34,3.5,4.0,4.0,3.88,4.0,3.5,3.5,3.8,3.5,3.5,3.8,3.34,4.0,3.87,3.7,3.0,3.7,4.0,3.7,4.0,3.4,3.4,2.79,3.6,3.73,3.86,3.7,3.6,3.66,3.6,3.7,3.8,3.5,3.7,2.6,3.6,3.98,3.5,4.0,3.2,4.0,3.5,2.9,3.36,3.4,2.94,3.5,3.2,3.75,3.4,3.72,3.9,3.0,3.79,3.79,3.3,4.0,3.4,3.4,2.5,2.5,2.8,3.7,3.0,3.0,4.0,3.86,3.71,3.93,3.71,3.71,2.8,3.4,3.91,3.5,3.66,3.7,3.7,3.72,3.6,2.97,3.2,3.6,3.27,3.56,3.5,3.11,3.11,3.11,3.2,3.9,2.66,3.0,2.0,3.92,3.73,3.85,3.87,3.49,2.8,2.8,3.55,3.34,3.34,3.73,3.3,4.0,3.2,3.15,3.95,3.7,3.5,2.5,3.75,2.4,2.4,3.75,3.3,3.2,2.1,3.6,4.0,4.0,3.02,3.41,3.01,2.35,3.87,3.2,3.2,3.12,4.0,3.4,3.61,3.69,3.7,3.7,3.3,3.4,3.51,3.5,3.4,3.5,3.86,3.4,3.87,3.8,3.8,3.8,3.2,3.5,4.0,3.4,3.2,3.34,4.0,3.5,3.4,2.71,2.0,3.8,3.8,3.57,3.93,3.7,3.7,1.48,3.4,3.6,3.3,3.3,3.5,3.7,4.0,3.69,3.4,2.5,2.92,3.5,3.71,3.0,4.0,3.4,2.89,3.0,3.77,4.0,3.53,3.33,3.57,3.0,3.0,3.88,3.03,3.8,3.7,4.0,3.6,3.8,3.15,3.15,3.8,2.5,3.34,3.34,3.64,2.8,3.91,3.78,3.73,4.0,3.89,4.0,3.9,3.6,3.93,3.69,3.14,4.0,3.85,3.85,3.54,2.7,3.72,3.72,3.54,3.56,3.47,3.7,4.0,2.7,3.2,2.8,3.86,3.68,3.68,4.0,4.0,3.9,3.77,3.68,3.35,3.7,3.76,2.86,3.6,3.93,3.93,3.4,3.99,2.995,3.1,2.62,3.3,3.3,3.3,3.0,2.8,4.0,4.0,3.4,4.0,3.64,2.0,3.7,3.6,3.7,3.4,3.8,3.8,3.71,3.57,3.85,3.1,3.1,3.65,3.0,3.65,3.65,2.0,3.78,3.0,3.7,3.5,3.57,3.57,3.5,3.7,3.3,3.3,3.3,3.66,3.95,3.3,3.79,3.93,3.79,3.9,3.97,3.31,3.31,2.5,2.5,3.89,3.9,3.48,4.0,3.95,3.9,4.0,2.8,3.08,3.8,3.75,3.1,2.7,3.3,3.81,3.68,3.87,3.51,3.6,3.0,2.57,3.81,3.9,4.0,3.94,3.7,3.7,3.4,4.0,3.95,3.7,3.83,2.7,3.8,3.27,3.8,3.5,3.5,3.5,3.88,2.9,2.61,3.6,3.6,3.69,3.3,3.4,2.5,3.88,2.85,2.4,3.98,3.62,3.6,3.7,2.8,4.0,3.8,3.3,2.7,3.27,3.1,3.86,3.3,3.32,3.8,3.6,3.21,2.0,2.6,3.77,3.96,3.33,3.9,2.7,3.87,3.76,3.6,3.37,3.8,3.86,3.83,2.58,3.7,3.18,3.25,3.25,3.3,3.3,3.86,3.3,3.4,3.8,4.0,2.04,2.8,2.04,3.6,3.98,3.73,3.8,2.9,3.48,3.37,3.0,3.42,3.86,3.0,3.0,4.0,4.0,3.5,3.6,2.9,3.0,3.6,3.0,3.8,3.4,3.3,3.58,3.2,4.0,2.83,3.5,3.0,2.4,2.4,3.9,3.75,3.0,3.6,4.0,3.9,2.5,3.3,3.0,3.78,3.0,2.8,2.09,2.7,3.2,3.79,3.2,3.58,2.3,3.4,3.21,3.87,3.21,3.0,3.1,3.7,3.61,3.55,3.89,3.18,3.7,3.7,3.96,3.7,3.0,3.2,3.02,3.02,3.0,3.87,3.29,3.8,3.89,3.02,3.5,3.0,2.88,3.1,3.1,3.32,2.9,3.89,3.47,2.8,3.8,3.3,2.4,3.3,4.0,3.85,3.12,3.2,2.4,3.8,3.8,3.59,3.8,3.65,3.6,3.2,2.8,3.0,3.5,3.82,3.68,3.5,3.7,3.0,2.4,3.02,3.73,3.1,3.45,3.4,2.6,3.78,3.05,3.83,2.76,3.75,2.0,2.85,3.0,3.92,2.4,3.75,3.0,3.91,3.8,3.0,3.2,3.82,4.0,3.0,2.7,3.91,3.68,2.9,3.0,3.58,3.0,3.25,2.3,3.4,2.3,3.25,3.4,3.4,3.25,3.93,2.1,3.93,3.4,3.0,4.0,3.3,3.5,2.7,3.08,3.0,3.8,2.3,3.71,3.5,2.3,2.4,3.68,2.4,3.3,3.92,3.81,3.6,3.82,3.54,3.79,2.88,3.6,2.9,2.8,3.63,3.14,3.2,3.0,3.76,2.66,3.8,3.47,3.1,3.7,2.85,3.75,3.0,1.9,3.2,2.8,3.03,3.24,3.23,3.21,3.48,2.81,3.1,3.17,3.66,3.6,3.2,3.51,3.1,3.2,3.1,3.5,3.47,3.2,3.6,3.0,2.88,2.8,3.51,3.0,3.21,3.16,3.0,3.16,3.2,2.26,2.8,3.7,3.28,3.54,3.01,2.7,3.89,3.85,3.24,3.04,3.2,3.1,2.66,3.97,3.4,3.29,3.18,3.96,2.8,4.0,2.7,4.0,4.0,1.92,2.9,3.7,3.2,3.79,3.01,3.37,3.66,3.2,3.29,4.0,3.8,3.75,3.0,3.0,3.93,3.0,2.8,3.15,3.01,3.4,2.7,3.03,2.9,3.6,3.0,3.62,3.0,3.0,3.2,2.43,3.33,3.31,3.6,3.45,2.95,3.8,3.09,3.1,3.92,3.2,3.3,3.4,3.65,2.89,3.92,3.9,3.1,4.0,3.3,2.6,3.0,3.48,3.7,3.71,3.09,3.3,3.93,4.0,2.5,3.62,3.3,3.95,2.8,3.21,2.65,3.5,3.2,3.9,2.3,3.46,3.21,2.55,3.68,2.94,3.5,3.97,3.58,2.83,3.95,2.65,3.3,3.88,3.65,3.8,3.66,3.3,3.87,2.7,2.7,3.45,3.3,3.7,3.96,3.41,3.08,3.7,3.6,3.0,2.4,4.0,3.2,3.1,3.93,3.1,3.72,3.6,3.73,3.75,3.12,3.2,2.78,3.62,2.8,2.75,3.03,3.78,3.5,3.98,3.21,3.9,3.47,3.8,2.9,3.86,3.65,2.83,3.52,3.0,2.5,3.54,3.09,3.67,3.32,3.06,3.69,3.95,2.48,3.68,3.16,3.56,2.9,3.0,3.58,3.18,3.5,3.79,3.77,4.0,3.38,3.41,3.92,3.42,3.61,2.9,3.89,3.0,3.57,3.86,3.4,3.4,4.0,3.09,3.0,3.4,3.68,3.18,3.47,3.14,3.6,4.0,3.5,3.35,3.41,3.81,3.47,2.8,3.7,3.0,3.45,3.55,3.79,2.8,3.2,3.1,3.82,2.89,3.4,3.83,3.8,3.62,4.0,3.45,3.93,2.5,2.9,3.6,3.2,3.45,2.7,3.45,3.9,3.85,2.82,3.92,3.3,3.7,3.81,3.8,3.8,3.88,3.75,3.58,2.7,3.6,3.84,2.0,3.1,3.15,2.9,3.4,3.88,3.39,3.24,3.77,3.67,3.13,3.7,3.1,2.89,4.0,3.74,3.36,3.1,3.78,3.4,3.3,2.69,3.63,3.72,3.89,3.76,3.91,3.95,2.75,3.0,3.01,3.05,3.4,3.99,3.86,2.4,2.33,3.62,3.59,3.23,3.13,3.65,2.65,3.58,3.72,3.5,3.89,3.8,3.0,3.6,2.8,3.78,3.85,2.92,2.97,3.12,3.01,3.9,3.23,3.08,3.42,3.58,3.96,3.6,3.6,3.5,4.0,3.9,3.72,3.72,2.96,3.51,3.9,3.5,3.2,4.0,3.8,3.76,4.0,3.13,3.91,3.98,3.41,3.2,3.45,2.9,2.5,3.85,3.92,3.63,3.96,2.8,3.6,3.96,3.96,3.4,3.2,3.5,3.5,3.94,1.76,3.3,2.64,3.0,3.78,3.67,3.9,4.0,2.44,3.93,3.9,2.9,3.47,3.95,3.9,3.67,2.83,3.79,3.67,3.47,3.5,3.26,3.76,3.6,3.5,3.7,2.7,2.8,3.9,3.5,3.6,4.0,3.1,3.9,4.0,3.98,3.16,3.47,3.3,3.67,2.8,3.47,3.19,3.65,3.5,4.0,2.83,3.8,3.67,3.8,3.93,2.95,2.99,3.02,3.8,3.4,2.69,3.845,3.95,3.57,2.9,3.8,3.86,3.77,3.0,3.8,3.68,3.9,3.25,3.75,3.2,3.9,3.1,3.5,3.87,3.4,3.8,3.96,3.8,3.43,3.7,3.2,4.0,4.0,3.6,3.93,3.46,3.67,3.2,3.18,3.38,3.82,3.4,3.92,3.1,3.79,3.9,3.94,3.97,3.33,3.7,3.47,4.0,3.6,3.08,4.0,3.5,3.8,4.0,3.5,4.0,4.0,3.8,2.5,4.0,3.84,3.5,4.0,4.0,4.0,4.0,4.0,3.9,3.9,4.0,4.0,4.0,3.0,4.0,3.88,3.8,4.0,3.7,4.0,3.4,3.5,4.0,3.6,4.0,4.0,4.0,3.7,3.15,4.0,3.3,4.0,4.0,2.8,4.0,3.5,3.77,4.0,4.0,3.71,4.0,3.2,3.3,4.0,3.7,3.0,4.0,4.0,4.0,4.0,3.5,2.45,2.0,4.0,4.0,4.0,3.8,3.75,3.5,3.0,4.0,4.0,3.5,4.0,3.9,3.7,3.98,3.67,3.62,3.33,3.61,4.0,3.8,4.0,3.0,4.0,3.0,4.0,4.0,4.0,3.81,3.92,4.0,2.5,4.0,3.63,3.2,3.2,3.5,3.8,4.0,3.0,3.9,3.1,3.9,3.7,3.34,3.9,2.97,3.7,2.8,3.2,4.0,4.0,3.5,3.12,4.0,4.0,3.8,4.0,3.64,2.0,3.8,4.0,3.0,3.4,4.0,4.0,4.0,4.0,4.0,3.8,3.5,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.3,3.0,4.0,3.95,4.0,3.5,4.0,3.0,3.5,4.0,4.0,4.0,4.0,4.0,4.0,3.57,4.0,3.17,3.3,4.0,3.94,3.8,4.0,2.8,4.0,4.0,3.0,4.0,3.77,4.0,3.0,3.6,4.0,4.0,4.0,4.0,4.0,4.0,3.5,3.83,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.0,4.0,3.7,3.9,3.04,3.5,3.5,4.0,4.0,3.45,3.9,3.7,3.7,3.4,4.0,3.5,3.9,3.5,3.87,2.0,3.8,4.0,2.9,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.8,3.8,4.0,3.78,3.0,3.6,4.0,3.0,4.0,3.8,4.0,3.3,3.64,4.0,3.5,3.6,3.3,3.83,3.6,3.75,3.5,3.5,3.97,4.0,3.93,3.5,4.0,4.0,3.8,1.0,3.5,4.0,3.55,3.3,4.0,4.0,3.85,3.82,3.96,3.53,3.2,3.7,4.0,4.0,3.0,3.5,1.9,3.48,3.7,3.8,3.5,3.2,3.4,4.0,3.5,3.54,4.0,3.36,3.49,3.15,3.8,3.8,3.0,3.5,4.0,3.79,4.0,3.7,3.85,4.0,4.0,3.98,4.0,3.66,3.84,3.84,3.76,2.94,3.6,4.0,3.6,4.0,3.61,3.91,2.8,3.46,3.94,3.03,3.33,2.8,3.6,3.5,3.2,3.2,3.89,3.43,3.8,3.6,3.92,3.95,3.3,3.71,3.6,3.1,3.0,3.2,3.75,3.3,3.01,2.82,3.4,3.5,3.1,3.5,3.41,3.68,2.8,2.8,4.0,3.8,3.2,3.33,3.0,3.02,2.69,3.2,2.6,3.8,3.18,3.44,3.2,3.5,3.1,3.3,3.2,3.06,2.8,3.4,3.8,2.67,3.38,3.8,3.334,3.78,3.7,2.6,2.3,3.5,2.7,3.4,3.912,3.76,3.2,3.7,3.2,3.22,3.4,4.0,2.99,3.7,3.5,3.8,3.2,3.8,4.0,3.0,3.5,3.55,2.9,2.74,3.34,3.0,3.3,2.81,2.81,3.73,3.65,2.8,3.6,3.7,3.9,2.4,3.48,3.2,3.7,3.3,3.43,2.9,3.29,3.0,2.51,3.0,3.5,3.92,3.8,3.36,3.07,3.03,3.6,3.95,3.42,3.57,1.6,3.21,2.6,2.7,2.8,3.93,3.8,3.9,3.0,3.7,3.8,2.88,3.7,3.95,3.76,3.72,4.0,3.25,3.1,3.6,3.41,3.5,3.6,3.25,3.1,3.91,2.6,4.0,3.4,3.8,3.4,3.0,3.3,3.0,3.0,3.26,3.2,3.94,3.333,4.0,3.0,4.0,3.9,3.4,3.65,3.74,3.5,3.1,3.42,3.52,3.0,3.6,3.8,3.92,3.1,2.81,3.05,3.7,4.0,2.86,2.8,3.89,2.8,4.0,3.62,3.54,3.44,2.7,3.0,3.14,2.9,3.5,3.2,3.3,3.2,3.8,3.2,4.0,3.25,4.0,3.5,3.94,4.0,3.2,2.0,2.91,3.44,3.27,3.8,3.92,4.0,3.7,2.57,3.4,4.0,3.1,3.8,3.8,3.8,3.69,3.92,3.0,2.8,3.4,3.67,3.0,3.65,3.0,3.0,4.0,3.3,3.8,3.79,3.87,3.2,3.67,3.0,4.0,4.0,3.36,3.7,3.98,4.0,3.65,3.3,3.2,3.1,2.6,3.8,3.8,4.0,3.8,3.85,3.2,3.5,3.73,3.5,3.19,3.78,3.66,3.52,4.0,4.0,3.6,2.5,3.71,1.9,3.66,3.87,3.4,2.75,3.3,2.8,3.4,3.94,4.0,3.89,3.1,2.95,3.4,3.69,3.87,3.8,3.62,3.1,3.56,3.2,3.5,3.3,2.0,3.0,3.5,2.98,3.0,3.2,3.8,3.7,3.8,3.84,3.3,3.29,3.86,3.2,3.5,3.6,3.2,3.0,3.1,3.02,3.0,4.0,3.5,3.81,4.0,3.3,3.85,3.6,3.5,3.2,3.64,3.66,3.51,3.91,3.98,3.1,3.4,3.0,3.2,4.0,2.9,2.1,3.5,3.77,2.6,1.69,3.5,3.0,3.32,4.0,3.0,3.52,2.6,2.1,3.64,3.6,3.91,3.56,2.01,3.5,3.3,2.7,3.6,3.1,3.75,3.0,3.4,2.49,3.03,3.4,3.38,3.0,4.0,3.2,3.18,3.66,3.61,3.86,3.9,3.15,3.2,4.0,3.2,3.6,3.79,2.85,3.22,3.53,3.8,3.9,2.98,3.66,3.78,3.7,3.2,3.68,2.73,3.8,2.95,3.95,3.9,3.2,3.1,3.07,3.95,3.7,3.0,2.57,3.5,3.75,3.57,2.7,3.4,3.2,3.1,3.36,3.0,3.2,3.01,3.65,3.3,3.34,3.33,3.7,4.0,3.3,3.14,3.3,3.0,3.95,3.33,2.83,3.23,2.9,2.96,3.3,3.35,3.0,3.18,3.11,3.31,3.3,3.36,3.0,3.9,3.12,3.7,2.72,3.26,2.02,3.4,3.1,3.3,1.5,2.28,3.93,3.7,3.4,3.8,3.91,2.8,3.0,3.6,2.6,3.35,2.74,3.24,2.3,3.2,2.9,3.56,3.16,4.0,3.85,2.95,3.89,4.0,3.2,4.0,3.8,3.27,4.0,4.0,3.8,3.55,2.6,3.7,3.9,3.54,4.0,3.3,3.8,3.93,3.5,2.49,3.3,4.0,4.0,3.7,3.12,3.56,3.3,3.47,3.1,3.4,4.0,3.61,4.0,3.9,3.6,4.0,4.0,4.0,3.019,4.0,3.8,3.36,3.1,3.7,4.0,4.0,3.77,4.0,4.0,3.16,3.6,3.61,3.85,4.0,4.0,4.0,3.01,3.05,4.0,3.0,4.0,4.0,4.0,4.0,4.0,4.0,3.79,3.71,3.0,4.0,3.07,4.0,3.95,3.0,4.0,4.0,3.7,3.6,3.98,3.3,3.39,4.0,3.42,3.86,4.0,3.0,4.0,3.07,3.63,3.11,3.48,3.8,3.85,4.0,4.0,3.7,3.8,3.73,4.0,3.73,3.39,3.8,3.87,3.27,4.0,3.93,3.78,3.33,3.56,3.88,3.5,4.0,2.25,4.0,3.5,3.97,3.5,3.4,2.38,3.5,2.86,2.8,3.14,3.79,2.92,4.0,4.0,3.99,4.0,3.73,3.8,2.7,3.93,3.2,2.7,3.09,4.0,4.0,3.56,3.85,2.68,3.91,3.2,3.4,3.8,3.73,3.41,2.58,3.67,3.7,3.25,4.0,2.91,3.0,4.0,2.58,4.0,4.0,4.0,3.5,3.5,3.55,4.0,3.4,3.5,3.4,3.4,2.43,3.32,4.0,3.66,3.0,2.9,3.64,3.75,3.2,3.0,2.49,3.31,3.25,3.0,3.06,3.8,3.07,4.0,3.3,3.22,4.0,3.98,3.9,3.69,3.5,3.6,4.0,4.0,3.57,3.16,3.17,4.0,4.0,3.0,3.0,3.2,3.3,3.7,3.3,3.77,3.77,3.8,3.1,2.99,2.9,3.5,4.0,4.0,3.5,4.0,4.0,3.3,3.4,4.0,4.0,4.0,3.3,4.0,4.0,3.3,4.0,3.04,3.25,3.8,3.68,4.0,3.5,4.0,3.14,4.0,4.0,3.2,3.92,3.61,3.31,3.03,4.0,4.0,3.25,4.0,3.4,3.88,3.09,3.5,4.0,3.5,3.4,3.7,3.5,3.47,3.2,4.0,3.5,3.7,4.0,3.7,2.77,3.01,3.08,4.0,3.81,3.4,4.0,3.79,3.9,2.99,3.67,3.0,4.0,3.9,3.83,4.0,3.4,3.6,4.0,3.66,3.4,4.0,4.0,3.5,3.6,2.69,3.4,4.0,4.0,2.7,3.71,3.56,4.0,3.5,3.51,3.5,3.66,3.6,4.0,4.0,3.7,3.2,2.7,3.5,3.71,2.8,4.0,3.5,3.74,3.33,4.0,3.9,3.88,2.7,3.5,2.76,3.5,3.5,3.0,3.9,3.84,3.92,4.0,4.0,3.5,3.0,4.0,3.49,3.8,4.0,3.7,4.0,4.0,3.5,4.0,4.0,4.0,4.0,3.0,3.3,4.0,3.8,3.94,3.76,4.0,3.8,3.5,4.0,3.35,3.66,3.8,3.0,3.55,3.75,4.0,4.0,3.75,3.75,3.2,3.5,3.02,4.0,3.8,3.81,4.0,2.82,3.6,3.51,3.71,4.0,3.7,3.4,4.0,3.31,3.8,3.72,3.6,4.0,2.69,3.17,4.0,3.8,3.78,4.0,3.54,3.94,3.8,3.88,3.5,4.0,4.0,3.09,3.5,4.0,3.74,4.0,4.0,4.0,3.24,3.8,3.37,3.51,3.77,3.4,3.4,3.0,4.0,4.0,3.37,3.5,3.31,3.69,3.31,4.0,3.6,3.5,3.5,4.0,3.08,3.89,3.29,3.57,2.7,4.0,3.73,4.0,3.89,3.4,4.0,4.0,4.0,3.9,3.7,3.4,3.2,3.5,3.92,3.01,4.0,4.0,3.57,3.42,3.66,3.9,3.8,2.43,3.46,4.0,4.0,3.7,3.4,3.9,2.86,2.95,2.86,2.8,3.55,3.7,3.86,3.67,3.67,3.6,3.79,3.52,2.91,2.71,3.2,3.67,2.99,3.37,4.0,2.5,4.0,2.7,2.9,4.0,4.0,2.67,3.35,4.0,3.0,4.0,3.27,3.99,4.0,3.8,3.3,3.8,4.0,3.8,3.2,3.8,3.87,3.2,3.2,3.0,3.49,3.09,4.0,3.0,3.5,3.08,3.5,3.57,3.8,3.54,3.5,2.67,4.0,4.0,3.4,3.28,3.9,4.0,3.4,4.0,3.7,2.8,3.8,3.58,4.0,3.3,3.3,3.61,3.61,3.61,3.6,3.45,3.4,3.4,3.4,3.4,4.0,4.0,3.95,4.0,4.0,4.0,2.7,3.3,3.3,3.7,4.0,3.4,3.83,3.2,3.25,3.5,3.8,3.93,3.8,3.91,4.0,4.0,3.3,3.1,3.1,4.0,4.0,4.0,3.4,4.0,2.3,3.8,3.8,3.84,3.2,3.89,3.89,2.5,4.0,3.5,3.4,4.0,3.66,3.0,3.0,4.0,3.62,3.8,3.0,3.92,4.0,3.92,3.4,3.73,4.0,4.0,3.86,4.0,4.0,3.34,3.6,2.95,3.88,3.4,3.94,3.75,3.2,3.78,3.0,3.88,3.9,3.9,3.35,3.2,3.3,3.5,3.8,3.4,3.54,3.83,3.83,2.74,3.93,3.6,3.8,3.86,3.78,4.0,4.0,3.6,3.0,4.0,4.0,4.0,4.0,4.0,3.11,1.83,4.0,3.7,3.85,3.37,3.53,3.7,3.7,4.0,3.76,3.32,3.32,3.29,3.98,4.0,3.6,3.2,3.0,3.85,3.96,3.9,3.95,3.95,3.7,3.8,2.17,3.89,3.8,3.85,3.25,3.5,2.6,3.9,3.81,3.81,3.5,3.9,3.7,3.7,3.43,3.6,3.0,4.0,3.8,3.89,3.34,3.55,4.0,4.0,3.19,3.77,3.1,4.0,3.68,3.65,3.3,3.9,2.26,3.68,3.8,3.8,3.8,2.99,3.4,3.8,3.53,3.9,3.2,4.0,3.0,2.7,3.71,3.34,3.5,4.0,4.0,3.88,4.0,3.5,3.5,3.8,3.5,3.5,3.8,3.34,4.0,3.87,3.7,3.0,3.7,4.0,3.7,4.0,3.4,3.4,2.79,3.6,3.73,3.86,3.7,3.6,3.66,3.6,3.7,3.8,3.5,3.7,2.6,3.6,3.98,3.5,4.0,3.2,4.0,3.5,2.9,3.36,3.4,2.94,3.5,3.2,3.75,3.4,3.72,3.9,3.0,3.79,3.79,3.3,4.0,3.4,3.4,2.5,2.5,2.8,3.7,3.0,3.0,4.0,3.86,3.71,3.93,3.71,3.71,2.8,3.4,3.91,3.5,3.66,3.7,3.7,3.72,3.6,2.97,3.2,3.6,3.27,3.56,3.5,3.11,3.11,3.11,3.2,3.9,2.66,3.0,2.0,3.92,3.73,3.85,3.87,3.49,2.8,2.8,3.55,3.34,3.34,3.73,3.3,4.0,3.2,3.15,3.95,3.7,3.5,2.5,3.75,2.4,2.4,3.75,3.3,3.2,2.1,3.6,4.0,4.0,3.02,3.41,3.01,2.35,3.87,3.2,3.2,3.12,4.0,3.4,3.61,3.69,3.7,3.7,3.3,3.4,3.51,3.5,3.4,3.5,3.86,3.4,3.87,3.8,3.8,3.8,3.2,3.5,4.0,3.4,3.2,3.34,4.0,3.5,3.4,2.71,2.0,3.8,3.8,3.57,3.93,3.7,3.7,1.48,3.4,3.6,3.3,3.3,3.5,3.7,4.0,3.69,3.4,2.5,2.92,3.5,3.71,3.0,4.0,3.4,2.89,3.0,3.77,4.0,3.53,3.33,3.57,3.0,3.0,3.88,3.03,3.8,3.7,4.0,3.6,3.8,3.15,3.15,3.8,2.5,3.34,3.34,3.64,2.8,3.91,3.78,3.73,4.0,3.89,4.0,3.9,3.6,3.93,3.69,3.14,4.0,3.85,3.85,3.54,2.7,3.72,3.72,3.54,3.56,3.47,3.7,4.0,2.7,3.2,2.8,3.86,3.68,3.68,4.0,4.0,3.9,3.77,3.68,3.35,3.7,3.76,2.86,3.6,3.93,3.93,3.4,3.99,2.995,3.1,2.62,3.3,3.3,3.3,3.0,2.8,4.0,4.0,3.4,4.0,3.64,2.0,3.7,3.6,3.7,3.4,3.8,3.8,3.71,3.57,3.85,3.1,3.1,3.65,3.0,3.65,3.65,2.0,3.78,3.0,3.7,3.5,3.57,3.57,3.5,3.7,3.3,3.3,3.3,3.66,3.95,3.3,3.79,3.93,3.79,3.9,3.97,3.31,3.31,2.5,2.5,3.89,3.9,3.48,4.0,3.95,3.9,4.0,2.8,3.08,3.8,3.75,3.1,2.7,3.3,3.81,3.68,3.87,3.51,3.6,3.0,2.57,3.81,3.9,4.0,3.94,3.7,3.7,3.4,4.0,3.95,3.7,3.83,2.7,3.8,3.27,3.8,3.5,3.5,3.5,3.88,2.9,2.61,3.6,3.6,3.69,3.3,3.4,2.5,3.88,2.85,2.4,3.98,3.62,3.6,3.7,2.8,4.0,3.8,3.3,2.7,3.27,3.1,3.86,3.3,3.32,3.8,3.6,3.21,2.0,2.6,3.77,3.96,3.33,3.9,2.7,3.87,3.76,3.6,3.37,3.8,3.86,3.83,2.58,3.7,3.18,3.25,3.25,3.3,3.3,3.86,3.3,3.4,3.8,4.0,2.04,2.8,2.04,3.6,3.98,3.73,3.8,2.9,3.48,3.37,3.0,3.42,3.86,3.0,3.0,4.0,4.0,3.5,3.6,2.9,3.0,3.6,3.0,3.8,3.4,3.3,3.58,3.2,4.0,2.83,3.5,3.0,2.4,2.4,3.9,3.75,3.0,3.6,4.0,3.9,2.5,3.3,3.0,3.78,3.0,2.8,2.09,2.7,3.2,3.79,3.2,3.58,2.3,3.4,3.21,3.87,3.21,3.0,3.1,3.7,3.61,3.55,3.89,3.18,3.7,3.7,3.96,3.7,3.0,3.2,3.02,3.02,3.0,3.87,3.29,3.8,3.89,3.02,3.5,3.0,2.88,3.1,3.1,3.32,2.9,3.89,3.47,2.8,3.8,3.3,2.4,3.3,4.0,3.85,3.12,3.2,2.4,3.8,3.8,3.59,3.8,3.65,3.6,3.2,2.8,3.0,3.5,3.82,3.68,3.5,3.7,3.0,2.4,3.02,3.73,3.1,3.45,3.4,2.6,3.78,3.05,3.83,2.76,3.75,2.0,2.85,3.0,3.92,2.4,3.75,3.0,3.91,3.8,3.0,3.2,3.82,4.0,3.0,2.7,3.91,3.68,2.9,3.0,3.58,3.0,3.25,2.3,3.4,2.3,3.25,3.4,3.4,3.25,3.93,2.1,3.93,3.4,3.0,4.0,3.3,3.5,2.7,3.08,3.0,3.8,2.3,3.71,3.5,2.3,2.4,3.68,2.4,3.3,3.92,3.81,3.91,4.0,3.92,4.0,4.0,3.4,2.57,2.89,2.7,2.89,3.5,4.0,3.44,4.0,3.98,3.98,3.98,3.04,3.73,3.5,3.3,3.8,3.7,2.88,3.9,3.7,3.9,2.53,4.0,3.2,3.2,2.8,3.45,3.84,2.6,3.7,4.0,3.02,3.6,3.1,3.8,3.76,3.97,3.74,2.99,3.68,3.3,3.7,3.25,3.84,3.7,2.9,4.0,3.47,3.06,3.75,3.66,3.0,3.42,3.96,3.2,3.9,3.1,3.6,3.91,3.4,3.02,3.92,3.75,3.74,3.23,3.95,4.0,3.59,3.1,3.0,4.0,3.8,3.5,2.97,2.97,3.2,2.87,3.45,3.32,3.4,1.0,3.75,3.5,3.23,3.0,2.6,3.75,3.5,2.5,2.56,4.0,3.88,3.1,3.49,2.8,3.35,3.5,3.98,4.0,3.9,3.83,2.2,3.96,3.8,2.0,4.0,3.4,3.12,3.42,3.2,3.2,2.9,3.32,3.3,4.0,4.0,3.25,4.0,2.5,3.9,3.5,3.27,3.8,2.4,4.0,3.71,3.9,3.81,3.62,3.94,4.0,4.0,2.9,3.65,2.4,3.75,3.33,3.8,3.94,3.5,3.85,3.62,2.94,3.96,3.75,3.55,3.98,4.0,4.0,3.64,3.6,2.9,3.25,3.5,3.66,3.1,3.83,3.29,4.0,2.57,3.55,3.54,3.0,3.96,3.6,2.91,2.64,2.8,3.9,2.8,3.84,2.5,3.77,3.5,3.8,3.96,4.0,3.2,3.0,3.0,2.88,3.95,3.0,3.69,3.2,2.6,1.9,3.6,3.5,3.5,3.5,3.96,3.0,3.5,2.84,3.49,4.0,4.0,4.0,2.6,2.6,4.0,3.2,2.85,3.33,3.92,3.98,3.66,3.3,3.9,3.5,4.0,3.1,4.0,3.08,3.7,4.0,2.3,4.0,3.8,3.1,4.0,4.0,3.8,4.0,3.75,3.0,3.4,4.0,3.8,3.79,2.71,3.8,4.0,3.7,3.83,3.7,3.91,4.0,4.0,3.96,3.97,3.3,3.5,3.95,3.77,3.8,3.6,3.5,3.8,4.0,4.0,3.8,4.0,3.8,3.7,4.0,3.38,3.32,3.6,3.6,3.7,3.36,3.67,4.0,3.67,3.01,3.92,3.3,3.7,3.27,3.59,3.5,2.8,3.96,2.8,4.0,3.9,3.6,3.33,3.69,3.86,3.0,3.64,3.76,3.9,3.0,3.6,3.76,3.2,3.2,3.54,3.6,4.0,4.0,3.2,3.5,3.5,3.84,3.7,3.4,4.0,3.2,4.0,3.41,4.0,3.7,3.9,3.8,3.8,3.5,1.0,3.8,4.0,3.8,4.0,3.3,3.97,3.6,3.3,3.94,3.9,3.9,3.69,3.8,3.5,4.0,4.0,3.2,3.6,2.9,3.53,2.5,3.24,4.0,3.2,3.0,3.0,3.5,3.6,3.9,3.43,3.86,3.4,3.8,3.6,4.0,3.9,3.7,3.6,3.5,3.76,3.17,3.3,4.0,2.9,3.8,3.6,4.0,3.4,2.84,3.5,3.4,4.0,3.3,3.86,3.5,4.0,3.95,3.5,3.5,3.04,2.8,4.0,3.9,3.76,3.45,3.6,2.8,2.81,3.1,4.0,3.9,3.69,3.0,3.8,2.97,3.7,4.0,3.46,2.9,3.5,2.0,3.1,4.0,3.6,4.0,3.5,3.62,3.4,4.0,4.0,3.6,4.0,3.7,3.6,3.04,4.0,3.33,3.6,4.0,3.0,3.49,3.5,2.16,3.03,2.4,4.0,3.5,2.5,3.34,3.4,4.0,3.5,3.33,3.1,3.85,3.9,3.8,3.5,3.7,3.0,3.7,3.33,3.7,2.83,3.0,3.2,3.1,3.0,3.97,3.0,3.51,3.5,3.6,4.0,4.0,4.0,3.97,2.8,3.8,3.41,4.0,4.0,4.0,3.81,3.92,3.7,2.3,3.64,4.0,3.5,3.44,3.92,2.9,3.04,4.0,3.48,3.5,3.5,3.3,3.5,3.95,4.0,3.65,3.7,3.78,2.3,2.5,3.4,3.8,3.7,3.7,4.0,3.7,2.88,3.64,3.74,3.0,3.97,2.3,4.0,2.7,3.4,3.77,3.69,3.9,3.56,3.66,3.75,3.6,3.95,2.9,3.8,2.45,3.4,4.0,3.94,3.2,3.89,3.87,3.7,3.5,3.88,3.9,3.9,2.5,3.8,3.35,3.15,3.18,4.0,3.63,3.2,3.57,4.0,2.87,3.7,3.2,3.93,4.0,3.6,3.5,3.78,3.97,3.4,3.2,3.23,3.5,3.2,3.2,3.8,3.8,4.0,3.81,3.27,3.38,4.0,3.2,3.8,3.7,3.4,4.0,3.8,3.64,3.46,4.0,3.5,3.6,3.0,3.7,3.81,3.9,3.0,3.0,3.44,3.0,3.9,2.95,3.9,3.5,3.8,4.0,3.6,3.96,3.4,3.93,3.5,3.7,4.0,3.97,3.6,3.02,3.96,4.0,3.6,3.7,3.8,3.83,3.8,3.33,3.95,3.94,3.3,1.9,3.67,3.93,3.0,3.66,3.85,3.2,3.79,3.95,2.75,3.4,3.46,3.59,3.56,3.75,4.0,3.5,3.3,3.6,3.9,3.97,2.85,4.0,4.0,3.5,4.0,4.0,3.9,4.0,3.7,3.6,3.64,2.9,2.31,3.0,3.5,3.22,3.13,4.0,3.95,3.79,4.0,3.8,4.0,3.6,3.33,3.6,3.8,3.95,3.3,3.25,3.2,3.6,3.0,1.14,3.56,3.5,3.76,3.8,3.1,4.0,3.8,3.01,3.98,3.6,3.9,3.78,3.3,3.04,3.38,3.27,3.4,2.5,2.7,3.5,3.9,3.85,3.9,3.6,3.82,4.0,3.1,3.0,3.83,3.5,3.1,3.7,3.9,3.98,3.6,3.91,3.4,3.8,3.5,3.2,3.45,3.76,3.6,3.6,3.4,3.5,3.49,3.7,3.5,2.8,3.9,3.2,3.2,4.0,3.49,3.1,3.22,3.7,3.03,3.6,3.85,3.3,3.94,3.0,4.0,3.8,2.0,3.9,3.8,3.49,4.0,2.9,3.01,3.4,3.8,3.75,3.0,3.97,3.2,2.69,3.82,2.61,3.0,4.0,1.9,3.5,2.5,3.75,3.77,3.1,3.0,2.71,3.73,3.55,3.58,3.95,3.3,3.5,2.1,3.95,3.39,3.1,3.6,3.47,2.9,2.6,3.0,3.44,3.81,3.5,2.7,3.39,2.78,3.5,3.8,3.3,3.8,3.28,3.87,2.99,3.23,3.75,3.94,3.5,2.8,4.0,3.4,3.25,3.5,3.83,3.0,3.79,3.54,3.76,4.0,3.73,3.3,4.0,3.95,3.0,3.0,3.8,3.3,2.5,3.5,3.57,3.0,3.6,3.6,3.2,2.3,3.7,4.0,3.89,3.5,3.2,3.21,3.89,4.0,2.8,3.2,4.0,3.56,3.3,3.0,3.77,3.7,2.84,3.03,4.0,3.7,3.7,3.72,4.0,3.7,3.0,3.6,4.0,2.6,3.75,3.0,3.8,3.74,3.4,3.3,2.9,2.7,2.8,3.8,3.72,3.5,3.92,3.71,3.92,3.91,3.6,3.97,3.6,3.4,3.45,3.68,2.78,2.81,3.97,3.6,4.0,3.3,3.4,3.82,3.72,3.01,4.0,2.34,3.77,3.0,3.0,3.8,3.8,3.8,3.95,3.8,3.41,3.82,4.0,4.0,3.94,3.9,3.89,3.75,3.7,3.4,3.44,3.7,3.95,3.14,3.8,3.89,3.78,3.91,4.0,3.7,4.0,2.8,3.4,3.53,2.89,3.4,3.6,3.37,3.9,4.0,1.0,3.2,3.0,3.81,3.5,3.56,2.9,3.9,3.0,3.93,3.92,3.03,3.7,3.8,3.5,4.0,3.4,3.46,3.41,3.86,3.8,3.9,4.0,3.46,3.2,3.85,3.86,3.87,3.83,3.4,3.1,3.46,2.5,3.85,3.33,3.6,3.2,3.5,3.5,1.99,3.5,4.0,3.2,3.6,3.3,2.66,3.89,3.6,2.87,3.33,3.0,3.45,3.7,3.0,4.0,3.84,4.0,3.8,3.14,3.58,3.85,3.6,4.0,3.8,3.2,3.91,3.86,3.15,3.93,4.0,3.75,2.67,3.7,2.6,3.96,2.8,3.3,2.63,4.0,3.5,3.88,3.8,2.69,4.0,3.77,3.5,4.0,3.83,3.95,3.75,2.8,3.76,3.82,3.2,3.6,3.5,3.69,3.66,3.1,3.6,3.1,3.86,3.21,3.4,3.43,4.0,3.52,3.89,3.15,4.0,2.9,3.5,3.0,3.3,4.0,3.5,2.96,3.79,3.2,2.9,3.49,3.9,3.87,3.5,4.0,1.87,2.77,3.7,4.0,3.8,3.2,4.0,3.2,3.92,3.51,3.87,2.88,3.38,3.9,4.0,2.0,3.3,3.61,3.0,3.4,3.0,3.7,3.54,3.02,3.8,3.02,3.2,4.0,3.0,3.4,3.25,3.17,3.0,3.77,3.31,3.8,3.0,3.18,3.8,3.0,3.0,3.94,3.93,3.4,3.5,2.6,3.74,3.5,3.5,3.86,3.25,2.57,4.0,3.8,3.64,3.36,3.0,3.2,3.5,3.8,3.4,3.2,3.6,4.0,3.5,3.0,3.2,3.1,4.0,4.0,3.5,2.8,3.75,3.7,3.61,3.4,3.5,3.39,3.7,3.7,2.99,3.86,3.75,3.5,4.0,3.9,3.2,3.6,3.84,4.0,3.23,3.92,3.1,2.31,3.78,3.85,3.9,3.8,3.0,3.5,3.28,3.84,3.7,3.76,3.0,3.57,3.66,3.5,2.0,2.69,3.9,3.95,3.5,3.29,3.7,3.5,3.4,3.5,3.3,3.8,3.8,3.16,3.0,4.0,2.77,3.95,3.4,3.2,2.97,3.9,3.5,3.93,4.0,3.0,3.7,4.0,3.44,3.7,3.0,3.11,3.4,3.5,3.06,3.3,3.2,3.63,3.6,3.67,3.2,2.9,3.2,3.86,2.9,3.0,3.0,3.2,3.0,3.6,3.85,4.0,3.38,3.2,2.0,4.0,3.9,2.56,4.0,3.05,4.0,3.97,3.65,2.7,2.83,4.0,3.75,2.96,3.33,3.2,3.6,3.6,3.8,2.56,3.3,3.7,2.9,2.87,3.0,3.71,3.6,2.8,2.77,2.16,4.0,3.3,3.47,3.66,3.45,2.5,3.2,2.3,2.9,3.6,3.2,3.4,2.6,3.94,2.98,3.7,3.65,3.0,3.2,3.69,3.28,4.0,3.47,3.94,3.9,3.64,2.56,2.23,3.87,3.79,3.3,4.0,2.89,3.7,2.7,4.0,3.98,2.48,3.68,2.44,4.0,3.92,3.54,4.0,3.1,3.8,3.4,3.8,3.3,4.0,2.3,3.4,3.0,3.45,3.56,3.93,3.8,3.54,4.0,3.53,3.94,3.03,3.0,3.35,3.0,3.8,3.5,2.18,3.83,3.02,3.2,3.86,3.5,3.4,3.8,3.91,4.0,3.9,3.91,3.15,2.9,3.0,3.2,3.86,3.58,3.78,3.0,3.2,2.88,4.0,2.0,3.83,2.53,4.0,2.9,3.85,3.8,2.9,2.22,4.0,3.8,3.6,3.0,3.87,3.0,3.84,3.5,3.4,3.3,3.95,3.06,3.0,3.27,2.8,3.12,3.0,3.66,2.7,3.5,3.4,3.93,3.7,3.7,3.15,3.78,3.3,3.9,4.0,2.8,3.84,2.96,2.64,3.72,3.8,3.3,2.06,3.4,3.28,2.5,3.72,3.67,3.6,3.66,3.94,3.0,4.0,3.2,3.55,3.26,3.0,3.96,3.4,3.83,3.23,3.8,2.8,3.4,3.67,3.0,3.7,3.8,3.2,3.0,3.83,3.6,4.0,3.5,3.47,3.5,3.6,3.35,3.5,3.45,2.0,3.0,3.25,3.69,3.5,3.95,3.97,3.3,3.7,3.5,3.73,3.9,3.1,3.89,3.84,3.89,3.5,3.4,3.7,3.06,3.4,3.7,3.5,3.2,3.25,3.0,3.46,4.0,3.0,2.25,3.8,3.28,2.3,3.93,3.6,3.2,2.2,3.2,3.9,3.33,3.73,2.5,3.65,3.1,2.87,3.92,3.4,3.5,3.13,3.6,3.3,3.56,2.8,2.98,3.78,3.1,3.91,3.0,3.23,3.0,3.3,2.7,3.6,3.64,3.2,3.07,3.7,3.42,3.0,3.0,3.8,2.76,2.8,3.25,3.86,2.1,3.23,3.5,2.0,3.0,3.7,3.8,1.87,3.76,3.93,4.0,2.68,2.79,3.9,2.7,3.94,2.9,2.7,4.0,3.0,3.27,3.4,3.6,3.65,3.89,3.76,2.35,3.65,3.5,3.3,2.8,3.89,2.8,3.0,2.48,3.2,2.78,3.5,3.82,2.56,2.92,2.1,3.8,3.66,3.95,3.9,3.07,3.57,3.41,3.75,3.0,3.3,3.3,4.0,3.3,3.87,2.4,2.1,3.42,3.28,3.07,3.0,2.7,2.94,4.0,3.8,3.65,3.33,2.4,2.8,3.01,3.5,3.3,2.7,3.03,2.8,3.5,3.12,2.78,3.9,3.0,3.6,4.0,3.3,3.3,2.93,3.4,3.69,3.12,2.8,3.0,3.3,3.1,3.5,3.2,3.02,2.5,2.98,3.0,3.05,2.6,4.0,3.0,2.49,3.87,3.6,3.8,3.6,3.29,2.9,2.49,3.5,3.69,4.0,3.89,3.6,3.79,2.13,3.2,3.6,3.0,3.8,3.23,2.8,3.8,3.79,2.7,3.0,3.88,2.75,3.0,2.5,3.82,3.68,3.25,3.2,3.3,2.69,3.3,3.63,3.2,3.3,3.2,3.3,3.73,3.3,3.21,2.7,3.01,2.8,3.2,3.5,3.2,3.64,2.8,1.76,3.5,3.79,3.29,2.8,2.5,3.8,3.84,3.14,3.6,2.9,3.48,3.6,3.8,3.58,3.47,3.3,3.25,3.82,2.9,4.0,3.49,3.2,3.71,3.5,2.8,3.26,3.26,3.4,3.67,2.7,3.5,3.52,3.76,3.54,2.99,3.64,2.9,3.16,3.79,3.3,3.46,2.57,3.07,3.8,3.6,3.0,3.8,3.57,2.9,3.63,3.6,2.94,3.9,2.8,3.95,3.6,2.94,3.98,3.4,3.4,3.81,3.8,3.0,3.2,3.6,2.7,3.2,3.0,3.46,2.4,3.18,3.9,3.2,3.04,3.49,3.0,2.9,3.21,3.98,3.62,3.4,3.35,3.8,3.3,3.7,3.94,3.89,3.47,3.1,3.56,3.2,3.4,2.82,3.15,2.9,3.07,3.2,3.7,2.1,3.7,2.3,3.69,2.75,3.3,3.4,3.4,3.96,3.1,2.98,3.91,3.6,3.71,3.44,3.8,2.6,3.15,3.9,3.92,2.8,2.7,3.8,3.1,3.93,3.3,3.0,3.12,2.93,3.65,3.95,2.77,3.4,2.7,3.3,3.34,3.47,3.92,3.0,3.2,3.35,2.9,3.5,3.52,2.26,2.7,3.42,3.4,2.7,3.73,3.41,3.69,3.09,3.5,3.54,4.0,3.82,3.0,3.79,3.7,3.0,2.68,3.87,3.2,3.14,3.3,2.7,2.9,3.72,3.96,3.0,3.4,3.27,3.19,3.14,3.01,3.12,3.72,3.8,2.75,3.65,3.44,3.37,3.42,3.12,2.57,3.0,3.5,3.92,3.5,3.3,4.0,3.2,2.8,4.0,4.0,2.66,3.9,2.5,3.07,3.55,3.4,3.53,3.16,3.18,2.54,3.3,2.98,3.3,3.45,3.3,3.36,3.09,3.4,3.3,3.5,3.64,2.8,3.1,3.6,2.9,3.48,4.0,3.32,3.08,3.87,3.5,3.78,2.64,3.65,3.0,3.2,3.85,3.19,3.2,3.5,3.3,2.84,2.98,3.0,3.47,3.6,3.74,3.18,3.05,3.01,3.4,2.95,3.12,3.0,2.4,3.3,3.61,3.42,3.79,3.69,3.2,2.87,3.79,3.9,3.0,3.64,2.71,3.86,3.2,3.98,3.63,2.9,3.95,3.42,3.47,2.8,3.66,3.74,3.4,3.1,3.91,2.9,3.36,3.24,2.6,3.87,3.64,2.95,3.61,3.84,3.27,3.57,2.92,3.79,3.76,3.77,3.4,3.98,3.8,3.67,3.88,2.84,3.5,3.0,3.77,3.48,3.15,3.12,3.8,3.85,3.45,2.5,2.84,3.82,3.5,3.93,3.34,3.7,3.81,3.34,3.8,2.6,3.11,3.7,3.86,3.53,4.0,3.0,2.94,2.8,2.7,3.54,3.2,3.83,3.41,3.18,3.23,3.7,3.67,3.01,3.6,3.0,3.51,3.3,3.81,3.86,2.4,3.1,3.46,3.0,2.8,2.6,2.0,3.6,2.49,3.5,2.86,3.4,3.0,2.6,3.69,3.96,3.25,2.66,3.87,2.7,3.58,3.2,2.91,3.15,3.5,2.98,2.79,3.53,3.55,3.26,2.9,3.73,3.5,3.87,3.6,3.1,2.71,3.1,3.28,2.8,3.79,3.65,3.4,3.49,3.16,3.5,3.0,2.9,3.0,3.5,2.85,3.91,3.6,3.5,3.6,3.29,3.77,3.21,3.88,2.81,2.95,3.97,3.67,3.8,3.02,4.0,2.5,4.0,3.39,3.07,3.37,3.14,3.88,3.12,3.43,3.6,3.1,3.0,3.0,3.4,2.89,3.0,3.69,3.7,3.65,3.4,3.83,3.8,3.21,3.57,3.93,3.96,3.73,3.15,3.94,3.56,1.78,2.86,3.9,3.4,3.72,2.82,3.6,3.17,2.3,3.7,2.95,3.0,3.52,3.0,3.27,3.16,3.9,3.81,3.2,2.79,3.5,3.25,2.96,3.5,3.0,3.4,1.78,3.7,2.98,3.09,3.85,3.93,3.4,3.7,3.92,3.09,3.5,3.4,3.79,3.4,2.5,3.4,3.79,3.58,3.82,3.1,3.3,3.57,3.2,2.96,3.9,2.8,3.2,3.38,3.9,3.35,3.95,3.5,3.2,3.2,3.62,3.89,3.97,3.47,3.52,3.5,3.92,3.24,3.4,2.2,3.46,3.5,3.5,3.92,3.57,3.9,3.75,3.8,3.7,3.29,3.5,2.4,3.92,3.81,2.8,2.8,3.63,3.6,3.9,2.19,3.5,3.9,3.14,3.0,3.2,2.7,3.12,3.94,3.0,3.3,3.0,2.8,2.6,3.6,3.85,3.2,2.94,3.44,3.75,2.9,3.6,3.5,3.7,3.67,3.96,3.2,3.52,3.67,3.52,3.3,3.14,3.45,3.8,3.1,3.91,3.98,3.46,3.28,3.7,3.54,3.22,2.0,3.66,3.47,3.75,3.8,3.5,3.93,3.54,3.57,3.3,3.07,3.5,3.3,3.71,3.7,3.26,2.9,3.9,3.8,2.93,3.45,3.48,3.92,3.69,3.3,2.82,3.2,3.78,3.18,3.8,3.41,2.98,3.8,3.7,3.1,2.26,3.2,3.4,3.2,3.3,2.8,3.54,3.2,3.2,1.76,3.55,3.02,3.19,3.6,3.64,3.6,3.0,2.89,3.01,1.78,3.4,3.04,3.1,2.41,3.3,2.8,2.7,2.5,2.8,3.4,2.78,2.6,3.74,3.74,3.4,3.25,2.7,3.1,3.8,3.8,2.99,3.83,3.45,3.5,3.56,3.48,2.66,3.97,3.44,3.3,4.0,3.41,3.12,3.48,2.57,3.79,3.2,3.98,3.61,3.3,3.4,3.14,2.56,3.72,2.9,3.7,3.7,3.36,3.3,3.79,3.61,2.8,3.12,3.32,3.2,2.66,2.92,3.8,3.2,3.89,3.51,3.12,2.7,3.72,3.35,3.6,3.21,3.18,2.87,3.1,3.66,3.74,3.73,2.6,3.86,3.42,4.0,3.64,3.95,2.87,2.8,3.17,3.0,3.42,2.74,3.19,3.79,3.7,3.65,2.66,3.79,3.15,3.14,3.8,3.6,4.0,3.2,3.6,3.7,3.81,3.13,2.01,2.98,3.35,2.8,2.9,3.5,3.69,3.2,3.09,3.04,3.18,3.24,2.8,3.43,2.9,3.91,3.3,3.8,3.5,3.67,3.78,3.3,3.2,3.19,3.2,2.8,3.92,3.64,3.3,3.5,3.06,3.05,3.06,2.7,3.45,3.01,2.6,3.42,2.7,3.79,3.6,3.4,3.93,3.59,3.9,3.21,3.27,3.34,3.7,2.92,3.96,3.266,3.3,3.07,3.0,3.47,3.0,3.0,3.87,3.9,3.85,2.6,3.56,2.97,2.7,3.65,3.66,3.5,3.86,3.84,3.12,3.0,3.0,3.28,3.74,2.5,3.64,3.6,3.4,3.8,3.85,3.36,3.23,2.93,3.3,3.62,3.77,3.0,3.0,2.6,2.64,3.0,3.3,3.26,3.34,3.5,3.22,3.57,3.6,3.8,3.54,3.1,2.6,2.87,3.45,3.0,3.88,3.0,2.49,3.2,3.91,3.11,3.93,3.21,3.7,3.5,3.21,3.02,2.85,3.5,3.6,3.6,3.0,2.99,3.0,3.43,3.2,2.98,3.5,3.0,3.1,2.5,3.5,3.0,3.37,3.89,3.0,2.99,3.85,3.73,3.0,3.23,3.2,2.8,3.8,4.0,3.43,3.3,3.97,3.7,3.26,3.57,1.78,3.65,3.16,3.3,3.25,3.56,3.38,3.77,3.96,3.4,3.0,3.51,3.95,3.7,3.14,3.92,3.83,3.5,3.4,3.3,2.85,3.73,3.0,3.25,3.0,3.4,3.93,3.99,3.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('efb45daa-855f-4568-89f0-753f52fe1379');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCALE DATA USING MINMAXSCALER"
      ],
      "metadata": {
        "id": "AYBPVQ21bRKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = DF4_ALL.columns\n",
        "scaler = MinMaxScaler()\n",
        "DF4_ALL_Scaled = pd.DataFrame(scaler.fit_transform(DF4_ALL), columns=cols)\n",
        "\n",
        "# GPAmax = GPA.max()\n",
        "# GPAmin = GPA.min()\n",
        "# GPAreshaped = GPA.values.reshape(-1, 1) \n",
        "# GPAScaled = pd.DataFrame(scaler.fit_transform(GPAreshaped))\n",
        "# GPAScaled2 = (GPA - GPA.min()) / (GPA.max() - GPA.min())\n",
        "\n",
        "#DF5ALL = pd.concat([DF4_ALL_Scaled, GPAALL], axis = 1)\n",
        "#DF5ALL.columns = range(DF5ALL.columns.size) # re index column numbers\n",
        "\n",
        "DF4_ALL_QO = DF4_ALL.iloc[:,0:61]\n",
        "DF4_ALL_QO.shape\n",
        "\n",
        "cols = DF4_ALL_QO.columns\n",
        "scaler2 = MinMaxScaler()\n",
        "DF4_ALL_QO_Scaled = pd.DataFrame(scaler2.fit_transform(DF4_ALL_QO), columns=cols)"
      ],
      "metadata": {
        "id": "eVc4-yMTerAm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = DF4FreJeoPost.columns\n",
        "scaler5 = MinMaxScaler()\n",
        "DF4FreJeoPost_Scaled = pd.DataFrame(scaler5.fit_transform(DF4FreJeoPost), columns=cols)\n",
        "\n",
        "# GPAmax = GPA.max()\n",
        "# GPAmin = GPA.min()\n",
        "# GPAreshaped = GPA.values.reshape(-1, 1) \n",
        "# GPAScaled = pd.DataFrame(scaler.fit_transform(GPAreshaped))\n",
        "# GPAScaled2 = (GPA - GPA.min()) / (GPA.max() - GPA.min())\n",
        "\n",
        "#DF5FreJeoPost = pd.concat([DF4FreJeoPost_Scaled, GPAFreJeoPost], axis = 1)\n",
        "#DF5FreJeoPost.columns = range(DF5FreJeoPost.columns.size) # re index column numbers\n",
        "\n",
        "DF4FreJeoPost_QO = DF4FreJeoPost.iloc[:,0:61]\n",
        "DF4FreJeoPost_QO.shape\n",
        "\n",
        "cols = DF4FreJeoPost_QO.columns\n",
        "scaler6 = MinMaxScaler()\n",
        "DF4FreJeoPost_QO_Scaled = pd.DataFrame(scaler6.fit_transform(DF4FreJeoPost_QO), columns=cols)"
      ],
      "metadata": {
        "id": "ACC4lIPfWb9k"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = DF4FreJeoPre.columns\n",
        "scaler7 = MinMaxScaler()\n",
        "DF4FreJeoPre_Scaled = pd.DataFrame(scaler7.fit_transform(DF4FreJeoPre), columns=cols)\n",
        "\n",
        "# GPAmax = GPA.max()\n",
        "# GPAmin = GPA.min()\n",
        "# GPAreshaped = GPA.values.reshape(-1, 1) \n",
        "# GPAScaled = pd.DataFrame(scaler.fit_transform(GPAreshaped))\n",
        "# GPAScaled2 = (GPA - GPA.min()) / (GPA.max() - GPA.min())\n",
        "\n",
        "#DF5FreJeoPre = pd.concat([DF4FreJeoPre_Scaled, GPAFreJeoPre], axis = 1)\n",
        "#DF5FreJeoPre.columns = range(DF5FreJeoPre.columns.size) # re index column numbers\n",
        "\n",
        "DF4FreJeoPre_QO = DF4FreJeoPre.iloc[:,0:61]\n",
        "DF4FreJeoPre_QO.shape\n",
        "\n",
        "cols = DF4FreJeoPre_QO.columns\n",
        "scaler8 = MinMaxScaler()\n",
        "DF4FreJeoPre_QO_Scaled = pd.DataFrame(scaler8.fit_transform(DF4FreJeoPre_QO), columns=cols)"
      ],
      "metadata": {
        "id": "HNnrFtepWb9l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FREKIDES PRE**_OCSVM USING _**FULL DATASET**_TH2 / ADDITIONAL FUNCTIONS REMOVED, QUESTIONS ONLY"
      ],
      "metadata": {
        "id": "48-eJq8ZvWnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "SVMOC.fit(DF4FreJeoPre_QO_Scaled)\n",
        "OCsvmresults = SVMOC.predict(DF4FreJeoPre_QO_Scaled)\n",
        "\n",
        "TH = 3.0\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre <= 4) & (GPAFreJeoPre >= TH), 1, GPAFreJeoPre)\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre < TH) & (GPAFreJeoPre >= 1.0), -1, GPAFreJeoPre_Cat)\n",
        "\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost <= 4) & (GPAFreJeoPost >= TH), 1, GPAFreJeoPost)\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost < TH) & (GPAFreJeoPost >= 1.0), -1, GPAFreJeoPost_Cat)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "#micro = f1_score(GPA_Cat, OCsvmresults, average='micro')\n",
        "#macro = f1_score(GPA_Cat, OCsvmresults, average='macro')\n",
        "#none = f1_score(GPA_Cat, OCsvmresults, average=None)\n",
        "#weighted = f1_score(GPA_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscoresPre = SVMOC.decision_function(DF4FreJeoPre_QO_Scaled)\n",
        "fpr5,tpr5,thresholds = roc_curve(GPAFreJeoPre_Cat,OCsvmscoresPre)\n",
        "\n",
        "OCsvmscoresPost = SVMOC.decision_function(DF4FreJeoPost_QO_Scaled)\n",
        "fpr6,tpr6,thresholds2 = roc_curve(GPAFreJeoPost_Cat,OCsvmscoresPost)\n",
        "\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "roc_auc6 = metrics.auc(fpr6,tpr6)\n",
        "print(f'The AUC Score for Frekides PRE Components ----- {roc_auc5}')\n",
        "print(f'The AUC Score for Frekides POST Components ----- {roc_auc6}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "my_dict = {\"Combinations\":[],\"AUC_Pre_On_PreNN\":[],\"AUC_Post_On_PreNN\":[]};\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"PreNNPre vs PreNNPost - ALL Features\")\n",
        "my_dict[\"AUC_Pre_On_PreNN\"].append(roc_auc5)\n",
        "my_dict[\"AUC_Post_On_PreNN\"].append(roc_auc6)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUC_Pre_On_PreNN', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "_nE9WY66vV8M",
        "outputId": "74aa51b1-be2b-43e6-ad6d-b8fed9c34252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]The AUC Score for Frekides PRE Components ----- 0.507243311832505\n",
            "The AUC Score for Frekides POST Components ----- 0.43089887640449437\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a2e0edf-887e-41b5-8faf-185a6e9451b7\", \"DFmy_dict.csv\", 126)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ALL DATA**_OCSVM USING _**FULL DATASET**_TH2.5 / ADDITIONAL FUNCTIONS REMOVED, QUESTIONS ONLY"
      ],
      "metadata": {
        "id": "5NiqP0YRX2yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "SVMOC.fit(DF4_ALL_QO_Scaled)\n",
        "OCsvmresults = SVMOC.predict(DF4_ALL_QO_Scaled)\n",
        "\n",
        "TH = 2.5\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 0), -1, GPAALL_Cat)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "#micro = f1_score(GPA_Cat, OCsvmresults, average='micro')\n",
        "#macro = f1_score(GPA_Cat, OCsvmresults, average='macro')\n",
        "#none = f1_score(GPA_Cat, OCsvmresults, average=None)\n",
        "#weighted = f1_score(GPA_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscores = SVMOC.decision_function(DF4_ALL_QO_Scaled)\n",
        "\n",
        "fpr5,tpr5,thresholds = roc_curve(GPAALL_Cat,OCsvmscores)\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "print(f'The AUC Score for Questions Principal Components ----- {roc_auc5}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"Biodeg Scaled ALL Features\")\n",
        "my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0211b99b-2b25-47d5-be7a-42a6477d3f1a",
        "id": "yRwe6SkeX2yv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]The AUC Score for Questions Principal Components ----- 0.5191212461489736\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fad1e561-66fe-4106-9380-cf1a42f6d3bc\", \"DFmy_dict.csv\", 72)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FREKIDES DATA** GPA THRESHOLD AT 2/2.5/3 QUESTIONS ONLY **RANDOM 18** OCSVM"
      ],
      "metadata": {
        "id": "mEnQDmpvv5c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "DF4FreJeoPre_Scaled_Rand18 = DF4FreJeoPre_QO_Scaled.sample(n=18,axis='columns')\n",
        "Comb1 = DF4FreJeoPre_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18 = DF4FreJeoPost_QO_Scaled.iloc[: , Comb1].copy()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4FreJeoPre_Scaled_Rand18, GPAFreJeoPre], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 3\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre <= 4) & (GPAFreJeoPre >= TH), 1, GPAFreJeoPre)\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre < TH) & (GPAFreJeoPre >= 1.0), -1, GPAFreJeoPre_Cat)\n",
        "\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost <= 4) & (GPAFreJeoPost >= TH), 1, GPAFreJeoPost)\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost < TH) & (GPAFreJeoPost >= 1.0), -1, GPAFreJeoPost_Cat)\n",
        "\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAFreJeoPre_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAFreJeoPre_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScoresPre\":[],\"AUCScoresPost\":[]};\n",
        "\n",
        "for i in range(20000):\n",
        "\n",
        "  DF4FreJeoPre_Scaled_Rand18 = DF4FreJeoPre_QO_Scaled.sample(n=18,axis='columns')\n",
        "  Comb1 = DF4FreJeoPre_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18 = DF4FreJeoPost_QO_Scaled.iloc[: , Comb1].copy()\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4FreJeoPre_Scaled_Rand18)\n",
        "  OCsvmresultsPre = SVMOC.predict(DF4FreJeoPre_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAFreJeoPre_Cat, OCsvmresultsPre, average='micro')\n",
        "  macro = f1_score(GPAFreJeoPre_Cat, OCsvmresultsPre, average='macro')\n",
        "  none = f1_score(GPAFreJeoPre_Cat, OCsvmresultsPre, average=None)\n",
        "  weighted = f1_score(GPAFreJeoPre_Cat, OCsvmresultsPre, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscoresPre = SVMOC.decision_function(DF4FreJeoPre_Scaled_Rand18)\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAFreJeoPre_Cat,OCsvmscoresPre)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "\n",
        "  OCsvmscoresPost = SVMOC.decision_function(DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18)\n",
        "  fpr6,tpr6,thresholds2 = roc_curve(GPAFreJeoPost_Cat,OCsvmscoresPost)\n",
        "  roc_auc6 = metrics.auc(fpr6,tpr6)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScoresPre\"].append(roc_auc5)\n",
        "  my_dict[\"AUCScoresPost\"].append(roc_auc6)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScoresPre', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "id": "GDOiCzyJvyMR",
        "outputId": "ef0180cc-afaf-483e-df86-58962d444948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 3\n",
            "Actual number of students above threshold 3 is .. 315\n",
            "Actual number of students below threshold 3 is .. 84\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e4657a2-8891-4507-b6d3-5d032d1504eb\", \"DFmy_dict.csv\", 2306278)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"])/len(DFmy_dict[\"AUCScoresPre\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "615a4839-8440-4b70-f9d6-47204ea58853",
        "id": "TlGpu2GTnc6H"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.5834678760393046\n",
            "Avarage of top 1000 AUC scores is = 0.5662982615268344\n",
            "Avarage of AUC scores is = 0.5214175160619766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Combinations  AUCScoresPre  \\\n",
              "4603  [52, 5, 47, 46, 39, 48, 53, 55, 19, 51, 6, 50,...      0.609902   \n",
              "7179  [60, 58, 30, 41, 2, 4, 57, 44, 38, 52, 48, 49,...      0.603741   \n",
              "8542  [33, 57, 48, 19, 46, 53, 36, 58, 4, 43, 31, 49...      0.599735   \n",
              "\n",
              "      AUCScoresPost  \n",
              "4603       0.661076  \n",
              "7179       0.553878  \n",
              "8542       0.565668  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd194456-caca-4d24-a210-9291e9ad7ca4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScoresPre</th>\n",
              "      <th>AUCScoresPost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4603</th>\n",
              "      <td>[52, 5, 47, 46, 39, 48, 53, 55, 19, 51, 6, 50,...</td>\n",
              "      <td>0.609902</td>\n",
              "      <td>0.661076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7179</th>\n",
              "      <td>[60, 58, 30, 41, 2, 4, 57, 44, 38, 52, 48, 49,...</td>\n",
              "      <td>0.603741</td>\n",
              "      <td>0.553878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>[33, 57, 48, 19, 46, 53, 36, 58, 4, 43, 31, 49...</td>\n",
              "      <td>0.599735</td>\n",
              "      <td>0.565668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd194456-caca-4d24-a210-9291e9ad7ca4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd194456-caca-4d24-a210-9291e9ad7ca4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd194456-caca-4d24-a210-9291e9ad7ca4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OLD DATA** GPA THRESHOLD AT 2.5 QUESTIONS ONLY **RANDOM 18** OCSVM"
      ],
      "metadata": {
        "id": "Rsbian2DhW95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "DF4_ALL_Scaled_Rand18 = DF4_ALL_QO_Scaled.sample(n=18,axis='columns')\n",
        "Comb1 = DF4_ALL_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4_ALL_Scaled_Rand18, GPAALL], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 2.5\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 1.0), -1, GPAALL_Cat)\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAALL_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAALL_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "for i in range(20000):\n",
        "\n",
        "  DF4_ALL_Scaled_Rand18 = DF4_ALL_QO_Scaled.sample(n=18,axis='columns')\n",
        "  Comb1 = DF4_ALL_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4_ALL_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF4_ALL_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAALL_Cat, OCsvmresults, average='micro')\n",
        "  macro = f1_score(GPAALL_Cat, OCsvmresults, average='macro')\n",
        "  none = f1_score(GPAALL_Cat, OCsvmresults, average=None)\n",
        "  weighted = f1_score(GPAALL_Cat, OCsvmresults, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscores = SVMOC.decision_function(DF4_ALL_Scaled_Rand18)\n",
        "\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAALL_Cat,OCsvmscores)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "cb856ca3-5a0e-4e08-be3a-2cfea2343744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "WNbAbd4OhW97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 2.5\n",
            "Actual number of students above threshold 2.5 is .. 2513\n",
            "Actual number of students below threshold 2.5 is .. 79\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_18bf3d41-6ef7-4d98-990d-a57bffdb6011\", \"DFmy_dict.csv\", 1928132)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScores\"])/len(DFmy_dict[\"AUCScores\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "6c4c1b13-c44e-4769-ffb1-c2da08a406e5",
        "id": "IEKT-9AlhW99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.6049348703199061\n",
            "Avarage of top 1000 AUC scores is = 0.5841036080734605\n",
            "Avarage of AUC scores is = 0.5321472836188533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Combinations  AUCScores\n",
              "13388  [22, 8, 50, 3, 59, 39, 11, 56, 45, 42, 1, 47, ...   0.634317\n",
              "13213  [57, 33, 53, 46, 32, 60, 59, 40, 25, 50, 0, 42...   0.632644\n",
              "17574  [19, 59, 45, 16, 11, 3, 39, 60, 36, 49, 33, 47...   0.630242"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f010888-f1ff-4d26-9451-5cdc11054555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13388</th>\n",
              "      <td>[22, 8, 50, 3, 59, 39, 11, 56, 45, 42, 1, 47, ...</td>\n",
              "      <td>0.634317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13213</th>\n",
              "      <td>[57, 33, 53, 46, 32, 60, 59, 40, 25, 50, 0, 42...</td>\n",
              "      <td>0.632644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17574</th>\n",
              "      <td>[19, 59, 45, 16, 11, 3, 39, 60, 36, 49, 33, 47...</td>\n",
              "      <td>0.630242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f010888-f1ff-4d26-9451-5cdc11054555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f010888-f1ff-4d26-9451-5cdc11054555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f010888-f1ff-4d26-9451-5cdc11054555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FREKIDES** GPA THRESHOLD AT 2/2.5/3 QUESTIONS ONLY **RANDOM 18** OCSVM **UPDATE SAMPLING WEIGHTS SOMEHOW**"
      ],
      "metadata": {
        "id": "FIWc6cJAs2uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "weightage = [1/61 for i in range(61)]\n",
        "\n",
        "DF4FreJeoPre_Scaled_Rand18 = DF4FreJeoPre_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "Comb1 = DF4FreJeoPre_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18 = DF4FreJeoPost_QO_Scaled.iloc[: , Comb1].copy()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4FreJeoPre_Scaled_Rand18, GPAFreJeoPre], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 3\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre <= 4) & (GPAFreJeoPre >= TH), 1, GPAFreJeoPre)\n",
        "GPAFreJeoPre_Cat = np.where((GPAFreJeoPre < TH) & (GPAFreJeoPre >= 1.0), -1, GPAFreJeoPre_Cat)\n",
        "\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost <= 4) & (GPAFreJeoPost >= TH), 1, GPAFreJeoPost)\n",
        "GPAFreJeoPost_Cat = np.where((GPAFreJeoPost < TH) & (GPAFreJeoPost >= 1.0), -1, GPAFreJeoPost_Cat)\n",
        "\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAFreJeoPre == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAFreJeoPre == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScoresPre\":[],\"AUCScoresPost\":[]};\n",
        "\n",
        "for i in range(5000):\n",
        "\n",
        "  DF4FreJeoPre_Scaled_Rand18 = DF4FreJeoPre_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "  Comb1 = DF4FreJeoPre_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18 = DF4FreJeoPost_QO_Scaled.iloc[: , Comb1].copy()\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4FreJeoPre_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF4FreJeoPre_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAFreJeoPre_Cat, OCsvmresults, average='micro')\n",
        "  macro = f1_score(GPAFreJeoPre_Cat, OCsvmresults, average='macro')\n",
        "  none = f1_score(GPAFreJeoPre_Cat, OCsvmresults, average=None)\n",
        "  weighted = f1_score(GPAFreJeoPre_Cat, OCsvmresults, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscoresPre = SVMOC.decision_function(DF4FreJeoPre_Scaled_Rand18)\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAFreJeoPre_Cat,OCsvmscoresPre)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "\n",
        "  OCsvmscoresPost = SVMOC.decision_function(DF4FreJeoPost_Corresponding_to_Pre_Scaled_Rand18)\n",
        "  fpr6,tpr6,thresholds2 = roc_curve(GPAFreJeoPost_Cat,OCsvmscoresPost)\n",
        "  roc_auc6 = metrics.auc(fpr6,tpr6)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScoresPre\"].append(roc_auc5)\n",
        "  my_dict[\"AUCScoresPost\"].append(roc_auc6)\n",
        "\n",
        "  for i in Comb1:\n",
        "    weightage[i] = weightage[i] + (0.01 * (roc_auc5 - (sum(my_dict[\"AUCScoresPre\"])/len(my_dict[\"AUCScoresPre\"]))))\n",
        "\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScoresPre', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "7a84649c-71c3-443f-e153-725557b3daad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "5TCe-fvvs2uH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 3\n",
            "Actual number of students above threshold 3 is .. 0\n",
            "Actual number of students below threshold 3 is .. 0\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9059a629-0ac8-4f89-9408-86bd38160d05\", \"DFmy_dict.csv\", 571900)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScoresPre\"])/len(DFmy_dict[\"AUCScoresPre\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "TVPUJYrZcsWx",
        "outputId": "05790070-acfd-4426-bd66-c358b8c1049a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.6059274376417234\n",
            "Avarage of top 1000 AUC scores is = 0.5891319160997726\n",
            "Avarage of AUC scores is = 0.5600638435374158\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Combinations  AUCScoresPre  \\\n",
              "3925  [50, 4, 60, 57, 49, 5, 24, 53, 39, 51, 22, 42,...      0.619010   \n",
              "4740  [42, 7, 21, 29, 24, 6, 51, 53, 15, 46, 3, 48, ...      0.615873   \n",
              "2197  [38, 60, 57, 24, 40, 42, 34, 35, 51, 41, 15, 5...      0.615533   \n",
              "\n",
              "      AUCScoresPost  \n",
              "3925       0.729096  \n",
              "4740       0.726620  \n",
              "2197       0.700749  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e58d79ed-a057-4038-8cb1-6c5e60506dc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScoresPre</th>\n",
              "      <th>AUCScoresPost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3925</th>\n",
              "      <td>[50, 4, 60, 57, 49, 5, 24, 53, 39, 51, 22, 42,...</td>\n",
              "      <td>0.619010</td>\n",
              "      <td>0.729096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4740</th>\n",
              "      <td>[42, 7, 21, 29, 24, 6, 51, 53, 15, 46, 3, 48, ...</td>\n",
              "      <td>0.615873</td>\n",
              "      <td>0.726620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2197</th>\n",
              "      <td>[38, 60, 57, 24, 40, 42, 34, 35, 51, 41, 15, 5...</td>\n",
              "      <td>0.615533</td>\n",
              "      <td>0.700749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e58d79ed-a057-4038-8cb1-6c5e60506dc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e58d79ed-a057-4038-8cb1-6c5e60506dc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e58d79ed-a057-4038-8cb1-6c5e60506dc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OLD DATA** GPA THRESHOLD AT 2.5 QUESTIONS ONLY **RANDOM 18** OCSVM **UPDATE SAMPLING WEIGHTS SOMEHOW**"
      ],
      "metadata": {
        "id": "SUipQohxssXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "weightage = [1/61 for i in range(61)]\n",
        "\n",
        "DF4_ALL_Scaled_Rand18 = DF4_ALL_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "Comb1 = DF4_ALL_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4_ALL_Scaled_Rand18, GPAALL], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 2.5\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 1.0), -1, GPAALL_Cat)\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAALL_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAALL_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "for i in range(5000):\n",
        "\n",
        "  DF4_ALL_Scaled_Rand18 = DF4_ALL_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "  Comb1 = DF4_ALL_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4_ALL_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF4_ALL_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAALL_Cat, OCsvmresults, average='micro')\n",
        "  macro = f1_score(GPAALL_Cat, OCsvmresults, average='macro')\n",
        "  none = f1_score(GPAALL_Cat, OCsvmresults, average=None)\n",
        "  weighted = f1_score(GPAALL_Cat, OCsvmresults, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscores = SVMOC.decision_function(DF4_ALL_Scaled_Rand18)\n",
        "\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAALL_Cat,OCsvmscores)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "  for i in Comb1:\n",
        "    weightage[i] = weightage[i] + (0.01 * (roc_auc5 - (sum(my_dict[\"AUCScores\"])/len(my_dict[\"AUCScores\"]))))\n",
        "\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "bc66ccd9-172f-4e7f-eefc-c5b29654eee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Kv3GJtTzssXy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 2.5\n",
            "Actual number of students above threshold 2.5 is .. 2513\n",
            "Actual number of students below threshold 2.5 is .. 79\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9700198b-dd7d-471f-a97a-2a6ee8eda7ba\", \"DFmy_dict.csv\", 480778)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScores\"])/len(DFmy_dict[\"AUCScores\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "469cee16-4968-4c47-aee8-a07507199cee",
        "id": "srjDa_7sssXz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.6399292791408725\n",
            "Avarage of top 1000 AUC scores is = 0.6192874923813876\n",
            "Avarage of AUC scores is = 0.5832301747369364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Combinations  AUCScores\n",
              "3672  [59, 53, 19, 38, 11, 39, 60, 31, 58, 40, 35, 3...   0.655500\n",
              "2181  [32, 56, 41, 49, 47, 58, 50, 42, 24, 35, 60, 1...   0.653130\n",
              "2805  [11, 59, 19, 1, 53, 47, 55, 42, 41, 58, 29, 26...   0.651901"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8496c14-f757-4c0a-990c-74dd6fd2b6a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3672</th>\n",
              "      <td>[59, 53, 19, 38, 11, 39, 60, 31, 58, 40, 35, 3...</td>\n",
              "      <td>0.655500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>[32, 56, 41, 49, 47, 58, 50, 42, 24, 35, 60, 1...</td>\n",
              "      <td>0.653130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2805</th>\n",
              "      <td>[11, 59, 19, 1, 53, 47, 55, 42, 41, 58, 29, 26...</td>\n",
              "      <td>0.651901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8496c14-f757-4c0a-990c-74dd6fd2b6a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8496c14-f757-4c0a-990c-74dd6fd2b6a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8496c14-f757-4c0a-990c-74dd6fd2b6a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weightage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "O5p4SAx7fdL8",
        "outputId": "14aa0fa4-c2a2-47f6-d9b8-401ed37ada27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-870c667fd2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweightage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'weightage' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NEW (PRE) DATA** - GPA THRESHOLD AT 3.0, QUESTIONS ONLY **RANDOM 18** OCSVM"
      ],
      "metadata": {
        "id": "7qjuPOjsIZJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "DF4Pre_Scaled_Rand18 = DF4Pre_QO_Scaled.sample(n=18,axis='columns')\n",
        "Comb1 = DF4Pre_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4Pre_Scaled_Rand18, GPAPre], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 3.0\n",
        "GPAPre_Cat = np.where((GPAPre <= 4) & (GPAPre >= TH), 1, GPAPre)\n",
        "GPAPre_Cat = np.where((GPAPre < TH) & (GPAPre >= 1.0), -1, GPAPre_Cat)\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAPre_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAPre_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "for i in range(20000):\n",
        "\n",
        "  DF4Pre_Scaled_Rand18 = DF4Pre_QO_Scaled.sample(n=18,axis='columns')\n",
        "  Comb1 = DF4Pre_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4Pre_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF4Pre_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAPre_Cat, OCsvmresults, average='micro')\n",
        "  macro = f1_score(GPAPre_Cat, OCsvmresults, average='macro')\n",
        "  none = f1_score(GPAPre_Cat, OCsvmresults, average=None)\n",
        "  weighted = f1_score(GPAPre_Cat, OCsvmresults, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscores = SVMOC.decision_function(DF4Pre_Scaled_Rand18)\n",
        "\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAPre_Cat,OCsvmscores)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "2fd3b815-0288-4c88-b66a-b9405408694e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "XUT5vK-wIZJV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 3.0\n",
            "Actual number of students above threshold 3.0 is .. 503\n",
            "Actual number of students below threshold 3.0 is .. 116\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d6aebf2f-6332-4b84-a9f8-ba05abdbd39e\", \"DFmy_dict.csv\", 1935416)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScores\"])/len(DFmy_dict[\"AUCScores\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "8224ff88-2619-4d54-bd2d-a0b47bc40a32",
        "id": "iOYpU4LDIZJX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.552020720504559\n",
            "Avarage of top 1000 AUC scores is = 0.5322726657297595\n",
            "Avarage of AUC scores is = 0.48197798296428246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Combinations  AUCScores\n",
              "16654  [41, 2, 19, 60, 33, 55, 24, 16, 59, 35, 8, 46,...   0.580654\n",
              "10182  [24, 57, 31, 58, 48, 59, 46, 36, 2, 0, 42, 34,...   0.574210\n",
              "8388   [53, 1, 42, 40, 7, 50, 60, 41, 21, 34, 4, 10, ...   0.571245"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c3bd2ec-90af-40e5-a0c7-9816ae27c357\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16654</th>\n",
              "      <td>[41, 2, 19, 60, 33, 55, 24, 16, 59, 35, 8, 46,...</td>\n",
              "      <td>0.580654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10182</th>\n",
              "      <td>[24, 57, 31, 58, 48, 59, 46, 36, 2, 0, 42, 34,...</td>\n",
              "      <td>0.574210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8388</th>\n",
              "      <td>[53, 1, 42, 40, 7, 50, 60, 41, 21, 34, 4, 10, ...</td>\n",
              "      <td>0.571245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c3bd2ec-90af-40e5-a0c7-9816ae27c357')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c3bd2ec-90af-40e5-a0c7-9816ae27c357 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c3bd2ec-90af-40e5-a0c7-9816ae27c357');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NEW (PRE) DATA** - GPA THRESHOLD AT 3.0, QUESTIONS ONLY **RANDOM 18** OCSVM - **UPDATE SAMPLING WEIGHTS SOMEHOW**"
      ],
      "metadata": {
        "id": "Bi-qVFQ3IZJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "weightage = [1/61 for i in range(61)]\n",
        "\n",
        "DF4Pre_Scaled_Rand18 = DF4Pre_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "Comb1 = DF4Pre_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "DF5 = pd.concat([DF4Pre_Scaled_Rand18, GPAPre], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 3.0\n",
        "GPAPre_Cat = np.where((GPAPre <= 4) & (GPAPre >= TH), 1, GPAPre)\n",
        "GPAPre_Cat = np.where((GPAPre < TH) & (GPAPre >= 1.0), -1, GPAPre_Cat)\n",
        "print(f'Threshold is {TH}')\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAPre_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAPre_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "for i in range(5000):\n",
        "\n",
        "  DF4Pre_Scaled_Rand18 = DF4Pre_QO_Scaled.sample(n=18,axis='columns',weights=weightage)\n",
        "  Comb1 = DF4Pre_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF4Pre_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF4Pre_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  micro = f1_score(GPAPre_Cat, OCsvmresults, average='micro')\n",
        "  macro = f1_score(GPAPre_Cat, OCsvmresults, average='macro')\n",
        "  none = f1_score(GPAPre_Cat, OCsvmresults, average=None)\n",
        "  weighted = f1_score(GPAPre_Cat, OCsvmresults, average='weighted')\n",
        "  #print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscores = SVMOC.decision_function(DF4Pre_Scaled_Rand18)\n",
        "\n",
        "  fpr5,tpr5,thresholds = roc_curve(GPAPre_Cat,OCsvmscores)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "  #print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  #print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "  for i in Comb1:\n",
        "    weightage[i] = weightage[i] + (0.01 * (roc_auc5 - (sum(my_dict[\"AUCScores\"])/len(my_dict[\"AUCScores\"]))))\n",
        "\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.head(10)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "94bf6ff8-cf9e-4c88-cc97-eeb74ace454a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Uoi1sDkHIZJZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 3.0\n",
            "Actual number of students above threshold 3.0 is .. 503\n",
            "Actual number of students below threshold 3.0 is .. 116\n",
            "********************************************************************************\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65a032ee-3e68-4a49-b834-1bb952b46c54\", \"DFmy_dict.csv\", 477225)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Avarage of top 100 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:100])/100}')\n",
        "print(f'Avarage of top 1000 AUC scores is = {sum(DFmy_dict[\"AUCScores\"][:1000])/1000}')\n",
        "print(f'Avarage of AUC scores is = {sum(DFmy_dict[\"AUCScores\"])/len(DFmy_dict[\"AUCScores\"])}')\n",
        "DFmy_dict.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "8e67c35d-9c9a-4117-b9a0-0e58e524e9d1",
        "id": "HmdZQgOsIZJb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avarage of top 100 AUC scores is = 0.586919003222047\n",
            "Avarage of top 1000 AUC scores is = 0.5678070285185436\n",
            "Avarage of AUC scores is = 0.5331946956193863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Combinations  AUCScores\n",
              "4186  [57, 46, 10, 59, 6, 2, 40, 60, 24, 58, 33, 45,...   0.604417\n",
              "4853  [59, 24, 7, 53, 33, 1, 42, 34, 6, 8, 35, 57, 4...   0.601666\n",
              "2828  [15, 46, 41, 2, 6, 59, 57, 58, 50, 32, 0, 60, ...   0.599918"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a520e12f-4810-4436-8c64-b56ce76e64fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Combinations</th>\n",
              "      <th>AUCScores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4186</th>\n",
              "      <td>[57, 46, 10, 59, 6, 2, 40, 60, 24, 58, 33, 45,...</td>\n",
              "      <td>0.604417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>[59, 24, 7, 53, 33, 1, 42, 34, 6, 8, 35, 57, 4...</td>\n",
              "      <td>0.601666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2828</th>\n",
              "      <td>[15, 46, 41, 2, 6, 59, 57, 58, 50, 32, 0, 60, ...</td>\n",
              "      <td>0.599918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a520e12f-4810-4436-8c64-b56ce76e64fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a520e12f-4810-4436-8c64-b56ce76e64fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a520e12f-4810-4436-8c64-b56ce76e64fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HERE I WANT TO TRY RANDOM FOREST TO SELECT BEST 18 FEATURES. SEE IF THEY COINCIDE FEATURES SELECTED WITH RAND18 OCSVM "
      ],
      "metadata": {
        "id": "dgpJhZkBcpwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "metadata": {
        "id": "vqWgq-oBc7Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TH = 2.5\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 1.0), -1, GPAALL_Cat)"
      ],
      "metadata": {
        "id": "tm91mg7xegZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100), max_features=18)\n",
        "sel.fit(DF4_ALL_QO_Scaled, GPAALL_Cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMiOXZlgeSOs",
        "outputId": "2c260277-0a0e-446d-9c7a-c002e54ee2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestClassifier(), max_features=18)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel.get_support()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AjOHSfwf9Mn",
        "outputId": "32c0e017-9bc9-4255-ef6b-8f5154951b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True, False, False,  True,  True, False,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False, False,\n",
              "        True, False, False, False,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False, False, False,  True, False, False, False, False, False,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feat= DF4_ALL_QO_Scaled.columns[(sel.get_support())]\n",
        "len(selected_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWBm6r_SgDGQ",
        "outputId": "0fb92802-be0f-4521-8d0d-8ee8a0071dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xh1oaghgD-m",
        "outputId": "dc03956e-240a-407b-8bcf-f2672b79598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18, 21, 25, 26, 53, 59, 60], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OCSVM WITH A SPECIFIC COMB OF FEATURES"
      ],
      "metadata": {
        "id": "UOwRU7y9ikH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "DF4_QO_SPECIFIC = DF4_ALL_QO_Scaled.iloc[: , [1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18, 21, 25, 26, 53, 59, 60]].copy()\n",
        "\n",
        "SVMOC.fit(DF4_QO_SPECIFIC)\n",
        "OCsvmresults = SVMOC.predict(DF4_QO_SPECIFIC)\n",
        "\n",
        "TH = 2.5\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 1.0), -1, GPAALL_Cat)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "#micro = f1_score(GPA_Cat, OCsvmresults, average='micro')\n",
        "#macro = f1_score(GPA_Cat, OCsvmresults, average='macro')\n",
        "#none = f1_score(GPA_Cat, OCsvmresults, average=None)\n",
        "#weighted = f1_score(GPA_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscores = SVMOC.decision_function(DF4_QO_SPECIFIC)\n",
        "\n",
        "fpr5,tpr5,thresholds = roc_curve(GPAALL_Cat,OCsvmscores)\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "print(f'The AUC Score for Questions Principal Components ----- {roc_auc5}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"Biodeg Scaled ALL Features\")\n",
        "my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "TidVJgPEitBc",
        "outputId": "03202490-5229-4c14-a1b2-71df99e76955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]The AUC Score for Questions Principal Components ----- 0.5676205251678613\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a933fc68-e727-4687-ae49-cbc8648b627e\", \"DFmy_dict.csv\", 72)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA COMPARISON STARTS HERE"
      ],
      "metadata": {
        "id": "4nZP2GiyQds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "for i in range(69):\n",
        "  pca = PCA(n_components=i)\n",
        "  principalcomponents = pca.fit_transform(DF4_ALL_QO)\n",
        "  var = sum(pca.explained_variance_ratio_)\n",
        "  if var >= 0.95:\n",
        "    break\n",
        "print(f'Number of component for %95 variance:', i)\n",
        "print(f'The variance is:', var)"
      ],
      "metadata": {
        "id": "JNyW0U34gzv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d52c857-6cf0-4691-b70a-9c27e6ff3819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of component for %95 variance: 38\n",
            "The variance is: 0.9533552606621356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DF4_Scaled_Rand18 = DF4_Scaled.sample(n=18,axis='columns')\n",
        "#Comb1 = DF4_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "#Questions = ' '.join(str(e) for e in Comb1)\n",
        "#DF5 = pd.concat([principalcomponents, GPAALL], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "TH = 3.0\n",
        "GPAALL_Cat = np.where((GPAALL <= 4) & (GPAALL >= TH), 1, GPAALL)\n",
        "GPAALL_Cat = np.where((GPAALL < TH) & (GPAALL >= 1.0), -1, GPAALL_Cat)\n",
        "print(f'Threshold is {TH}')\n",
        "from numpy.ma.core import count\n",
        "print(f'Actual number of students above threshold {TH} is .. {count(np.where(GPAALL_Cat == 1))}')\n",
        "print(f'Actual number of students below threshold {TH} is .. {count(np.where(GPAALL_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "\n",
        "# DF4_Scaled_Rand18 = DF4_Scaled.sample(n=18,axis='columns')\n",
        "# Comb1 = DF4_Scaled_Rand18.columns.values.tolist()\n",
        "# Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "SVMOC.fit(principalcomponents)\n",
        "OCsvmresults = SVMOC.predict(principalcomponents)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "micro = f1_score(GPAALL_Cat, OCsvmresults, average='micro')\n",
        "macro = f1_score(GPAALL_Cat, OCsvmresults, average='macro')\n",
        "none = f1_score(GPAALL_Cat, OCsvmresults, average=None)\n",
        "weighted = f1_score(GPAALL_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscores = SVMOC.decision_function(principalcomponents)\n",
        "\n",
        "fpr5,tpr5,thresholds = roc_curve(GPAALL_Cat,OCsvmscores)\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "print(f'The AUC Score for Questions Principal Components ----- {roc_auc5}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"Principal Components Nonscaled DF4 functions included\")\n",
        "my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "outputId": "3fbc3142-3e3a-4887-9916-dd04249fdb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "WGQ_MI1Iaimm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold is 3.0\n",
            "Actual number of students above threshold 3.0 is .. 2280\n",
            "Actual number of students below threshold 3.0 is .. 312\n",
            "********************************************************************************\n",
            "[LibSVM]The AUC Score for Questions Principal Components ----- 0.5338801731893836\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39c742ae-e7b6-4deb-bd4c-578f51f24c4b\", \"DFmy_dict.csv\", 99)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRYING ANOTHER DATASET"
      ],
      "metadata": {
        "id": "ZEpp636zON7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "K03tSJU1b8Si",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "557e6ed9-59f9-4f7b-d7a6-f4a0d93c6358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f9687ae-0b1a-43c3-aee5-75befc9931d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f9687ae-0b1a-43c3-aee5-75befc9931d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving biodeg.csv to biodeg.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF_biodeg = pd.read_csv(io.BytesIO(uploaded['biodeg.csv']), header=None, skip_blank_lines=True)\n",
        "DF_biodeg.head()"
      ],
      "metadata": {
        "id": "U5AOjGbFnwb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5b6ecaea-f415-4f36-894a-1dfc99c04a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0       1   2   3   4   5   6     7   8   9   ...  32  33  34     35  \\\n",
              "0  3.919  2.6909   0   0   0   0   0  31.4   2   0  ...   0   0   0  2.949   \n",
              "1  4.170  2.1144   0   0   0   0   0  30.8   1   1  ...   0   0   0  3.315   \n",
              "2  3.932  3.2512   0   0   0   0   0  26.7   2   4  ...   0   0   1  3.076   \n",
              "3  3.000  2.7098   0   0   0   0   0  20.0   0   2  ...   0   0   1  3.046   \n",
              "4  4.236  3.3944   0   0   0   0   0  29.4   2   4  ...   0   0   0  3.351   \n",
              "\n",
              "      36  37     38  39  40  41  \n",
              "0  1.591   0  7.253   0   0  RB  \n",
              "1  1.967   0  7.257   0   0  RB  \n",
              "2  2.417   0  7.601   0   0  RB  \n",
              "3  5.000   0  6.690   0   0  RB  \n",
              "4  2.405   0  8.003   0   0  RB  \n",
              "\n",
              "[5 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afc7e170-4f26-4d39-a71b-70329bc8dfeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.919</td>\n",
              "      <td>2.6909</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.949</td>\n",
              "      <td>1.591</td>\n",
              "      <td>0</td>\n",
              "      <td>7.253</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.170</td>\n",
              "      <td>2.1144</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.315</td>\n",
              "      <td>1.967</td>\n",
              "      <td>0</td>\n",
              "      <td>7.257</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.932</td>\n",
              "      <td>3.2512</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.076</td>\n",
              "      <td>2.417</td>\n",
              "      <td>0</td>\n",
              "      <td>7.601</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.000</td>\n",
              "      <td>2.7098</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.046</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0</td>\n",
              "      <td>6.690</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.236</td>\n",
              "      <td>3.3944</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.351</td>\n",
              "      <td>2.405</td>\n",
              "      <td>0</td>\n",
              "      <td>8.003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afc7e170-4f26-4d39-a71b-70329bc8dfeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afc7e170-4f26-4d39-a71b-70329bc8dfeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afc7e170-4f26-4d39-a71b-70329bc8dfeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF_biodeg.iloc[:,41].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYqa5JvQMM4q",
        "outputId": "dc8fa0c1-33eb-4da6-94ba-bd7b16b2bc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1055\n",
              "unique       2\n",
              "top        NRB\n",
              "freq       699\n",
              "Name: 41, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Bio_Cat = DF_biodeg.iloc[:,41]\n",
        "DF_biodeg.drop(DF_biodeg.columns[41], axis=1, inplace=True)\n",
        "Bio_Cat.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj63rXtCMkY9",
        "outputId": "6cd72864-3386-490f-f730-cade3bf81728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1055\n",
              "unique       2\n",
              "top        NRB\n",
              "freq       699\n",
              "Name: 41, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "for i in range(40):\n",
        "  pca = PCA(n_components=i)\n",
        "  principalcomponents = pca.fit_transform(DF_biodeg)\n",
        "  var = sum(pca.explained_variance_ratio_)\n",
        "  if var >= 0.95:\n",
        "    break\n",
        "print(f'Number of component for %95 variance:', i)\n",
        "print(f'The variance is:', var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sjsXbCMRoxN",
        "outputId": "9e38de31-0059-4727-eda0-d5111f3845db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of component for %95 variance: 7\n",
            "The variance is: 0.9515848819546795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Bio_Cat = np.where(Bio_Cat == \"NRB\", -1, Bio_Cat)\n",
        "Bio_Cat = np.where(Bio_Cat == \"RB\", 1, Bio_Cat)\n",
        "Bio_Cat = Bio_Cat.astype(int)\n",
        "Bio_Cat"
      ],
      "metadata": {
        "id": "DpXKt4sInwez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca17508-0b34-4634-fbd0-7c1795037860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1, ..., -1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols3 = DF_biodeg.columns\n",
        "scaler3 = MinMaxScaler()\n",
        "DF_biodeg_Scaled = pd.DataFrame(scaler3.fit_transform(DF_biodeg), columns=cols3)"
      ],
      "metadata": {
        "id": "LIyl9fKenwiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from numpy.ma.core import count\n",
        "\n",
        "DF_biodeg_Scaled_Rand18 = DF_biodeg_Scaled.sample(n=7,axis='columns')\n",
        "Comb1 = DF_biodeg_Scaled_Rand18.columns.values.tolist()\n",
        "\n",
        "Questions = ' '.join(str(e) for e in Comb1)\n",
        "## DF5biodeg = pd.concat([DF_biodeg_Scaled_Rand18, Bio_Cat], axis = 1)\n",
        "\n",
        "########################################################################\n",
        "print(f'Actual number of ready biodegradables RB .. {count(np.where(Bio_Cat == 1))}')\n",
        "print(f'Actual number of NON ready biodegradable NBR .. {count(np.where(Bio_Cat == -1))}')\n",
        "print('********************************************************************************')\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "for i in range(20000):\n",
        "\n",
        "  DF_biodeg_Scaled_Rand18 = DF_biodeg_Scaled.sample(n=7,axis='columns')\n",
        "  Comb1 = DF_biodeg_Scaled_Rand18.columns.values.tolist()\n",
        "  Questions = ' '.join(str(e) for e in Comb1)\n",
        "\n",
        "  SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "  # if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "  # if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "  # print(SVMOC)\n",
        "\n",
        "  SVMOC.fit(DF_biodeg_Scaled_Rand18)\n",
        "  OCsvmresults = SVMOC.predict(DF_biodeg_Scaled_Rand18)\n",
        "\n",
        "  #print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "  #print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "  #print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "  #print('********************************************************************************')\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  from sklearn import metrics\n",
        "  #micro = f1_score(Bio_Cat, OCsvmresults, average='micro')\n",
        "  #macro = f1_score(Bio_Cat, OCsvmresults, average='macro')\n",
        "  #none = f1_score(Bio_Cat, OCsvmresults, average=None)\n",
        "  #weighted = f1_score(Bio_Cat, OCsvmresults, average='weighted')\n",
        "  print(f'The comb tryout number: {i}')\n",
        "  #print(f'F1 Score using micro avarage = {micro}')\n",
        "  #print(f'F1 Score using macro avarage = {macro}')\n",
        "  #print(f'F1 Score using no avarage = {none}')\n",
        "  #print(f'F1 Score using weighted avarage = {weighted}')\n",
        "  #print('********************************************************************************')\n",
        "  #print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "  #print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "  #print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "  #print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "  #print('********************************************************************************')\n",
        "  #decision calculated to use in roc \n",
        "  OCsvmscores = SVMOC.decision_function(DF_biodeg_Scaled_Rand18)\n",
        "\n",
        "  fpr5,tpr5,thresholds = roc_curve(Bio_Cat, OCsvmscores)\n",
        "  roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "  print(f'The AUC Score for Questions {Comb1} ----- {roc_auc5}')\n",
        "  print('*****************************************************************************************************************************************')\n",
        "  \n",
        "  \n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "  # plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver operating characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(OCsvmresults == -1)\n",
        "  # #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "  # np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "\n",
        "  my_dict[\"Combinations\"].append(Comb1)\n",
        "  my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "id": "1cmixCbfnwlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c24248ec-70eb-4edb-ac3e-dcec23c2c1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The AUC Score for Questions [22, 13, 23, 20, 24, 12, 14] ----- 0.5523179180530775\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18334\n",
            "The AUC Score for Questions [3, 23, 4, 12, 40, 15, 8] ----- 0.505286444519458\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18335\n",
            "The AUC Score for Questions [36, 8, 26, 23, 9, 24, 30] ----- 0.7038405587436305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18336\n",
            "The AUC Score for Questions [31, 29, 19, 15, 4, 1, 12] ----- 0.5880752600022504\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18337\n",
            "The AUC Score for Questions [27, 5, 17, 18, 32, 10, 14] ----- 0.46601284338782534\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18338\n",
            "The AUC Score for Questions [37, 2, 18, 6, 16, 30, 0] ----- 0.44528901641188856\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18339\n",
            "The AUC Score for Questions [17, 25, 16, 10, 39, 19, 7] ----- 0.5484178842969893\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18340\n",
            "The AUC Score for Questions [17, 9, 24, 10, 21, 13, 40] ----- 0.6225506743180467\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18341\n",
            "The AUC Score for Questions [33, 7, 11, 35, 18, 40, 23] ----- 0.4289394158589317\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18342\n",
            "The AUC Score for Questions [25, 5, 36, 34, 32, 21, 29] ----- 0.5254838372635066\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18343\n",
            "The AUC Score for Questions [6, 17, 29, 32, 18, 24, 15] ----- 0.6846719229718217\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18344\n",
            "The AUC Score for Questions [9, 26, 15, 25, 2, 8, 32] ----- 0.5106391956406423\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18345\n",
            "The AUC Score for Questions [20, 35, 13, 28, 34, 5, 1] ----- 0.4726133641960425\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18346\n",
            "The AUC Score for Questions [15, 18, 31, 14, 22, 40, 36] ----- 0.5813160052080821\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18347\n",
            "The AUC Score for Questions [31, 28, 39, 10, 32, 7, 5] ----- 0.40604555464467695\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18348\n",
            "The AUC Score for Questions [14, 1, 31, 8, 36, 23, 18] ----- 0.6067536287794763\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18349\n",
            "The AUC Score for Questions [23, 21, 8, 14, 16, 25, 5] ----- 0.553059346417836\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18350\n",
            "The AUC Score for Questions [25, 14, 10, 22, 5, 16, 19] ----- 0.5003998489013197\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18351\n",
            "The AUC Score for Questions [18, 9, 8, 24, 6, 40, 13] ----- 0.5556111459388211\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18352\n",
            "The AUC Score for Questions [40, 26, 1, 8, 20, 18, 23] ----- 0.5441200109305429\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18353\n",
            "The AUC Score for Questions [30, 23, 40, 27, 14, 39, 22] ----- 0.6120159618073974\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18354\n",
            "The AUC Score for Questions [39, 15, 12, 5, 26, 40, 32] ----- 0.47608943755927413\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18355\n",
            "The AUC Score for Questions [33, 27, 6, 2, 20, 3, 8] ----- 0.39202874089791195\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18356\n",
            "The AUC Score for Questions [16, 12, 1, 20, 34, 13, 23] ----- 0.44472038706981076\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18357\n",
            "The AUC Score for Questions [12, 2, 24, 3, 1, 16, 21] ----- 0.562026811978589\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18358\n",
            "The AUC Score for Questions [0, 19, 13, 2, 31, 25, 4] ----- 0.4510275513976627\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18359\n",
            "The AUC Score for Questions [27, 19, 21, 11, 29, 9, 25] ----- 0.6832131777338413\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18360\n",
            "The AUC Score for Questions [23, 38, 13, 27, 7, 26, 19] ----- 0.5512992075356448\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18361\n",
            "The AUC Score for Questions [5, 26, 2, 8, 19, 24, 38] ----- 0.5323234636961309\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18362\n",
            "The AUC Score for Questions [7, 27, 18, 23, 32, 12, 26] ----- 0.574695391490251\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18363\n",
            "The AUC Score for Questions [29, 20, 21, 33, 26, 28, 40] ----- 0.5529528539968817\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18364\n",
            "The AUC Score for Questions [18, 26, 27, 9, 24, 8, 16] ----- 0.6908826413335262\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18365\n",
            "The AUC Score for Questions [15, 23, 5, 31, 35, 29, 14] ----- 0.5676086222693736\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18366\n",
            "The AUC Score for Questions [8, 36, 10, 20, 32, 27, 34] ----- 0.5594448730931829\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18367\n",
            "The AUC Score for Questions [19, 23, 9, 34, 10, 7, 37] ----- 0.5995442928099532\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18368\n",
            "The AUC Score for Questions [8, 11, 26, 3, 21, 13, 28] ----- 0.5456551092250567\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18369\n",
            "The AUC Score for Questions [34, 24, 4, 6, 19, 33, 10] ----- 0.3770434489077494\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18370\n",
            "The AUC Score for Questions [27, 29, 24, 16, 26, 30, 21] ----- 0.7097096976418961\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18371\n",
            "The AUC Score for Questions [12, 27, 1, 29, 5, 23, 32] ----- 0.5415360627541752\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18372\n",
            "The AUC Score for Questions [40, 0, 20, 29, 22, 36, 19] ----- 0.6545124656411245\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18373\n",
            "The AUC Score for Questions [2, 18, 1, 15, 0, 12, 21] ----- 0.5014908938933629\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18374\n",
            "The AUC Score for Questions [38, 23, 37, 39, 7, 34, 27] ----- 0.4443788076063719\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18375\n",
            "The AUC Score for Questions [20, 37, 28, 19, 4, 1, 27] ----- 0.5163375448071884\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18376\n",
            "The AUC Score for Questions [14, 1, 15, 40, 18, 23, 30] ----- 0.5967433412097539\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18377\n",
            "The AUC Score for Questions [8, 18, 39, 7, 32, 31, 11] ----- 0.51532486216264\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18378\n",
            "The AUC Score for Questions [34, 25, 7, 39, 12, 37, 14] ----- 0.43964692739226185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18379\n",
            "The AUC Score for Questions [24, 38, 25, 0, 19, 14, 11] ----- 0.6278893604025011\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18380\n",
            "The AUC Score for Questions [36, 28, 37, 23, 6, 9, 11] ----- 0.5365490025879668\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18381\n",
            "The AUC Score for Questions [14, 15, 20, 23, 34, 17, 3] ----- 0.6001189500249153\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18382\n",
            "The AUC Score for Questions [29, 2, 20, 24, 39, 31, 13] ----- 0.5576947806657987\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18383\n",
            "The AUC Score for Questions [37, 19, 12, 28, 26, 13, 34] ----- 0.43665308385976753\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18384\n",
            "The AUC Score for Questions [0, 16, 40, 36, 35, 4, 22] ----- 0.5069400909806947\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18385\n",
            "The AUC Score for Questions [40, 20, 36, 21, 17, 1, 2] ----- 0.5351746475703653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18386\n",
            "The AUC Score for Questions [5, 21, 23, 36, 30, 13, 7] ----- 0.47237224928067384\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18387\n",
            "The AUC Score for Questions [28, 31, 39, 23, 9, 1, 29] ----- 0.70688463455016\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18388\n",
            "The AUC Score for Questions [12, 14, 5, 2, 30, 31, 36] ----- 0.4967248557329089\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18389\n",
            "The AUC Score for Questions [22, 28, 8, 34, 16, 32, 20] ----- 0.5610804359357671\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18390\n",
            "The AUC Score for Questions [27, 1, 39, 34, 3, 14, 11] ----- 0.538948095995885\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18391\n",
            "The AUC Score for Questions [29, 32, 28, 24, 37, 19, 10] ----- 0.433385976756522\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18392\n",
            "The AUC Score for Questions [5, 34, 2, 29, 25, 21, 8] ----- 0.5044184308241307\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18393\n",
            "The AUC Score for Questions [19, 0, 23, 1, 5, 30, 21] ----- 0.5998336307083956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18394\n",
            "The AUC Score for Questions [5, 27, 18, 17, 26, 16, 32] ----- 0.5703874716689974\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18395\n",
            "The AUC Score for Questions [39, 23, 24, 15, 22, 12, 8] ----- 0.5887222516918231\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18396\n",
            "The AUC Score for Questions [40, 37, 27, 38, 29, 8, 18] ----- 0.4584538907910177\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18397\n",
            "The AUC Score for Questions [36, 38, 1, 14, 2, 9, 25] ----- 0.48977672758836865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18398\n",
            "The AUC Score for Questions [3, 37, 21, 9, 28, 27, 33] ----- 0.5340615003777467\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18399\n",
            "The AUC Score for Questions [7, 39, 18, 31, 5, 22, 2] ----- 0.3547443378180708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18400\n",
            "The AUC Score for Questions [34, 19, 7, 10, 30, 29, 37] ----- 0.6261473051389626\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18401\n",
            "The AUC Score for Questions [23, 17, 19, 11, 9, 21, 7] ----- 0.6800766745430872\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18402\n",
            "The AUC Score for Questions [26, 4, 30, 11, 24, 8, 31] ----- 0.6537589815305974\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18403\n",
            "The AUC Score for Questions [6, 23, 26, 12, 31, 24, 4] ----- 0.502051486071595\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18404\n",
            "The AUC Score for Questions [28, 34, 40, 4, 9, 30, 16] ----- 0.5384357268007266\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18405\n",
            "The AUC Score for Questions [8, 20, 28, 4, 36, 24, 2] ----- 0.4504649499284692\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18406\n",
            "The AUC Score for Questions [26, 13, 17, 4, 10, 24, 19] ----- 0.6127071578981209\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18407\n",
            "The AUC Score for Questions [29, 27, 33, 21, 31, 0, 11] ----- 0.6587098744595007\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18408\n",
            "The AUC Score for Questions [14, 37, 38, 25, 2, 21, 24] ----- 0.5357392583305204\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18409\n",
            "The AUC Score for Questions [36, 27, 14, 9, 15, 23, 2] ----- 0.5843440066869203\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18410\n",
            "The AUC Score for Questions [22, 12, 38, 24, 5, 39, 9] ----- 0.4022680876372346\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18411\n",
            "The AUC Score for Questions [8, 22, 3, 10, 17, 31, 13] ----- 0.47598495442928096\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18412\n",
            "The AUC Score for Questions [37, 17, 28, 33, 14, 4, 40] ----- 0.48231221166674704\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18413\n",
            "The AUC Score for Questions [29, 32, 12, 25, 3, 8, 7] ----- 0.5144668949221199\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18414\n",
            "The AUC Score for Questions [16, 13, 0, 12, 14, 7, 10] ----- 0.44799352204594045\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18415\n",
            "The AUC Score for Questions [11, 16, 19, 18, 39, 40, 37] ----- 0.43157560560029573\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18416\n",
            "The AUC Score for Questions [16, 6, 40, 21, 25, 24, 11] ----- 0.5449558759704876\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18417\n",
            "The AUC Score for Questions [35, 8, 32, 24, 40, 34, 18] ----- 0.45887986047483564\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18418\n",
            "The AUC Score for Questions [28, 19, 29, 15, 23, 12, 13] ----- 0.47044734853964737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18419\n",
            "The AUC Score for Questions [20, 27, 18, 40, 34, 15, 28] ----- 0.521067415730337\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18420\n",
            "The AUC Score for Questions [25, 8, 38, 31, 12, 35, 19] ----- 0.4085491311825883\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18421\n",
            "The AUC Score for Questions [33, 20, 25, 30, 14, 38, 29] ----- 0.49837046503030014\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18422\n",
            "The AUC Score for Questions [29, 14, 6, 15, 40, 0, 10] ----- 0.5107818552989021\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18423\n",
            "The AUC Score for Questions [1, 36, 28, 20, 29, 8, 39] ----- 0.635265467521821\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18424\n",
            "The AUC Score for Questions [33, 4, 8, 27, 36, 17, 11] ----- 0.5935505778720805\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18425\n",
            "The AUC Score for Questions [16, 30, 0, 25, 38, 13, 19] ----- 0.48116289723682304\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18426\n",
            "The AUC Score for Questions [24, 26, 6, 39, 38, 2, 10] ----- 0.42568637379241614\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18427\n",
            "The AUC Score for Questions [17, 25, 2, 39, 35, 7, 23] ----- 0.3879699731558728\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18428\n",
            "The AUC Score for Questions [12, 23, 37, 7, 17, 38, 24] ----- 0.48849479995499184\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18429\n",
            "The AUC Score for Questions [28, 18, 19, 40, 33, 7, 32] ----- 0.40350782016042186\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18430\n",
            "The AUC Score for Questions [3, 21, 18, 5, 20, 32, 1] ----- 0.46597466685955863\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18431\n",
            "The AUC Score for Questions [1, 14, 29, 13, 35, 40, 23] ----- 0.5490387552040636\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18432\n",
            "The AUC Score for Questions [30, 21, 34, 40, 38, 24, 13] ----- 0.41477793316294553\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18433\n",
            "The AUC Score for Questions [11, 12, 33, 39, 25, 8, 14] ----- 0.4160779444149749\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18434\n",
            "The AUC Score for Questions [33, 38, 14, 0, 19, 39, 29] ----- 0.5163656748806481\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18435\n",
            "The AUC Score for Questions [20, 22, 40, 14, 25, 36, 21] ----- 0.49965239266367684\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18436\n",
            "The AUC Score for Questions [36, 2, 11, 21, 16, 28, 8] ----- 0.5071068621304914\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18437\n",
            "The AUC Score for Questions [10, 19, 9, 15, 38, 29, 36] ----- 0.6271579784925496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18438\n",
            "The AUC Score for Questions [14, 18, 32, 39, 34, 36, 28] ----- 0.5247745575541303\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18439\n",
            "The AUC Score for Questions [28, 31, 0, 25, 14, 35, 21] ----- 0.48751024738390314\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18440\n",
            "The AUC Score for Questions [1, 19, 6, 22, 34, 15, 11] ----- 0.5425487453987237\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18441\n",
            "The AUC Score for Questions [5, 0, 17, 4, 9, 10, 19] ----- 0.6469756152448924\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18442\n",
            "The AUC Score for Questions [26, 13, 4, 5, 32, 37, 16] ----- 0.4513349729147578\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18443\n",
            "The AUC Score for Questions [31, 37, 8, 34, 39, 18, 20] ----- 0.5612572535403707\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18444\n",
            "The AUC Score for Questions [6, 14, 24, 28, 38, 15, 29] ----- 0.6065828390477568\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18445\n",
            "The AUC Score for Questions [26, 14, 32, 16, 12, 23, 11] ----- 0.4515760878301265\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18446\n",
            "The AUC Score for Questions [30, 1, 40, 37, 32, 31, 18] ----- 0.42325714102007683\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18447\n",
            "The AUC Score for Questions [33, 23, 31, 37, 1, 9, 20] ----- 0.5048484190898715\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18448\n",
            "The AUC Score for Questions [10, 40, 39, 11, 3, 0, 33] ----- 0.3982515150053849\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18449\n",
            "The AUC Score for Questions [15, 39, 19, 24, 1, 14, 33] ----- 0.5813079680442366\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18450\n",
            "The AUC Score for Questions [2, 6, 8, 5, 23, 7, 10] ----- 0.35321727668740255\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18451\n",
            "The AUC Score for Questions [18, 34, 2, 21, 19, 17, 4] ----- 0.4435590168941184\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18452\n",
            "The AUC Score for Questions [6, 0, 14, 27, 1, 31, 32] ----- 0.5653742907202907\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18453\n",
            "The AUC Score for Questions [19, 12, 25, 34, 23, 6, 27] ----- 0.5019449936506406\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18454\n",
            "The AUC Score for Questions [24, 29, 23, 21, 37, 3, 18] ----- 0.5849246917747666\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18455\n",
            "The AUC Score for Questions [3, 19, 4, 40, 18, 2, 14] ----- 0.3964692739226181\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18456\n",
            "The AUC Score for Questions [9, 8, 10, 19, 22, 23, 26] ----- 0.6333928083457909\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18457\n",
            "The AUC Score for Questions [17, 24, 39, 22, 27, 13, 38] ----- 0.4967047628232949\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18458\n",
            "The AUC Score for Questions [32, 21, 5, 36, 0, 31, 16] ----- 0.45019369564867945\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18459\n",
            "The AUC Score for Questions [20, 1, 3, 12, 36, 22, 7] ----- 0.5136671971194805\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18460\n",
            "The AUC Score for Questions [9, 20, 2, 29, 6, 21, 4] ----- 0.5970387069810805\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18461\n",
            "The AUC Score for Questions [36, 5, 8, 20, 34, 17, 22] ----- 0.5310837311729437\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18462\n",
            "The AUC Score for Questions [23, 17, 8, 11, 40, 38, 21] ----- 0.4259897767275884\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18463\n",
            "The AUC Score for Questions [14, 30, 26, 21, 35, 36, 19] ----- 0.5556292295574738\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18464\n",
            "The AUC Score for Questions [23, 33, 13, 1, 7, 8, 9] ----- 0.6190866567005834\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18465\n",
            "The AUC Score for Questions [29, 28, 20, 1, 7, 32, 39] ----- 0.6261513237208853\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18466\n",
            "The AUC Score for Questions [15, 25, 10, 32, 29, 33, 0] ----- 0.46815675684364505\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18467\n",
            "The AUC Score for Questions [39, 31, 12, 17, 40, 6, 28] ----- 0.4737626786259665\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18468\n",
            "The AUC Score for Questions [9, 26, 34, 1, 6, 3, 18] ----- 0.5296812460818827\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18469\n",
            "The AUC Score for Questions [35, 6, 40, 22, 39, 13, 38] ----- 0.3542862194788703\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18470\n",
            "The AUC Score for Questions [0, 7, 9, 14, 15, 20, 3] ----- 0.6228219285978364\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18471\n",
            "The AUC Score for Questions [32, 35, 8, 20, 16, 18, 24] ----- 0.4689685103920529\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18472\n",
            "The AUC Score for Questions [22, 38, 27, 24, 29, 23, 2] ----- 0.6004303901239331\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18473\n",
            "The AUC Score for Questions [22, 39, 14, 15, 34, 30, 8] ----- 0.5501920882159104\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18474\n",
            "The AUC Score for Questions [6, 3, 40, 33, 23, 9, 11] ----- 0.46789554901866226\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18475\n",
            "The AUC Score for Questions [40, 36, 12, 14, 37, 32, 34] ----- 0.4231827972545048\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18476\n",
            "The AUC Score for Questions [38, 17, 6, 24, 34, 11, 3] ----- 0.5332437189564547\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18477\n",
            "The AUC Score for Questions [13, 39, 36, 24, 23, 15, 0] ----- 0.6523143013293469\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18478\n",
            "The AUC Score for Questions [9, 31, 1, 32, 24, 25, 35] ----- 0.5799537059362492\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18479\n",
            "The AUC Score for Questions [9, 13, 31, 20, 10, 16, 29] ----- 0.5996427480670621\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18480\n",
            "The AUC Score for Questions [21, 1, 18, 25, 13, 26, 11] ----- 0.5476242143672341\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18481\n",
            "The AUC Score for Questions [12, 11, 37, 19, 22, 40, 1] ----- 0.35111957692369516\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18482\n",
            "The AUC Score for Questions [17, 29, 30, 16, 7, 18, 11] ----- 0.6146179936024175\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18483\n",
            "The AUC Score for Questions [32, 14, 28, 22, 19, 12, 23] ----- 0.3927701692626706\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18484\n",
            "The AUC Score for Questions [38, 9, 13, 22, 8, 27, 26] ----- 0.547276607030911\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18485\n",
            "The AUC Score for Questions [4, 22, 26, 7, 9, 29, 10] ----- 0.6413114240246901\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18486\n",
            "The AUC Score for Questions [36, 2, 11, 24, 10, 15, 27] ----- 0.6323560142097058\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18487\n",
            "The AUC Score for Questions [35, 8, 14, 4, 25, 31, 1] ----- 0.4031401199144846\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18488\n",
            "The AUC Score for Questions [36, 0, 33, 23, 40, 3, 37] ----- 0.5144468020125058\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18489\n",
            "The AUC Score for Questions [20, 37, 19, 1, 16, 2, 5] ----- 0.44525083988362185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18490\n",
            "The AUC Score for Questions [16, 1, 39, 31, 30, 20, 0] ----- 0.5482953175483436\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18491\n",
            "The AUC Score for Questions [8, 23, 12, 21, 28, 35, 37] ----- 0.4475414315796241\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18492\n",
            "The AUC Score for Questions [6, 11, 36, 27, 26, 32, 7] ----- 0.5922244458375527\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18493\n",
            "The AUC Score for Questions [37, 14, 36, 35, 0, 38, 5] ----- 0.44535532301361497\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18494\n",
            "The AUC Score for Questions [15, 8, 16, 38, 11, 28, 25] ----- 0.5080873961196574\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18495\n",
            "The AUC Score for Questions [19, 20, 11, 25, 5, 13, 6] ----- 0.4758000996608317\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18496\n",
            "The AUC Score for Questions [30, 23, 8, 24, 11, 37, 28] ----- 0.5081677677581136\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18497\n",
            "The AUC Score for Questions [36, 29, 16, 32, 28, 26, 3] ----- 0.5787561685232515\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18498\n",
            "The AUC Score for Questions [18, 26, 1, 39, 19, 25, 5] ----- 0.5120477086045876\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18499\n",
            "The AUC Score for Questions [9, 19, 40, 37, 27, 32, 13] ----- 0.5147903907669061\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18500\n",
            "The AUC Score for Questions [26, 22, 11, 37, 29, 32, 20] ----- 0.48691549725932715\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18501\n",
            "The AUC Score for Questions [9, 27, 13, 10, 21, 26, 16] ----- 0.5780288051952227\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18502\n",
            "The AUC Score for Questions [37, 18, 33, 12, 20, 24, 17] ----- 0.48588874957804884\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18503\n",
            "The AUC Score for Questions [8, 15, 23, 4, 2, 10, 39] ----- 0.4354676021925383\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18504\n",
            "The AUC Score for Questions [2, 33, 17, 34, 6, 22, 23] ----- 0.3490881837617142\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18505\n",
            "The AUC Score for Questions [16, 37, 32, 11, 8, 13, 28] ----- 0.47518927520856435\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18506\n",
            "The AUC Score for Questions [37, 27, 12, 34, 32, 40, 7] ----- 0.45610703894809596\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18507\n",
            "The AUC Score for Questions [2, 25, 28, 14, 34, 11, 24] ----- 0.5856580829756796\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18508\n",
            "The AUC Score for Questions [14, 6, 7, 12, 31, 29, 34] ----- 0.5357834627316712\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18509\n",
            "The AUC Score for Questions [25, 17, 1, 3, 10, 33, 29] ----- 0.5664874379129092\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18510\n",
            "The AUC Score for Questions [19, 17, 15, 21, 29, 27, 25] ----- 0.6584908617447076\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18511\n",
            "The AUC Score for Questions [22, 15, 28, 7, 25, 12, 37] ----- 0.46584808152899004\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18512\n",
            "The AUC Score for Questions [34, 5, 18, 22, 0, 3, 11] ----- 0.5232012827313498\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18513\n",
            "The AUC Score for Questions [12, 24, 4, 27, 29, 10, 17] ----- 0.6465094597418464\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18514\n",
            "The AUC Score for Questions [29, 24, 33, 3, 31, 15, 38] ----- 0.6127855202456158\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18515\n",
            "The AUC Score for Questions [33, 25, 40, 6, 0, 3, 35] ----- 0.3537195994277539\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18516\n",
            "The AUC Score for Questions [14, 5, 12, 21, 11, 0, 29] ----- 0.5110109144685023\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18517\n",
            "The AUC Score for Questions [5, 18, 0, 33, 14, 39, 26] ----- 0.49059651830062206\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18518\n",
            "The AUC Score for Questions [0, 34, 28, 27, 13, 30, 23] ----- 0.5677271704360964\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18519\n",
            "The AUC Score for Questions [15, 37, 21, 36, 25, 19, 22] ----- 0.5011975374129977\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18520\n",
            "The AUC Score for Questions [31, 36, 37, 40, 18, 21, 16] ----- 0.422029464242658\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18521\n",
            "The AUC Score for Questions [25, 6, 9, 15, 3, 2, 14] ----- 0.4480759029753581\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18522\n",
            "The AUC Score for Questions [18, 15, 40, 35, 5, 9, 3] ----- 0.5152706113066821\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18523\n",
            "The AUC Score for Questions [15, 33, 38, 27, 23, 20, 37] ----- 0.47486377007281666\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18524\n",
            "The AUC Score for Questions [1, 12, 20, 22, 19, 31, 7] ----- 0.544051695037855\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18525\n",
            "The AUC Score for Questions [39, 29, 28, 31, 12, 22, 5] ----- 0.4750225040587677\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18526\n",
            "The AUC Score for Questions [6, 21, 0, 4, 24, 26, 35] ----- 0.4690307984118564\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18527\n",
            "The AUC Score for Questions [33, 2, 34, 19, 25, 27, 16] ----- 0.4929333236887367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18528\n",
            "The AUC Score for Questions [39, 8, 38, 34, 18, 12, 29] ----- 0.5143161981000145\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18529\n",
            "The AUC Score for Questions [19, 11, 1, 31, 36, 6, 21] ----- 0.6301417755702368\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18530\n",
            "The AUC Score for Questions [20, 6, 8, 0, 28, 14, 4] ----- 0.4399362652907042\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18531\n",
            "The AUC Score for Questions [26, 36, 22, 25, 16, 23, 29] ----- 0.612524312420633\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18532\n",
            "The AUC Score for Questions [11, 6, 31, 17, 27, 26, 2] ----- 0.5276016299368279\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18533\n",
            "The AUC Score for Questions [25, 10, 4, 31, 8, 6, 0] ----- 0.40428943434440856\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18534\n",
            "The AUC Score for Questions [37, 22, 9, 28, 25, 12, 19] ----- 0.45973782771535576\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18535\n",
            "The AUC Score for Questions [8, 4, 38, 18, 17, 32, 39] ----- 0.4102911864461269\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18536\n",
            "The AUC Score for Questions [2, 7, 35, 37, 38, 15, 13] ----- 0.41010432238671624\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18537\n",
            "The AUC Score for Questions [7, 15, 16, 5, 2, 30, 32] ----- 0.5550224236871293\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18538\n",
            "The AUC Score for Questions [17, 7, 26, 37, 2, 5, 27] ----- 0.4892502933564804\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18539\n",
            "The AUC Score for Questions [28, 6, 3, 17, 37, 10, 11] ----- 0.5481667229268136\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18540\n",
            "The AUC Score for Questions [39, 27, 34, 16, 25, 15, 29] ----- 0.5389159473405025\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18541\n",
            "The AUC Score for Questions [0, 28, 2, 4, 33, 3, 23] ----- 0.3944097506871775\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18542\n",
            "The AUC Score for Questions [38, 33, 17, 4, 21, 0, 31] ----- 0.4830898072688109\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18543\n",
            "The AUC Score for Questions [16, 5, 40, 4, 1, 35, 6] ----- 0.48444808795872113\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18544\n",
            "The AUC Score for Questions [3, 4, 21, 39, 37, 28, 12] ----- 0.44139099194676185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18545\n",
            "The AUC Score for Questions [7, 12, 25, 39, 5, 38, 37] ----- 0.3512642458729164\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18546\n",
            "The AUC Score for Questions [33, 8, 27, 37, 26, 21, 38] ----- 0.5887544003472054\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18547\n",
            "The AUC Score for Questions [18, 4, 6, 0, 19, 17, 39] ----- 0.39960778640433364\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18548\n",
            "The AUC Score for Questions [27, 40, 12, 35, 18, 30, 3] ----- 0.410747295494366\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18549\n",
            "The AUC Score for Questions [6, 7, 9, 12, 37, 19, 29] ----- 0.48907950362476094\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18550\n",
            "The AUC Score for Questions [28, 35, 19, 0, 12, 36, 40] ----- 0.4811809808554757\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18551\n",
            "The AUC Score for Questions [13, 17, 29, 15, 28, 31, 30] ----- 0.624117921267943\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18552\n",
            "The AUC Score for Questions [19, 3, 35, 6, 0, 2, 27] ----- 0.4435007474562377\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18553\n",
            "The AUC Score for Questions [16, 25, 10, 35, 31, 28, 30] ----- 0.47793396666184434\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18554\n",
            "The AUC Score for Questions [8, 31, 15, 34, 0, 12, 33] ----- 0.4847032679108196\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18555\n",
            "The AUC Score for Questions [20, 16, 32, 14, 21, 35, 38] ----- 0.46484142675732587\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18556\n",
            "The AUC Score for Questions [30, 31, 9, 10, 16, 24, 29] ----- 0.6357577438073653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18557\n",
            "The AUC Score for Questions [32, 12, 29, 9, 35, 15, 4] ----- 0.523122920383855\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18558\n",
            "The AUC Score for Questions [14, 4, 22, 24, 12, 8, 29] ----- 0.6285383613830351\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18559\n",
            "The AUC Score for Questions [8, 5, 1, 16, 33, 39, 26] ----- 0.5136671971194805\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18560\n",
            "The AUC Score for Questions [38, 20, 33, 7, 29, 12, 28] ----- 0.5070747134751089\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18561\n",
            "The AUC Score for Questions [16, 37, 29, 5, 19, 27, 14] ----- 0.5658344183504525\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18562\n",
            "The AUC Score for Questions [39, 13, 3, 20, 36, 32, 11] ----- 0.5292251370336436\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18563\n",
            "The AUC Score for Questions [1, 31, 21, 25, 14, 38, 3] ----- 0.4809880889231808\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18564\n",
            "The AUC Score for Questions [1, 10, 21, 15, 2, 4, 18] ----- 0.5443892559193712\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18565\n",
            "The AUC Score for Questions [34, 35, 2, 24, 5, 32, 31] ----- 0.36013526546752184\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18566\n",
            "The AUC Score for Questions [2, 21, 17, 23, 38, 9, 35] ----- 0.5113886611692465\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18567\n",
            "The AUC Score for Questions [26, 8, 17, 22, 0, 10, 23] ----- 0.5261328382440404\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18568\n",
            "The AUC Score for Questions [23, 26, 13, 31, 36, 0, 32] ----- 0.5214873575412708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18569\n",
            "The AUC Score for Questions [28, 6, 17, 24, 21, 14, 10] ----- 0.5836889778335022\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18570\n",
            "The AUC Score for Questions [12, 37, 3, 0, 38, 33, 24] ----- 0.45875930301715123\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18571\n",
            "The AUC Score for Questions [21, 17, 23, 16, 0, 18, 34] ----- 0.540692160550385\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18572\n",
            "The AUC Score for Questions [32, 28, 6, 37, 19, 39, 31] ----- 0.3469924932889682\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18573\n",
            "The AUC Score for Questions [2, 16, 9, 32, 22, 37, 0] ----- 0.5209388211088071\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18574\n",
            "The AUC Score for Questions [20, 7, 4, 31, 32, 37, 8] ----- 0.4459239523556927\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18575\n",
            "The AUC Score for Questions [22, 28, 35, 14, 11, 8, 36] ----- 0.49897526160968314\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18576\n",
            "The AUC Score for Questions [35, 32, 20, 17, 38, 10, 30] ----- 0.436655093150729\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18577\n",
            "The AUC Score for Questions [7, 30, 31, 0, 34, 38, 22] ----- 0.5016014048962403\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18578\n",
            "The AUC Score for Questions [13, 9, 29, 10, 15, 19, 4] ----- 0.6355929819485299\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18579\n",
            "The AUC Score for Questions [26, 17, 10, 37, 25, 8, 24] ----- 0.5717136037035251\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18580\n",
            "The AUC Score for Questions [20, 3, 4, 8, 12, 5, 18] ----- 0.4115952162800791\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18581\n",
            "The AUC Score for Questions [36, 1, 20, 18, 0, 38, 4] ----- 0.5268039414251499\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18582\n",
            "The AUC Score for Questions [15, 3, 37, 6, 38, 2, 25] ----- 0.38097964990114286\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18583\n",
            "The AUC Score for Questions [18, 27, 3, 4, 23, 19, 20] ----- 0.47451616273649355\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18584\n",
            "The AUC Score for Questions [30, 14, 20, 8, 5, 28, 13] ----- 0.4853924547105817\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18585\n",
            "The AUC Score for Questions [14, 1, 23, 19, 6, 13, 40] ----- 0.49150069923325457\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18586\n",
            "The AUC Score for Questions [4, 34, 13, 28, 6, 21, 39] ----- 0.4945367378759383\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18587\n",
            "The AUC Score for Questions [12, 38, 14, 21, 29, 25, 34] ----- 0.5254858465544678\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18588\n",
            "The AUC Score for Questions [35, 11, 19, 22, 6, 18, 3] ----- 0.3844075002813008\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18589\n",
            "The AUC Score for Questions [8, 30, 12, 3, 33, 32, 11] ----- 0.4264579415215959\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18590\n",
            "The AUC Score for Questions [16, 11, 9, 22, 3, 13, 19] ----- 0.6638918358489656\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18591\n",
            "The AUC Score for Questions [9, 12, 13, 22, 31, 37, 27] ----- 0.3925250357653791\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18592\n",
            "The AUC Score for Questions [20, 22, 23, 27, 18, 40, 11] ----- 0.4564305347928823\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18593\n",
            "The AUC Score for Questions [6, 3, 0, 21, 28, 33, 37] ----- 0.5506743180466478\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18594\n",
            "The AUC Score for Questions [28, 12, 23, 5, 10, 19, 3] ----- 0.34806143608043594\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18595\n",
            "The AUC Score for Questions [7, 36, 28, 2, 15, 19, 1] ----- 0.6260910449920432\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18596\n",
            "The AUC Score for Questions [13, 31, 32, 2, 25, 26, 23] ----- 0.45034841105270773\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18597\n",
            "The AUC Score for Questions [8, 7, 27, 40, 1, 26, 38] ----- 0.5663588432913794\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18598\n",
            "The AUC Score for Questions [6, 3, 7, 26, 39, 20, 30] ----- 0.4385558824002186\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18599\n",
            "The AUC Score for Questions [0, 10, 30, 22, 32, 33, 38] ----- 0.4301590554725049\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18600\n",
            "The AUC Score for Questions [15, 35, 40, 38, 8, 21, 11] ----- 0.5165766504315956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18601\n",
            "The AUC Score for Questions [2, 40, 26, 28, 12, 4, 37] ----- 0.35240150455707187\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18602\n",
            "The AUC Score for Questions [8, 22, 21, 24, 10, 29, 33] ----- 0.5895862468052273\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18603\n",
            "The AUC Score for Questions [21, 17, 6, 26, 23, 40, 12] ----- 0.43042227258844895\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18604\n",
            "The AUC Score for Questions [22, 7, 19, 21, 0, 39, 12] ----- 0.515334908617447\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18605\n",
            "The AUC Score for Questions [23, 34, 33, 8, 31, 26, 39] ----- 0.5202074391988555\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18606\n",
            "The AUC Score for Questions [10, 40, 26, 3, 21, 2, 4] ----- 0.4637463631833599\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18607\n",
            "The AUC Score for Questions [40, 26, 28, 20, 6, 39, 4] ----- 0.34453914902509203\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18608\n",
            "The AUC Score for Questions [13, 26, 32, 30, 15, 5, 33] ----- 0.4279608911607272\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18609\n",
            "The AUC Score for Questions [8, 37, 18, 36, 19, 0, 38] ----- 0.48996359164777925\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18610\n",
            "The AUC Score for Questions [14, 40, 23, 3, 18, 20, 6] ----- 0.3770173281252511\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18611\n",
            "The AUC Score for Questions [8, 14, 16, 11, 37, 32, 33] ----- 0.4448188423269197\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18612\n",
            "The AUC Score for Questions [36, 13, 19, 34, 15, 31, 25] ----- 0.5174064875986562\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18613\n",
            "The AUC Score for Questions [13, 6, 30, 0, 39, 19, 37] ----- 0.3778773046567327\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18614\n",
            "The AUC Score for Questions [5, 21, 16, 32, 1, 18, 7] ----- 0.5001004645480702\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18615\n",
            "The AUC Score for Questions [2, 26, 27, 32, 30, 12, 18] ----- 0.5217184260018325\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18616\n",
            "The AUC Score for Questions [19, 23, 9, 18, 3, 17, 29] ----- 0.7494916493867645\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18617\n",
            "The AUC Score for Questions [32, 39, 35, 12, 9, 6, 29] ----- 0.5240592499718699\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18618\n",
            "The AUC Score for Questions [38, 15, 29, 32, 22, 19, 16] ----- 0.6235372361800967\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18619\n",
            "The AUC Score for Questions [14, 22, 32, 20, 3, 29, 18] ----- 0.5092688592049637\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18620\n",
            "The AUC Score for Questions [37, 15, 40, 23, 2, 17, 5] ----- 0.4196203243799328\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18621\n",
            "The AUC Score for Questions [1, 30, 37, 14, 28, 3, 23] ----- 0.4990918004854447\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18622\n",
            "The AUC Score for Questions [18, 4, 6, 27, 35, 17, 16] ----- 0.47597691726543534\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18623\n",
            "The AUC Score for Questions [0, 6, 13, 16, 38, 3, 28] ----- 0.4682552121007539\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18624\n",
            "The AUC Score for Questions [40, 33, 30, 22, 32, 2, 8] ----- 0.45993473822957354\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18625\n",
            "The AUC Score for Questions [20, 13, 1, 38, 2, 18, 7] ----- 0.4356906334892543\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18626\n",
            "The AUC Score for Questions [27, 22, 3, 25, 39, 5, 32] ----- 0.3443944800758708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18627\n",
            "The AUC Score for Questions [32, 16, 19, 40, 21, 25, 35] ----- 0.45930382086769217\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18628\n",
            "The AUC Score for Questions [16, 34, 5, 14, 15, 33, 13] ----- 0.5073901721560495\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18629\n",
            "The AUC Score for Questions [24, 4, 20, 6, 39, 38, 30] ----- 0.3402030991303788\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18630\n",
            "The AUC Score for Questions [6, 1, 35, 13, 34, 4, 27] ----- 0.4779299480799216\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18631\n",
            "The AUC Score for Questions [5, 25, 23, 38, 35, 28, 29] ----- 0.5562159425182042\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18632\n",
            "The AUC Score for Questions [17, 8, 40, 32, 11, 25, 27] ----- 0.5061645046695922\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18633\n",
            "The AUC Score for Questions [9, 16, 30, 29, 2, 24, 6] ----- 0.6481369854205848\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18634\n",
            "The AUC Score for Questions [38, 10, 23, 32, 30, 28, 5] ----- 0.33650600376139267\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18635\n",
            "The AUC Score for Questions [8, 37, 6, 33, 9, 18, 40] ----- 0.5168418768385012\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18636\n",
            "The AUC Score for Questions [21, 18, 6, 15, 1, 8, 10] ----- 0.5477729018983781\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18637\n",
            "The AUC Score for Questions [27, 32, 6, 26, 9, 29, 11] ----- 0.6251024738390316\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18638\n",
            "The AUC Score for Questions [33, 24, 16, 25, 8, 19, 7] ----- 0.613960955458038\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18639\n",
            "The AUC Score for Questions [16, 23, 8, 2, 26, 5, 30] ----- 0.5882922634260822\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18640\n",
            "The AUC Score for Questions [35, 32, 38, 27, 10, 20, 25] ----- 0.38390316824998794\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18641\n",
            "The AUC Score for Questions [31, 10, 34, 35, 27, 33, 17] ----- 0.5263377859221038\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18642\n",
            "The AUC Score for Questions [28, 31, 8, 1, 26, 23, 2] ----- 0.4746789153043674\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18643\n",
            "The AUC Score for Questions [3, 6, 11, 39, 30, 7, 22] ----- 0.43500144668949225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18644\n",
            "The AUC Score for Questions [9, 19, 3, 30, 35, 26, 36] ----- 0.5975912619954671\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18645\n",
            "The AUC Score for Questions [35, 8, 24, 12, 4, 39, 23] ----- 0.45260082622044334\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18646\n",
            "The AUC Score for Questions [29, 22, 13, 34, 8, 1, 5] ----- 0.6261834723762678\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18647\n",
            "The AUC Score for Questions [4, 3, 25, 10, 32, 31, 38] ----- 0.4446400154313546\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18648\n",
            "The AUC Score for Questions [36, 26, 25, 8, 28, 9, 37] ----- 0.5631620613717832\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18649\n",
            "The AUC Score for Questions [39, 13, 20, 36, 3, 24, 30] ----- 0.5442586520068797\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18650\n",
            "The AUC Score for Questions [31, 18, 8, 15, 21, 10, 40] ----- 0.5609136647859703\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18651\n",
            "The AUC Score for Questions [34, 16, 6, 26, 25, 28, 39] ----- 0.47852469820449756\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18652\n",
            "The AUC Score for Questions [30, 2, 3, 0, 31, 32, 17] ----- 0.5232535242963463\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18653\n",
            "The AUC Score for Questions [7, 30, 3, 15, 8, 31, 37] ----- 0.5423277233929691\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18654\n",
            "The AUC Score for Questions [35, 11, 31, 9, 18, 34, 22] ----- 0.54847615373487\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18655\n",
            "The AUC Score for Questions [26, 28, 37, 27, 0, 13, 20] ----- 0.5504171288035878\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18656\n",
            "The AUC Score for Questions [4, 3, 12, 34, 24, 40, 31] ----- 0.5114067447878993\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18657\n",
            "The AUC Score for Questions [4, 40, 31, 19, 1, 34, 22] ----- 0.4473766697207889\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18658\n",
            "The AUC Score for Questions [10, 33, 36, 17, 37, 1, 16] ----- 0.49256160486087663\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18659\n",
            "The AUC Score for Questions [13, 1, 2, 11, 7, 35, 34] ----- 0.49080548456060824\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18660\n",
            "The AUC Score for Questions [30, 37, 12, 18, 7, 36, 1] ----- 0.4529745543392647\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18661\n",
            "The AUC Score for Questions [5, 4, 7, 0, 36, 6, 1] ----- 0.549283888701355\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18662\n",
            "The AUC Score for Questions [26, 28, 3, 18, 40, 1, 39] ----- 0.5085676166594332\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18663\n",
            "The AUC Score for Questions [32, 25, 29, 19, 20, 30, 39] ----- 0.565153268714536\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18664\n",
            "The AUC Score for Questions [29, 1, 15, 24, 14, 32, 13] ----- 0.6084655446785938\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18665\n",
            "The AUC Score for Questions [25, 24, 10, 0, 15, 26, 30] ----- 0.6759114143800936\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18666\n",
            "The AUC Score for Questions [38, 15, 17, 3, 16, 23, 10] ----- 0.5693848354792561\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18667\n",
            "The AUC Score for Questions [21, 13, 28, 33, 12, 25, 20] ----- 0.3738426484062304\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18668\n",
            "The AUC Score for Questions [15, 4, 35, 37, 6, 22, 19] ----- 0.5849789426307245\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18669\n",
            "The AUC Score for Questions [14, 35, 3, 24, 18, 19, 9] ----- 0.5981598913375449\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18670\n",
            "The AUC Score for Questions [14, 35, 1, 10, 22, 0, 29] ----- 0.521567729179727\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18671\n",
            "The AUC Score for Questions [13, 28, 27, 0, 21, 17, 23] ----- 0.6235713941264408\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18672\n",
            "The AUC Score for Questions [36, 0, 22, 38, 26, 4, 17] ----- 0.5241054636639823\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18673\n",
            "The AUC Score for Questions [37, 35, 6, 18, 26, 12, 17] ----- 0.34190094999276655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18674\n",
            "The AUC Score for Questions [16, 24, 2, 26, 19, 11, 40] ----- 0.6412812846602691\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18675\n",
            "The AUC Score for Questions [6, 29, 24, 40, 14, 38, 19] ----- 0.5633067303210043\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18676\n",
            "The AUC Score for Questions [25, 31, 4, 21, 14, 35, 40] ----- 0.38350934722155244\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18677\n",
            "The AUC Score for Questions [18, 4, 31, 40, 15, 35, 32] ----- 0.4811528507820161\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18678\n",
            "The AUC Score for Questions [2, 30, 22, 40, 10, 24, 12] ----- 0.4878538361383035\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18679\n",
            "The AUC Score for Questions [39, 5, 17, 18, 6, 23, 20] ----- 0.48480775104081275\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18680\n",
            "The AUC Score for Questions [9, 21, 16, 24, 20, 26, 0] ----- 0.6505883203934996\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18681\n",
            "The AUC Score for Questions [2, 27, 20, 32, 31, 36, 16] ----- 0.5222971017987172\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18682\n",
            "The AUC Score for Questions [11, 14, 12, 26, 33, 13, 24] ----- 0.5017259809358474\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18683\n",
            "The AUC Score for Questions [10, 6, 22, 37, 5, 15, 13] ----- 0.41077944414974843\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18684\n",
            "The AUC Score for Questions [2, 22, 20, 33, 38, 23, 31] ----- 0.373914982880841\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18685\n",
            "The AUC Score for Questions [31, 7, 14, 11, 2, 21, 10] ----- 0.517846522319204\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18686\n",
            "The AUC Score for Questions [19, 7, 28, 32, 21, 27, 0] ----- 0.6364830978444328\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18687\n",
            "The AUC Score for Questions [22, 9, 23, 34, 5, 1, 16] ----- 0.6324323672662391\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18688\n",
            "The AUC Score for Questions [19, 2, 21, 28, 9, 20, 26] ----- 0.6044891578659722\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18689\n",
            "The AUC Score for Questions [34, 38, 31, 35, 4, 19, 24] ----- 0.5442686984616868\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18690\n",
            "The AUC Score for Questions [14, 40, 5, 18, 28, 31, 23] ----- 0.5045168860812397\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18691\n",
            "The AUC Score for Questions [38, 0, 19, 26, 15, 3, 36] ----- 0.5428441111700504\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18692\n",
            "The AUC Score for Questions [11, 27, 16, 37, 23, 34, 5] ----- 0.46630017199530627\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18693\n",
            "The AUC Score for Questions [25, 15, 3, 11, 4, 31, 19] ----- 0.6114855089935862\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18694\n",
            "The AUC Score for Questions [31, 7, 29, 38, 9, 12, 6] ----- 0.5081034704473485\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18695\n",
            "The AUC Score for Questions [40, 27, 34, 21, 8, 1, 30] ----- 0.5366615228818055\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18696\n",
            "The AUC Score for Questions [18, 13, 32, 25, 39, 2, 24] ----- 0.37406166112102357\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18697\n",
            "The AUC Score for Questions [26, 21, 30, 23, 31, 4, 37] ----- 0.5394745302277733\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18698\n",
            "The AUC Score for Questions [12, 17, 13, 37, 9, 19, 1] ----- 0.4353691469354294\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18699\n",
            "The AUC Score for Questions [13, 17, 26, 20, 11, 34, 23] ----- 0.5520928774654\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18700\n",
            "The AUC Score for Questions [0, 35, 14, 37, 1, 40, 17] ----- 0.3592130009162367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18701\n",
            "The AUC Score for Questions [19, 38, 22, 39, 10, 37, 30] ----- 0.46158838469081026\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18702\n",
            "The AUC Score for Questions [36, 13, 33, 20, 17, 28, 22] ----- 0.42266440018646223\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18703\n",
            "The AUC Score for Questions [38, 34, 13, 30, 36, 25, 37] ----- 0.3772865731140794\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18704\n",
            "The AUC Score for Questions [35, 16, 17, 36, 38, 13, 24] ----- 0.4225016476185884\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18705\n",
            "The AUC Score for Questions [40, 15, 22, 0, 25, 27, 34] ----- 0.630742553567697\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18706\n",
            "The AUC Score for Questions [33, 29, 20, 26, 28, 1, 6] ----- 0.5109586729035057\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18707\n",
            "The AUC Score for Questions [19, 29, 15, 3, 12, 5, 7] ----- 0.5853265499670476\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18708\n",
            "The AUC Score for Questions [29, 24, 38, 37, 1, 40, 36] ----- 0.5844987220909486\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18709\n",
            "The AUC Score for Questions [10, 34, 9, 18, 8, 39, 2] ----- 0.4988245647875777\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18710\n",
            "The AUC Score for Questions [37, 0, 31, 24, 32, 13, 10] ----- 0.5322310363119063\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18711\n",
            "The AUC Score for Questions [22, 18, 1, 21, 5, 38, 8] ----- 0.4488916751056887\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18712\n",
            "The AUC Score for Questions [9, 26, 19, 2, 20, 33, 0] ----- 0.4809057079937632\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18713\n",
            "The AUC Score for Questions [33, 8, 16, 29, 30, 31, 10] ----- 0.5505497420070405\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18714\n",
            "The AUC Score for Questions [13, 35, 19, 4, 15, 28, 10] ----- 0.49497878188744754\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18715\n",
            "The AUC Score for Questions [30, 27, 16, 31, 5, 39, 32] ----- 0.45043882914597094\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18716\n",
            "The AUC Score for Questions [14, 0, 2, 10, 24, 5, 25] ----- 0.5421810451527865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18717\n",
            "The AUC Score for Questions [23, 2, 22, 36, 6, 7, 37] ----- 0.44380615968237125\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18718\n",
            "The AUC Score for Questions [38, 23, 15, 12, 9, 33, 27] ----- 0.5050473388950507\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18719\n",
            "The AUC Score for Questions [21, 15, 8, 4, 32, 26, 11] ----- 0.5670661137097941\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18720\n",
            "The AUC Score for Questions [5, 24, 10, 25, 3, 21, 4] ----- 0.47787770651492506\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18721\n",
            "The AUC Score for Questions [7, 10, 26, 38, 12, 31, 2] ----- 0.4295120637829323\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18722\n",
            "The AUC Score for Questions [6, 27, 20, 28, 3, 2, 14] ----- 0.4056979473083538\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18723\n",
            "The AUC Score for Questions [12, 8, 30, 22, 23, 32, 24] ----- 0.5046093134654643\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18724\n",
            "The AUC Score for Questions [19, 16, 17, 20, 26, 0, 24] ----- 0.6612174695793349\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18725\n",
            "The AUC Score for Questions [19, 27, 23, 34, 16, 8, 6] ----- 0.5446946681455048\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18726\n",
            "The AUC Score for Questions [33, 15, 29, 19, 37, 26, 8] ----- 0.5462599058044397\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18727\n",
            "The AUC Score for Questions [16, 26, 13, 35, 31, 7, 23] ----- 0.5038819501374354\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18728\n",
            "The AUC Score for Questions [32, 2, 38, 20, 26, 15, 23] ----- 0.4795594830496214\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18729\n",
            "The AUC Score for Questions [15, 35, 20, 25, 19, 34, 27] ----- 0.5287147771294466\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18730\n",
            "The AUC Score for Questions [38, 10, 22, 3, 4, 15, 35] ----- 0.49447244056517337\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18731\n",
            "The AUC Score for Questions [24, 25, 16, 29, 36, 18, 12] ----- 0.5842093841925062\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18732\n",
            "The AUC Score for Questions [17, 32, 7, 23, 38, 3, 11] ----- 0.4434002829081673\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18733\n",
            "The AUC Score for Questions [16, 5, 17, 40, 19, 20, 24] ----- 0.5501740045972577\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18734\n",
            "The AUC Score for Questions [36, 39, 6, 38, 16, 22, 25] ----- 0.4806023050585909\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18735\n",
            "The AUC Score for Questions [30, 25, 21, 18, 9, 32, 4] ----- 0.5075529247239234\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18736\n",
            "The AUC Score for Questions [27, 17, 13, 18, 38, 19, 15] ----- 0.4914404205044124\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18737\n",
            "The AUC Score for Questions [17, 29, 1, 24, 34, 26, 35] ----- 0.6271961550208163\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18738\n",
            "The AUC Score for Questions [12, 8, 38, 17, 18, 15, 0] ----- 0.4961120219896803\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18739\n",
            "The AUC Score for Questions [37, 3, 12, 26, 22, 17, 4] ----- 0.43999855331050775\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18740\n",
            "The AUC Score for Questions [21, 12, 26, 2, 38, 17, 8] ----- 0.4410674961019756\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18741\n",
            "The AUC Score for Questions [27, 32, 8, 23, 28, 33, 12] ----- 0.42696629213483145\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18742\n",
            "The AUC Score for Questions [5, 10, 23, 38, 21, 16, 24] ----- 0.5110611467425376\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18743\n",
            "The AUC Score for Questions [19, 11, 34, 32, 5, 16, 17] ----- 0.4978741701628329\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18744\n",
            "The AUC Score for Questions [18, 33, 35, 5, 1, 37, 7] ----- 0.4326164183183039\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18745\n",
            "The AUC Score for Questions [39, 38, 3, 37, 29, 24, 36] ----- 0.5463844818440469\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18746\n",
            "The AUC Score for Questions [33, 35, 26, 31, 13, 36, 34] ----- 0.47037903264695957\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18747\n",
            "The AUC Score for Questions [6, 36, 33, 0, 34, 37, 19] ----- 0.5341378534342801\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18748\n",
            "The AUC Score for Questions [25, 38, 12, 4, 15, 30, 26] ----- 0.4564245069199981\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18749\n",
            "The AUC Score for Questions [10, 12, 25, 20, 8, 4, 5] ----- 0.38406793010882323\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18750\n",
            "The AUC Score for Questions [19, 29, 23, 18, 33, 11, 1] ----- 0.6467666489849062\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18751\n",
            "The AUC Score for Questions [19, 4, 26, 35, 16, 37, 28] ----- 0.45434489077494333\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18752\n",
            "The AUC Score for Questions [22, 18, 3, 27, 15, 39, 13] ----- 0.4819344649660028\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18753\n",
            "The AUC Score for Questions [10, 16, 0, 12, 23, 22, 25] ----- 0.489183986754754\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18754\n",
            "The AUC Score for Questions [27, 12, 36, 2, 28, 14, 33] ----- 0.5533205542428188\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18755\n",
            "The AUC Score for Questions [18, 15, 34, 40, 27, 7, 30] ----- 0.5553378823680699\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18756\n",
            "The AUC Score for Questions [35, 21, 11, 16, 1, 36, 7] ----- 0.5428662133706258\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18757\n",
            "The AUC Score for Questions [15, 18, 0, 3, 11, 39, 37] ----- 0.45451768979762425\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18758\n",
            "The AUC Score for Questions [20, 40, 19, 37, 31, 33, 36] ----- 0.3642261818649435\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18759\n",
            "The AUC Score for Questions [7, 13, 0, 37, 20, 38, 19] ----- 0.4615602546173506\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18760\n",
            "The AUC Score for Questions [34, 33, 38, 39, 0, 26, 3] ----- 0.43943394255035284\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18761\n",
            "The AUC Score for Questions [27, 18, 2, 37, 38, 35, 16] ----- 0.448268794907653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18762\n",
            "The AUC Score for Questions [36, 3, 15, 35, 7, 12, 9] ----- 0.5105568147112247\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18763\n",
            "The AUC Score for Questions [3, 4, 40, 24, 13, 5, 38] ----- 0.40258756490009806\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18764\n",
            "The AUC Score for Questions [35, 39, 32, 38, 40, 16, 29] ----- 0.47981466300172\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18765\n",
            "The AUC Score for Questions [2, 1, 16, 15, 20, 17, 14] ----- 0.5603832119721592\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18766\n",
            "The AUC Score for Questions [24, 28, 1, 4, 35, 5, 7] ----- 0.5815169343042227\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18767\n",
            "The AUC Score for Questions [11, 23, 16, 19, 1, 36, 28] ----- 0.6310298821751781\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18768\n",
            "The AUC Score for Questions [8, 38, 28, 20, 27, 16, 23] ----- 0.4820128273134976\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18769\n",
            "The AUC Score for Questions [40, 9, 29, 23, 24, 37, 15] ----- 0.615417691405057\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18770\n",
            "The AUC Score for Questions [35, 29, 9, 14, 3, 24, 8] ----- 0.6207061452154763\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18771\n",
            "The AUC Score for Questions [6, 16, 18, 7, 0, 1, 4] ----- 0.537585796724052\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18772\n",
            "The AUC Score for Questions [16, 35, 40, 0, 39, 5, 3] ----- 0.47321615148446416\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18773\n",
            "The AUC Score for Questions [1, 39, 10, 22, 7, 16, 12] ----- 0.43383003005899273\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18774\n",
            "The AUC Score for Questions [27, 36, 7, 21, 26, 1, 38] ----- 0.5684444873093183\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18775\n",
            "The AUC Score for Questions [37, 20, 15, 39, 1, 14, 17] ----- 0.5194740479979425\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18776\n",
            "The AUC Score for Questions [21, 15, 13, 31, 10, 16, 7] ----- 0.5479738309945187\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18777\n",
            "The AUC Score for Questions [8, 11, 7, 13, 32, 2, 18] ----- 0.5001105110028773\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18778\n",
            "The AUC Score for Questions [38, 7, 10, 23, 9, 39, 24] ----- 0.5803374805098777\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18779\n",
            "The AUC Score for Questions [13, 23, 25, 26, 21, 28, 35] ----- 0.5453376412531545\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18780\n",
            "The AUC Score for Questions [0, 7, 20, 40, 36, 18, 24] ----- 0.6739885229300285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18781\n",
            "The AUC Score for Questions [13, 7, 0, 32, 29, 38, 26] ----- 0.5090759672726688\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18782\n",
            "The AUC Score for Questions [22, 14, 5, 39, 37, 17, 11] ----- 0.41071514683898347\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18783\n",
            "The AUC Score for Questions [38, 23, 39, 35, 1, 29, 33] ----- 0.5012377232322258\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18784\n",
            "The AUC Score for Questions [12, 5, 20, 3, 7, 27, 40] ----- 0.515795036247609\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18785\n",
            "The AUC Score for Questions [36, 0, 29, 25, 4, 34, 14] ----- 0.5952604844802366\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18786\n",
            "The AUC Score for Questions [5, 21, 0, 31, 11, 24, 15] ----- 0.6287031232418705\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18787\n",
            "The AUC Score for Questions [21, 17, 11, 31, 38, 36, 24] ----- 0.5830158653614312\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18788\n",
            "The AUC Score for Questions [10, 40, 17, 24, 22, 26, 37] ----- 0.5301916059860796\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18789\n",
            "The AUC Score for Questions [22, 11, 36, 3, 5, 4, 17] ----- 0.5256064040121522\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18790\n",
            "The AUC Score for Questions [7, 32, 4, 13, 1, 30, 3] ----- 0.5426934143479449\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18791\n",
            "The AUC Score for Questions [37, 18, 22, 27, 28, 5, 40] ----- 0.31955361592001413\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18792\n",
            "The AUC Score for Questions [25, 32, 30, 16, 9, 36, 39] ----- 0.4517790262172285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18793\n",
            "The AUC Score for Questions [38, 24, 10, 12, 6, 4, 19] ----- 0.3184464966002797\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18794\n",
            "The AUC Score for Questions [37, 12, 8, 26, 38, 6, 36] ----- 0.4335226085418978\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18795\n",
            "The AUC Score for Questions [27, 25, 13, 1, 39, 33, 0] ----- 0.5354680040507306\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18796\n",
            "The AUC Score for Questions [2, 22, 17, 30, 34, 21, 14] ----- 0.5389722074874218\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18797\n",
            "The AUC Score for Questions [27, 9, 31, 21, 10, 32, 38] ----- 0.49455683078555246\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18798\n",
            "The AUC Score for Questions [17, 5, 7, 40, 1, 20, 0] ----- 0.5407886065165324\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18799\n",
            "The AUC Score for Questions [29, 35, 32, 3, 18, 40, 8] ----- 0.5185758949381941\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18800\n",
            "The AUC Score for Questions [8, 30, 35, 39, 13, 12, 20] ----- 0.3368817411711755\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18801\n",
            "The AUC Score for Questions [10, 7, 22, 29, 8, 21, 19] ----- 0.6779126681776535\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18802\n",
            "The AUC Score for Questions [33, 35, 37, 32, 12, 19, 29] ----- 0.4441175997813892\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18803\n",
            "The AUC Score for Questions [35, 33, 36, 0, 6, 34, 2] ----- 0.4940926845734677\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18804\n",
            "The AUC Score for Questions [33, 21, 11, 25, 16, 39, 13] ----- 0.49746628409766763\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18805\n",
            "The AUC Score for Questions [8, 27, 19, 35, 21, 9, 7] ----- 0.584554982237868\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18806\n",
            "The AUC Score for Questions [39, 16, 37, 23, 20, 4, 12] ----- 0.42340180996929805\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18807\n",
            "The AUC Score for Questions [20, 39, 12, 32, 4, 38, 10] ----- 0.28353305685489705\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18808\n",
            "The AUC Score for Questions [15, 2, 21, 38, 31, 12, 3] ----- 0.492865007796049\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18809\n",
            "The AUC Score for Questions [8, 4, 14, 27, 5, 0, 37] ----- 0.5292974715082541\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18810\n",
            "The AUC Score for Questions [19, 18, 11, 10, 13, 29, 32] ----- 0.6223216151484465\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18811\n",
            "The AUC Score for Questions [24, 16, 3, 39, 7, 19, 32] ----- 0.5090016235070969\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18812\n",
            "The AUC Score for Questions [12, 34, 20, 28, 8, 26, 6] ----- 0.4693120991464532\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18813\n",
            "The AUC Score for Questions [27, 32, 33, 37, 1, 25, 13] ----- 0.4617631930044526\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18814\n",
            "The AUC Score for Questions [18, 3, 26, 12, 11, 31, 7] ----- 0.5127228303676198\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18815\n",
            "The AUC Score for Questions [9, 32, 1, 33, 2, 15, 37] ----- 0.5335370754368198\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18816\n",
            "The AUC Score for Questions [1, 15, 16, 4, 18, 9, 39] ----- 0.6126689813698543\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18817\n",
            "The AUC Score for Questions [7, 36, 23, 27, 8, 19, 35] ----- 0.580001928919323\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18818\n",
            "The AUC Score for Questions [3, 27, 24, 7, 15, 33, 39] ----- 0.614055392133224\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18819\n",
            "The AUC Score for Questions [21, 37, 29, 38, 35, 33, 5] ----- 0.4230843419973959\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18820\n",
            "The AUC Score for Questions [22, 11, 24, 29, 2, 33, 19] ----- 0.6468309462956712\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18821\n",
            "The AUC Score for Questions [17, 18, 22, 4, 32, 13, 3] ----- 0.385944607866776\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18822\n",
            "The AUC Score for Questions [32, 27, 3, 17, 0, 24, 12] ----- 0.6267842503737281\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18823\n",
            "The AUC Score for Questions [31, 32, 24, 38, 12, 14, 0] ----- 0.515111877320731\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18824\n",
            "The AUC Score for Questions [0, 31, 16, 10, 29, 26, 21] ----- 0.5839401392036778\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18825\n",
            "The AUC Score for Questions [5, 10, 6, 23, 28, 22, 15] ----- 0.3537718409927505\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18826\n",
            "The AUC Score for Questions [4, 40, 26, 5, 19, 25, 9] ----- 0.6236216264004757\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18827\n",
            "The AUC Score for Questions [15, 30, 26, 14, 5, 31, 28] ----- 0.5966529231164907\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18828\n",
            "The AUC Score for Questions [6, 0, 36, 38, 14, 9, 31] ----- 0.4662137724839659\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18829\n",
            "The AUC Score for Questions [10, 15, 2, 19, 40, 17, 18] ----- 0.5020755975631319\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18830\n",
            "The AUC Score for Questions [24, 1, 28, 36, 34, 21, 30] ----- 0.6906696564916173\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18831\n",
            "The AUC Score for Questions [22, 29, 2, 11, 27, 7, 4] ----- 0.6007337930591052\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18832\n",
            "The AUC Score for Questions [6, 14, 25, 0, 20, 30, 36] ----- 0.5464206490813522\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18833\n",
            "The AUC Score for Questions [21, 22, 6, 23, 25, 38, 10] ----- 0.41023894488113033\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18834\n",
            "The AUC Score for Questions [3, 31, 36, 22, 8, 37, 26] ----- 0.5275714905724069\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18835\n",
            "The AUC Score for Questions [1, 39, 31, 25, 9, 14, 2] ----- 0.5124093809776407\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18836\n",
            "The AUC Score for Questions [11, 15, 18, 17, 10, 30, 35] ----- 0.5257068685602225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18837\n",
            "The AUC Score for Questions [11, 3, 22, 33, 18, 23, 26] ----- 0.5010930542830045\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18838\n",
            "The AUC Score for Questions [23, 18, 10, 12, 30, 19, 40] ----- 0.38748573403417397\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18839\n",
            "The AUC Score for Questions [3, 36, 33, 9, 6, 18, 7] ----- 0.5633428975583096\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18840\n",
            "The AUC Score for Questions [18, 7, 26, 11, 20, 25, 0] ----- 0.6057047788976226\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18841\n",
            "The AUC Score for Questions [18, 13, 19, 7, 6, 39, 9] ----- 0.5419138094549196\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18842\n",
            "The AUC Score for Questions [6, 24, 31, 3, 12, 30, 18] ----- 0.4306111459388211\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18843\n",
            "The AUC Score for Questions [31, 6, 30, 12, 3, 37, 40] ----- 0.33032743405507065\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18844\n",
            "The AUC Score for Questions [7, 21, 11, 4, 38, 14, 1] ----- 0.5226768577904228\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18845\n",
            "The AUC Score for Questions [16, 23, 36, 22, 3, 20, 27] ----- 0.5476644001864622\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18846\n",
            "The AUC Score for Questions [20, 25, 19, 21, 2, 4, 39] ----- 0.46988474707045375\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18847\n",
            "The AUC Score for Questions [30, 40, 29, 36, 38, 25, 37] ----- 0.46115839642506956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18848\n",
            "The AUC Score for Questions [14, 1, 4, 31, 32, 34, 25] ----- 0.4985734034174021\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18849\n",
            "The AUC Score for Questions [4, 32, 24, 36, 19, 39, 30] ----- 0.3821390107858739\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18850\n",
            "The AUC Score for Questions [40, 5, 39, 29, 33, 35, 1] ----- 0.4089630451206378\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18851\n",
            "The AUC Score for Questions [35, 18, 24, 30, 33, 6, 5] ----- 0.3381897895870505\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18852\n",
            "The AUC Score for Questions [33, 9, 21, 36, 35, 28, 25] ----- 0.545478291620453\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18853\n",
            "The AUC Score for Questions [25, 16, 24, 39, 7, 4, 38] ----- 0.5713479127485492\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18854\n",
            "The AUC Score for Questions [7, 33, 6, 5, 21, 24, 18] ----- 0.4700856761665943\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18855\n",
            "The AUC Score for Questions [39, 12, 36, 26, 13, 10, 5] ----- 0.35539132950764335\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18856\n",
            "The AUC Score for Questions [31, 13, 27, 38, 2, 20, 21] ----- 0.36790720290623846\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18857\n",
            "The AUC Score for Questions [22, 20, 38, 33, 9, 7, 37] ----- 0.4588457025284918\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18858\n",
            "The AUC Score for Questions [22, 19, 23, 25, 32, 38, 30] ----- 0.3915887061773641\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18859\n",
            "The AUC Score for Questions [2, 15, 27, 34, 17, 21, 37] ----- 0.5324882255549662\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18860\n",
            "The AUC Score for Questions [15, 17, 8, 0, 22, 29, 19] ----- 0.6817463953320153\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18861\n",
            "The AUC Score for Questions [8, 33, 21, 36, 2, 13, 4] ----- 0.3890931668032985\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18862\n",
            "The AUC Score for Questions [18, 14, 27, 24, 31, 19, 1] ----- 0.6998842648406232\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18863\n",
            "The AUC Score for Questions [6, 3, 30, 35, 15, 37, 4] ----- 0.5129257687547218\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18864\n",
            "The AUC Score for Questions [37, 20, 32, 31, 26, 18, 16] ----- 0.45477286974972275\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18865\n",
            "The AUC Score for Questions [16, 21, 29, 31, 14, 38, 4] ----- 0.5231108646380865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18866\n",
            "The AUC Score for Questions [9, 25, 8, 2, 39, 35, 28] ----- 0.5127810998055007\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18867\n",
            "The AUC Score for Questions [33, 5, 6, 23, 20, 3, 26] ----- 0.3634646605905708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18868\n",
            "The AUC Score for Questions [17, 30, 37, 6, 8, 12, 40] ----- 0.44397895870505216\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18869\n",
            "The AUC Score for Questions [18, 14, 40, 12, 21, 25, 7] ----- 0.5235308064490203\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18870\n",
            "The AUC Score for Questions [13, 25, 12, 11, 10, 38, 5] ----- 0.34795494365948143\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18871\n",
            "The AUC Score for Questions [6, 23, 37, 15, 11, 4, 1] ----- 0.5683118741058655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18872\n",
            "The AUC Score for Questions [9, 12, 24, 10, 36, 17, 34] ----- 0.5929397534198133\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18873\n",
            "The AUC Score for Questions [38, 23, 11, 16, 14, 36, 17] ----- 0.5295305492597773\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18874\n",
            "The AUC Score for Questions [38, 25, 36, 12, 16, 2, 1] ----- 0.44168635771808845\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18875\n",
            "The AUC Score for Questions [22, 37, 19, 11, 21, 38, 39] ----- 0.3831557120123451\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18876\n",
            "The AUC Score for Questions [20, 37, 10, 1, 23, 17, 13] ----- 0.5283792255388918\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18877\n",
            "The AUC Score for Questions [21, 39, 35, 24, 4, 5, 19] ----- 0.43959870440918813\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18878\n",
            "The AUC Score for Questions [25, 11, 27, 6, 31, 3, 26] ----- 0.48372876179453794\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18879\n",
            "The AUC Score for Questions [10, 20, 24, 28, 31, 5, 8] ----- 0.46321189178762595\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18880\n",
            "The AUC Score for Questions [22, 13, 36, 3, 32, 24, 21] ----- 0.5251382392181447\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18881\n",
            "The AUC Score for Questions [34, 23, 13, 19, 36, 20, 26] ----- 0.6068962884377361\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18882\n",
            "The AUC Score for Questions [39, 31, 13, 12, 6, 15, 7] ----- 0.372968606838019\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18883\n",
            "The AUC Score for Questions [3, 9, 4, 11, 18, 35, 31] ----- 0.5359843918278118\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18884\n",
            "The AUC Score for Questions [36, 3, 15, 32, 24, 27, 16] ----- 0.6014631656780955\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18885\n",
            "The AUC Score for Questions [24, 31, 5, 14, 2, 0, 13] ----- 0.5904683255372845\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18886\n",
            "The AUC Score for Questions [24, 16, 19, 23, 32, 18, 6] ----- 0.43915866968864026\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18887\n",
            "The AUC Score for Questions [19, 37, 9, 26, 28, 32, 31] ----- 0.4868873671858674\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18888\n",
            "The AUC Score for Questions [26, 16, 31, 3, 36, 32, 37] ----- 0.4806264165501278\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18889\n",
            "The AUC Score for Questions [31, 28, 5, 27, 10, 0, 2] ----- 0.5311359727379402\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18890\n",
            "The AUC Score for Questions [24, 37, 39, 35, 0, 2, 15] ----- 0.4609273279645079\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18891\n",
            "The AUC Score for Questions [40, 22, 3, 38, 13, 6, 4] ----- 0.33894528298853904\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18892\n",
            "The AUC Score for Questions [19, 35, 10, 16, 26, 40, 32] ----- 0.4598061436080436\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18893\n",
            "The AUC Score for Questions [39, 8, 30, 25, 27, 15, 33] ----- 0.5016958415714262\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18894\n",
            "The AUC Score for Questions [36, 8, 31, 28, 33, 16, 15] ----- 0.5487052129044703\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18895\n",
            "The AUC Score for Questions [12, 5, 7, 22, 10, 23, 29] ----- 0.5490367459131021\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18896\n",
            "The AUC Score for Questions [24, 17, 7, 8, 19, 10, 23] ----- 0.6691802896593849\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18897\n",
            "The AUC Score for Questions [0, 36, 11, 33, 39, 30, 28] ----- 0.6019032003986433\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18898\n",
            "The AUC Score for Questions [10, 37, 30, 27, 16, 1, 19] ----- 0.531397180562923\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18899\n",
            "The AUC Score for Questions [16, 36, 29, 4, 30, 22, 7] ----- 0.6128196781919596\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18900\n",
            "The AUC Score for Questions [38, 10, 28, 34, 13, 9, 16] ----- 0.5208564401793895\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18901\n",
            "The AUC Score for Questions [9, 29, 33, 12, 37, 2, 13] ----- 0.42019900017681755\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18902\n",
            "The AUC Score for Questions [15, 20, 30, 29, 9, 34, 10] ----- 0.6219197569561653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18903\n",
            "The AUC Score for Questions [31, 40, 13, 8, 19, 27, 0] ----- 0.5833453890791018\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18904\n",
            "The AUC Score for Questions [3, 10, 34, 15, 21, 6, 14] ----- 0.5188049541077944\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18905\n",
            "The AUC Score for Questions [6, 36, 27, 32, 12, 2, 8] ----- 0.594261866872418\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18906\n",
            "The AUC Score for Questions [9, 12, 27, 5, 18, 10, 14] ----- 0.5587737699120734\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18907\n",
            "The AUC Score for Questions [32, 17, 29, 30, 13, 26, 39] ----- 0.5061825882882449\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18908\n",
            "The AUC Score for Questions [5, 19, 2, 9, 37, 24, 34] ----- 0.4472641494269502\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18909\n",
            "The AUC Score for Questions [40, 39, 0, 6, 17, 7, 33] ----- 0.4008595746732893\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18910\n",
            "The AUC Score for Questions [0, 33, 8, 7, 22, 5, 11] ----- 0.4951154136728232\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18911\n",
            "The AUC Score for Questions [11, 10, 33, 27, 16, 2, 14] ----- 0.49966243911848385\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18912\n",
            "The AUC Score for Questions [35, 29, 16, 37, 1, 9, 14] ----- 0.5007595119834113\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18913\n",
            "The AUC Score for Questions [3, 0, 25, 2, 21, 31, 29] ----- 0.5897489993731011\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18914\n",
            "The AUC Score for Questions [37, 14, 34, 2, 26, 20, 30] ----- 0.4271893234315475\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18915\n",
            "The AUC Score for Questions [13, 7, 11, 14, 39, 23, 37] ----- 0.45096526337785925\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18916\n",
            "The AUC Score for Questions [11, 0, 20, 35, 3, 10, 21] ----- 0.4989632058639148\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18917\n",
            "The AUC Score for Questions [27, 14, 6, 35, 2, 1, 30] ----- 0.4969740078121233\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18918\n",
            "The AUC Score for Questions [6, 2, 18, 37, 7, 25, 34] ----- 0.37418020928774653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18919\n",
            "The AUC Score for Questions [27, 0, 40, 36, 29, 34, 23] ----- 0.6440038739129736\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18920\n",
            "The AUC Score for Questions [17, 10, 16, 11, 28, 24, 38] ----- 0.5780790374692579\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18921\n",
            "The AUC Score for Questions [0, 4, 24, 18, 12, 23, 11] ----- 0.6341503110382409\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18922\n",
            "The AUC Score for Questions [39, 34, 30, 22, 1, 5, 7] ----- 0.5664392149298356\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18923\n",
            "The AUC Score for Questions [19, 35, 9, 11, 3, 20, 39] ----- 0.553485316101654\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18924\n",
            "The AUC Score for Questions [22, 30, 27, 35, 14, 29, 33] ----- 0.5862990467923679\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18925\n",
            "The AUC Score for Questions [25, 15, 5, 27, 17, 29, 16] ----- 0.5806207905354359\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18926\n",
            "The AUC Score for Questions [15, 9, 40, 1, 35, 17, 10] ----- 0.5080170709360081\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18927\n",
            "The AUC Score for Questions [0, 4, 12, 38, 31, 39, 6] ----- 0.36067375544517855\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18928\n",
            "The AUC Score for Questions [28, 1, 27, 4, 25, 34, 5] ----- 0.5149651990805485\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18929\n",
            "The AUC Score for Questions [3, 34, 9, 18, 35, 6, 37] ----- 0.46303105560109953\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18930\n",
            "The AUC Score for Questions [23, 29, 22, 12, 24, 25, 15] ----- 0.6268706498850686\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18931\n",
            "The AUC Score for Questions [34, 5, 10, 28, 1, 2, 19] ----- 0.43771599877835105\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18932\n",
            "The AUC Score for Questions [18, 6, 36, 38, 14, 32, 29] ----- 0.5492457121730884\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18933\n",
            "The AUC Score for Questions [38, 6, 13, 20, 37, 40, 4] ----- 0.33268835093472215\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18934\n",
            "The AUC Score for Questions [25, 3, 30, 0, 6, 34, 31] ----- 0.48267388403980005\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18935\n",
            "The AUC Score for Questions [15, 22, 19, 25, 21, 6, 29] ----- 0.6550610020735883\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18936\n",
            "The AUC Score for Questions [25, 33, 1, 35, 36, 16, 34] ----- 0.4977134268859205\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18937\n",
            "The AUC Score for Questions [31, 4, 33, 6, 8, 19, 28] ----- 0.46537388886209835\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18938\n",
            "The AUC Score for Questions [12, 35, 17, 10, 39, 26, 8] ----- 0.3930092748870778\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18939\n",
            "The AUC Score for Questions [10, 3, 35, 38, 34, 22, 26] ----- 0.44200784427191336\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18940\n",
            "The AUC Score for Questions [36, 3, 9, 12, 37, 23, 26] ----- 0.4592957837038466\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18941\n",
            "The AUC Score for Questions [9, 11, 37, 12, 5, 32, 3] ----- 0.37788132323865553\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18942\n",
            "The AUC Score for Questions [15, 31, 5, 10, 35, 11, 21] ----- 0.5237297262541993\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18943\n",
            "The AUC Score for Questions [33, 10, 26, 13, 7, 27, 9] ----- 0.5907255147803443\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18944\n",
            "The AUC Score for Questions [17, 24, 20, 19, 22, 38, 7] ----- 0.5438125894134478\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18945\n",
            "The AUC Score for Questions [32, 14, 27, 25, 3, 7, 31] ----- 0.5319899213965376\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18946\n",
            "The AUC Score for Questions [3, 21, 17, 15, 37, 24, 2] ----- 0.5345577952452139\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18947\n",
            "The AUC Score for Questions [7, 32, 22, 15, 38, 10, 27] ----- 0.49674494864252305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18948\n",
            "The AUC Score for Questions [37, 6, 32, 30, 36, 13, 2] ----- 0.40564168716143445\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18949\n",
            "The AUC Score for Questions [2, 4, 23, 13, 6, 18, 9] ----- 0.4734452106540644\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18950\n",
            "The AUC Score for Questions [1, 30, 32, 6, 5, 34, 7] ----- 0.5529046310138078\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18951\n",
            "The AUC Score for Questions [15, 20, 10, 11, 16, 33, 9] ----- 0.5349275047821125\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18952\n",
            "The AUC Score for Questions [26, 10, 15, 12, 11, 2, 8] ----- 0.48148036520872517\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18953\n",
            "The AUC Score for Questions [23, 24, 2, 19, 17, 37, 38] ----- 0.42109112536368165\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18954\n",
            "The AUC Score for Questions [13, 38, 20, 9, 14, 31, 28] ----- 0.4860474835639999\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18955\n",
            "The AUC Score for Questions [23, 18, 36, 40, 7, 14, 28] ----- 0.62262702737458\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18956\n",
            "The AUC Score for Questions [10, 36, 22, 26, 38, 18, 11] ----- 0.4897626625516388\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18957\n",
            "The AUC Score for Questions [8, 26, 28, 0, 13, 14, 23] ----- 0.5652256031891466\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18958\n",
            "The AUC Score for Questions [37, 39, 22, 5, 2, 13, 33] ----- 0.28825890919612285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18959\n",
            "The AUC Score for Questions [13, 8, 2, 34, 39, 23, 32] ----- 0.4233676520229541\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18960\n",
            "The AUC Score for Questions [32, 20, 16, 26, 37, 31, 6] ----- 0.47108429377441285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18961\n",
            "The AUC Score for Questions [18, 21, 25, 33, 17, 38, 35] ----- 0.44197569561653083\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18962\n",
            "The AUC Score for Questions [2, 39, 35, 25, 5, 7, 10] ----- 0.35743276912443134\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18963\n",
            "The AUC Score for Questions [4, 39, 25, 9, 32, 15, 17] ----- 0.5278628377618105\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18964\n",
            "The AUC Score for Questions [35, 13, 29, 9, 6, 21, 17] ----- 0.5786878526305638\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18965\n",
            "The AUC Score for Questions [19, 1, 27, 30, 0, 4, 24] ----- 0.721540402822652\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18966\n",
            "The AUC Score for Questions [35, 29, 7, 0, 8, 15, 19] ----- 0.6267902782466124\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18967\n",
            "The AUC Score for Questions [39, 14, 35, 12, 30, 40, 23] ----- 0.4209745864879202\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18968\n",
            "The AUC Score for Questions [39, 33, 23, 7, 26, 31, 34] ----- 0.5027286171255887\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18969\n",
            "The AUC Score for Questions [24, 32, 7, 2, 0, 12, 6] ----- 0.5048805677452541\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18970\n",
            "The AUC Score for Questions [29, 3, 13, 8, 34, 19, 0] ----- 0.6243409525646589\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18971\n",
            "The AUC Score for Questions [0, 22, 19, 12, 16, 25, 20] ----- 0.5114690328077027\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18972\n",
            "The AUC Score for Questions [34, 19, 30, 9, 40, 18, 39] ----- 0.5875347607336323\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18973\n",
            "The AUC Score for Questions [15, 40, 6, 4, 26, 32, 31] ----- 0.5268682387359149\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18974\n",
            "The AUC Score for Questions [10, 29, 16, 1, 26, 6, 21] ----- 0.5527559434826639\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18975\n",
            "The AUC Score for Questions [39, 28, 36, 9, 21, 12, 30] ----- 0.5304729067206764\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18976\n",
            "The AUC Score for Questions [37, 18, 35, 9, 32, 26, 19] ----- 0.3944800758708267\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18977\n",
            "The AUC Score for Questions [24, 37, 39, 12, 40, 13, 30] ----- 0.29526530677854396\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18978\n",
            "The AUC Score for Questions [31, 21, 33, 2, 38, 39, 18] ----- 0.3963587629197409\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18979\n",
            "The AUC Score for Questions [3, 14, 38, 27, 8, 19, 25] ----- 0.5613396344697883\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18980\n",
            "The AUC Score for Questions [27, 8, 35, 13, 30, 23, 3] ----- 0.41540282265194256\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18981\n",
            "The AUC Score for Questions [30, 0, 23, 40, 36, 24, 4] ----- 0.7161976981562745\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18982\n",
            "The AUC Score for Questions [38, 13, 1, 21, 35, 29, 28] ----- 0.5015270611306683\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18983\n",
            "The AUC Score for Questions [36, 18, 17, 8, 27, 34, 19] ----- 0.6024477182491843\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18984\n",
            "The AUC Score for Questions [39, 5, 7, 11, 3, 6, 30] ----- 0.4677790101429008\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18985\n",
            "The AUC Score for Questions [20, 23, 19, 16, 10, 3, 0] ----- 0.5748742183858161\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18986\n",
            "The AUC Score for Questions [3, 31, 15, 18, 0, 39, 22] ----- 0.5321124881451833\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18987\n",
            "The AUC Score for Questions [27, 40, 16, 29, 37, 3, 4] ----- 0.49304584398257545\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18988\n",
            "The AUC Score for Questions [40, 3, 31, 21, 11, 30, 22] ----- 0.47716641751458744\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18989\n",
            "The AUC Score for Questions [1, 24, 37, 31, 6, 22, 10] ----- 0.3726290366655415\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18990\n",
            "The AUC Score for Questions [16, 18, 22, 13, 10, 3, 20] ----- 0.4490564369645239\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18991\n",
            "The AUC Score for Questions [25, 19, 20, 36, 18, 38, 10] ----- 0.5304568323929851\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18992\n",
            "The AUC Score for Questions [6, 37, 27, 39, 35, 31, 14] ----- 0.33555359984568645\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18993\n",
            "The AUC Score for Questions [9, 10, 8, 20, 32, 36, 13] ----- 0.49156901512594237\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18994\n",
            "The AUC Score for Questions [18, 6, 11, 17, 35, 19, 15] ----- 0.5419861439295302\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18995\n",
            "The AUC Score for Questions [17, 24, 6, 19, 30, 13, 10] ----- 0.551052064747392\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18996\n",
            "The AUC Score for Questions [13, 15, 8, 30, 21, 31, 18] ----- 0.5634172413238816\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18997\n",
            "The AUC Score for Questions [34, 30, 40, 32, 6, 29, 3] ----- 0.5685730819308482\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18998\n",
            "The AUC Score for Questions [32, 29, 38, 21, 10, 22, 34] ----- 0.4920793750301394\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 18999\n",
            "The AUC Score for Questions [9, 25, 29, 35, 27, 8, 5] ----- 0.5864919387246628\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19000\n",
            "The AUC Score for Questions [32, 16, 15, 24, 8, 29, 36] ----- 0.5929598463294273\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19001\n",
            "The AUC Score for Questions [15, 37, 30, 36, 24, 25, 32] ----- 0.4075505135747698\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19002\n",
            "The AUC Score for Questions [10, 21, 16, 8, 0, 13, 15] ----- 0.5501237723232226\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19003\n",
            "The AUC Score for Questions [8, 33, 16, 9, 34, 25, 1] ----- 0.6168965295526515\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19004\n",
            "The AUC Score for Questions [31, 7, 39, 13, 16, 10, 33] ----- 0.5267014675861181\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19005\n",
            "The AUC Score for Questions [35, 10, 7, 3, 19, 1, 39] ----- 0.4916493867643986\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19006\n",
            "The AUC Score for Questions [1, 26, 4, 10, 34, 18, 35] ----- 0.44408946970792945\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19007\n",
            "The AUC Score for Questions [1, 7, 22, 17, 4, 2, 29] ----- 0.6254721833759302\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19008\n",
            "The AUC Score for Questions [12, 19, 35, 7, 32, 24, 20] ----- 0.460159778817251\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19009\n",
            "The AUC Score for Questions [14, 5, 23, 7, 39, 15, 0] ----- 0.5769377602031796\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19010\n",
            "The AUC Score for Questions [17, 25, 8, 34, 7, 27, 18] ----- 0.6174249730755011\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19011\n",
            "The AUC Score for Questions [32, 10, 36, 19, 25, 2, 23] ----- 0.35418977351272285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19012\n",
            "The AUC Score for Questions [8, 0, 26, 12, 22, 18, 13] ----- 0.46514482969249815\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19013\n",
            "The AUC Score for Questions [30, 17, 10, 9, 5, 7, 6] ----- 0.5390304769253026\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19014\n",
            "The AUC Score for Questions [13, 37, 33, 38, 34, 2, 6] ----- 0.3454975808136824\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19015\n",
            "The AUC Score for Questions [28, 0, 4, 12, 29, 18, 27] ----- 0.6625978524698205\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19016\n",
            "The AUC Score for Questions [22, 11, 28, 35, 27, 7, 6] ----- 0.4109763546639662\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19017\n",
            "The AUC Score for Questions [34, 9, 1, 30, 26, 17, 8] ----- 0.6170974586487921\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19018\n",
            "The AUC Score for Questions [21, 35, 3, 14, 2, 40, 9] ----- 0.5120999501695842\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19019\n",
            "The AUC Score for Questions [30, 27, 14, 12, 16, 5, 20] ----- 0.5514539229396731\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19020\n",
            "The AUC Score for Questions [5, 17, 40, 30, 6, 3, 23] ----- 0.4394419797141984\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19021\n",
            "The AUC Score for Questions [25, 32, 23, 40, 24, 16, 13] ----- 0.45328800372924405\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19022\n",
            "The AUC Score for Questions [8, 19, 13, 22, 1, 24, 3] ----- 0.6685996045715388\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19023\n",
            "The AUC Score for Questions [8, 17, 19, 9, 24, 29, 0] ----- 0.7242529456205495\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19024\n",
            "The AUC Score for Questions [33, 6, 0, 31, 12, 15, 27] ----- 0.5414396167880279\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19025\n",
            "The AUC Score for Questions [16, 12, 38, 24, 5, 35, 39] ----- 0.41822587645271736\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19026\n",
            "The AUC Score for Questions [18, 38, 19, 26, 1, 4, 9] ----- 0.5433203131279034\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19027\n",
            "The AUC Score for Questions [2, 32, 30, 3, 16, 38, 12] ----- 0.46098559740238865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19028\n",
            "The AUC Score for Questions [17, 4, 33, 22, 9, 31, 32] ----- 0.4233857356416068\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19029\n",
            "The AUC Score for Questions [31, 4, 30, 2, 20, 34, 14] ----- 0.46441947565543074\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19030\n",
            "The AUC Score for Questions [32, 9, 24, 14, 19, 39, 23] ----- 0.6017946986867275\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19031\n",
            "The AUC Score for Questions [31, 11, 26, 5, 39, 3, 33] ----- 0.3852252817025928\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19032\n",
            "The AUC Score for Questions [34, 37, 39, 27, 24, 8, 13] ----- 0.5349254954911511\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19033\n",
            "The AUC Score for Questions [4, 31, 24, 14, 16, 12, 10] ----- 0.6014249891498288\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19034\n",
            "The AUC Score for Questions [28, 25, 6, 18, 21, 13, 8] ----- 0.46031248493031784\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19035\n",
            "The AUC Score for Questions [27, 7, 11, 39, 20, 8, 36] ----- 0.5644017938949704\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19036\n",
            "The AUC Score for Questions [7, 3, 2, 12, 6, 11, 20] ----- 0.4135020334024529\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19037\n",
            "The AUC Score for Questions [0, 5, 37, 40, 12, 19, 38] ----- 0.3246752985806369\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19038\n",
            "The AUC Score for Questions [21, 25, 24, 26, 11, 27, 12] ----- 0.6630499429361367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19039\n",
            "The AUC Score for Questions [15, 29, 24, 1, 40, 0, 14] ----- 0.6690054813457428\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19040\n",
            "The AUC Score for Questions [3, 12, 10, 13, 21, 5, 14] ----- 0.36149354615743196\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19041\n",
            "The AUC Score for Questions [12, 37, 31, 21, 13, 8, 7] ----- 0.35354479111411163\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19042\n",
            "The AUC Score for Questions [36, 12, 14, 37, 33, 8, 34] ----- 0.49817154522512097\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19043\n",
            "The AUC Score for Questions [0, 17, 8, 36, 9, 3, 30] ----- 0.6207603960714343\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19044\n",
            "The AUC Score for Questions [14, 3, 10, 26, 30, 17, 5] ----- 0.5411743903811224\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19045\n",
            "The AUC Score for Questions [6, 19, 28, 34, 3, 20, 10] ----- 0.43269879924772153\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19046\n",
            "The AUC Score for Questions [21, 0, 18, 28, 37, 32, 29] ----- 0.5305773898506696\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19047\n",
            "The AUC Score for Questions [22, 8, 29, 15, 1, 33, 12] ----- 0.4968213016990565\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19048\n",
            "The AUC Score for Questions [18, 11, 24, 5, 39, 40, 32] ----- 0.5121160244972754\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19049\n",
            "The AUC Score for Questions [12, 27, 30, 11, 28, 25, 24] ----- 0.6213069232129367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19050\n",
            "The AUC Score for Questions [17, 30, 2, 18, 12, 22, 16] ----- 0.4569208017874653\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19051\n",
            "The AUC Score for Questions [1, 26, 3, 0, 22, 24, 5] ----- 0.6241862371606307\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19052\n",
            "The AUC Score for Questions [32, 12, 27, 0, 33, 11, 29] ----- 0.5510862226937359\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19053\n",
            "The AUC Score for Questions [28, 40, 33, 22, 12, 13, 16] ----- 0.3769409750687177\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19054\n",
            "The AUC Score for Questions [8, 0, 36, 13, 22, 37, 26] ----- 0.5013000112520294\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19055\n",
            "The AUC Score for Questions [10, 9, 30, 12, 6, 19, 38] ----- 0.5107597530983268\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19056\n",
            "The AUC Score for Questions [15, 19, 16, 4, 11, 14, 0] ----- 0.5648177171239813\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19057\n",
            "The AUC Score for Questions [26, 18, 5, 7, 29, 12, 19] ----- 0.6007538859687194\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19058\n",
            "The AUC Score for Questions [18, 13, 27, 6, 4, 34, 9] ----- 0.5006047965793831\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19059\n",
            "The AUC Score for Questions [16, 37, 2, 11, 18, 7, 27] ----- 0.4615703010721577\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19060\n",
            "The AUC Score for Questions [22, 23, 35, 33, 37, 19, 2] ----- 0.4505654144765395\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19061\n",
            "The AUC Score for Questions [6, 21, 30, 14, 0, 26, 38] ----- 0.3752270498786388\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19062\n",
            "The AUC Score for Questions [5, 40, 30, 19, 12, 33, 6] ----- 0.3563979842793075\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19063\n",
            "The AUC Score for Questions [11, 32, 8, 9, 0, 19, 25] ----- 0.5742613846425874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19064\n",
            "The AUC Score for Questions [36, 33, 18, 39, 37, 13, 12] ----- 0.33882271623989324\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19065\n",
            "The AUC Score for Questions [30, 2, 39, 10, 21, 36, 31] ----- 0.42981948530002734\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19066\n",
            "The AUC Score for Questions [28, 30, 12, 34, 9, 27, 16] ----- 0.5127208210766585\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19067\n",
            "The AUC Score for Questions [38, 12, 33, 25, 30, 13, 27] ----- 0.37528531931651954\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19068\n",
            "The AUC Score for Questions [24, 40, 36, 27, 8, 18, 15] ----- 0.6580809663885808\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19069\n",
            "The AUC Score for Questions [34, 6, 3, 1, 11, 23, 38] ----- 0.44499766922248474\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19070\n",
            "The AUC Score for Questions [35, 29, 20, 5, 17, 23, 1] ----- 0.6214857501085017\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19071\n",
            "The AUC Score for Questions [27, 13, 3, 11, 21, 2, 33] ----- 0.5073881628650881\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19072\n",
            "The AUC Score for Questions [18, 24, 35, 32, 25, 5, 13] ----- 0.3465966629695713\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19073\n",
            "The AUC Score for Questions [9, 38, 33, 30, 37, 5, 6] ----- 0.5500735400491874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19074\n",
            "The AUC Score for Questions [8, 12, 13, 26, 6, 37, 33] ----- 0.3740837633215991\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19075\n",
            "The AUC Score for Questions [19, 4, 13, 11, 23, 40, 7] ----- 0.5724630692321293\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19076\n",
            "The AUC Score for Questions [32, 27, 5, 21, 22, 28, 6] ----- 0.49364662198003567\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19077\n",
            "The AUC Score for Questions [36, 21, 14, 4, 39, 0, 37] ----- 0.4922039510697465\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19078\n",
            "The AUC Score for Questions [40, 5, 8, 15, 7, 21, 17] ----- 0.5589787175901368\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19079\n",
            "The AUC Score for Questions [33, 31, 12, 39, 5, 34, 3] ----- 0.42335157769526294\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19080\n",
            "The AUC Score for Questions [17, 19, 40, 8, 20, 16, 32] ----- 0.5830259118162383\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19081\n",
            "The AUC Score for Questions [13, 36, 32, 5, 27, 25, 19] ----- 0.4399844882737779\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19082\n",
            "The AUC Score for Questions [31, 2, 19, 0, 36, 10, 24] ----- 0.674328093102506\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19083\n",
            "The AUC Score for Questions [38, 14, 37, 15, 16, 8, 39] ----- 0.43643407114497434\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19084\n",
            "The AUC Score for Questions [20, 15, 4, 7, 38, 26, 22] ----- 0.5422815097008568\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19085\n",
            "The AUC Score for Questions [4, 17, 5, 37, 31, 36, 39] ----- 0.3582666248734147\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19086\n",
            "The AUC Score for Questions [7, 36, 17, 37, 19, 25, 12] ----- 0.4811890180193214\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19087\n",
            "The AUC Score for Questions [8, 16, 13, 19, 40, 7, 38] ----- 0.42924482808506537\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19088\n",
            "The AUC Score for Questions [9, 0, 5, 7, 26, 30, 23] ----- 0.6245258073331083\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19089\n",
            "The AUC Score for Questions [34, 31, 37, 4, 11, 6, 26] ----- 0.42050843098487406\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19090\n",
            "The AUC Score for Questions [8, 15, 37, 14, 40, 3, 22] ----- 0.4347362202825866\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19091\n",
            "The AUC Score for Questions [5, 10, 31, 37, 29, 0, 12] ----- 0.42914235424603364\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19092\n",
            "The AUC Score for Questions [6, 0, 1, 13, 35, 37, 17] ----- 0.4759447686100529\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19093\n",
            "The AUC Score for Questions [15, 19, 33, 13, 0, 30, 26] ----- 0.5277241966854737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19094\n",
            "The AUC Score for Questions [4, 17, 12, 32, 35, 15, 10] ----- 0.46638456221568536\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19095\n",
            "The AUC Score for Questions [11, 1, 10, 23, 27, 0, 3] ----- 0.5870947260130844\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19096\n",
            "The AUC Score for Questions [30, 12, 0, 7, 3, 37, 22] ----- 0.4955192811560656\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19097\n",
            "The AUC Score for Questions [7, 39, 5, 24, 15, 21, 20] ----- 0.597472713828744\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19098\n",
            "The AUC Score for Questions [18, 14, 19, 30, 22, 35, 40] ----- 0.4372277410747295\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19099\n",
            "The AUC Score for Questions [27, 21, 30, 22, 32, 15, 0] ----- 0.6381226792689395\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19100\n",
            "The AUC Score for Questions [20, 6, 30, 23, 17, 2, 5] ----- 0.3771881178569707\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19101\n",
            "The AUC Score for Questions [33, 27, 25, 20, 28, 22, 18] ----- 0.445608493674752\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19102\n",
            "The AUC Score for Questions [24, 37, 15, 23, 27, 33, 38] ----- 0.5226366719711948\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19103\n",
            "The AUC Score for Questions [40, 33, 3, 27, 2, 23, 30] ----- 0.35675362877947625\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19104\n",
            "The AUC Score for Questions [8, 26, 38, 5, 21, 12, 20] ----- 0.457712462426259\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19105\n",
            "The AUC Score for Questions [31, 12, 10, 18, 37, 24, 8] ----- 0.43584936747520536\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19106\n",
            "The AUC Score for Questions [22, 8, 40, 29, 5, 39, 23] ----- 0.5436176881901914\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19107\n",
            "The AUC Score for Questions [21, 31, 9, 3, 30, 28, 35] ----- 0.558004211473855\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19108\n",
            "The AUC Score for Questions [26, 37, 30, 9, 1, 16, 33] ----- 0.5511444921316166\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19109\n",
            "The AUC Score for Questions [40, 7, 11, 25, 39, 12, 26] ----- 0.4718297407210943\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19110\n",
            "The AUC Score for Questions [16, 5, 23, 31, 39, 9, 27] ----- 0.5369910465994759\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19111\n",
            "The AUC Score for Questions [6, 2, 18, 10, 7, 34, 20] ----- 0.3761071193197344\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19112\n",
            "The AUC Score for Questions [25, 39, 2, 33, 0, 17, 30] ----- 0.535980373245889\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19113\n",
            "The AUC Score for Questions [25, 38, 12, 15, 10, 6, 23] ----- 0.45457394994454353\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19114\n",
            "The AUC Score for Questions [15, 8, 29, 37, 38, 6, 2] ----- 0.5280075067110318\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19115\n",
            "The AUC Score for Questions [16, 35, 24, 19, 0, 4, 7] ----- 0.6111821060584142\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19116\n",
            "The AUC Score for Questions [15, 3, 38, 37, 8, 16, 17] ----- 0.5537244217260613\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19117\n",
            "The AUC Score for Questions [9, 1, 21, 7, 25, 40, 8] ----- 0.6334571056565559\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19118\n",
            "The AUC Score for Questions [7, 36, 4, 24, 37, 8, 17] ----- 0.5664894472038707\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19119\n",
            "The AUC Score for Questions [3, 37, 17, 38, 15, 21, 27] ----- 0.5000502322740351\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19120\n",
            "The AUC Score for Questions [8, 32, 33, 40, 26, 25, 14] ----- 0.3626167398048577\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19121\n",
            "The AUC Score for Questions [11, 27, 20, 26, 1, 33, 14] ----- 0.5049026699458294\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19122\n",
            "The AUC Score for Questions [16, 24, 9, 7, 40, 5, 14] ----- 0.6459890533828424\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19123\n",
            "The AUC Score for Questions [35, 3, 32, 40, 17, 34, 18] ----- 0.43722975036569095\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19124\n",
            "The AUC Score for Questions [23, 24, 6, 10, 29, 16, 26] ----- 0.6106797833180626\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19125\n",
            "The AUC Score for Questions [3, 40, 33, 16, 18, 11, 32] ----- 0.4180249473565768\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19126\n",
            "The AUC Score for Questions [14, 26, 40, 5, 20, 24, 28] ----- 0.6909790872996737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19127\n",
            "The AUC Score for Questions [37, 40, 1, 18, 14, 29, 22] ----- 0.5332497468293389\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19128\n",
            "The AUC Score for Questions [2, 0, 26, 34, 30, 29, 39] ----- 0.554401552780055\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19129\n",
            "The AUC Score for Questions [2, 10, 14, 15, 6, 37, 21] ----- 0.5364666216585492\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19130\n",
            "The AUC Score for Questions [40, 2, 11, 37, 25, 26, 33] ----- 0.38516902155567345\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19131\n",
            "The AUC Score for Questions [21, 14, 18, 2, 20, 38, 6] ----- 0.4407399816752664\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19132\n",
            "The AUC Score for Questions [20, 35, 28, 8, 23, 30, 1] ----- 0.5384337175097651\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19133\n",
            "The AUC Score for Questions [32, 19, 13, 9, 4, 29, 27] ----- 0.6384622494414172\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19134\n",
            "The AUC Score for Questions [3, 12, 6, 34, 9, 27, 22] ----- 0.49382544887560076\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19135\n",
            "The AUC Score for Questions [35, 23, 36, 7, 4, 22, 38] ----- 0.5553760588963367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19136\n",
            "The AUC Score for Questions [18, 1, 27, 33, 5, 14, 6] ----- 0.419893587950684\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19137\n",
            "The AUC Score for Questions [23, 17, 9, 40, 13, 22, 12] ----- 0.3274722315989134\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19138\n",
            "The AUC Score for Questions [16, 18, 2, 22, 23, 25, 40] ----- 0.5285962289627235\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19139\n",
            "The AUC Score for Questions [11, 24, 9, 29, 13, 25, 21] ----- 0.7009652633778591\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19140\n",
            "The AUC Score for Questions [15, 0, 8, 21, 38, 34, 40] ----- 0.5027567471990484\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19141\n",
            "The AUC Score for Questions [35, 20, 25, 31, 24, 27, 10] ----- 0.4817154522512096\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19142\n",
            "The AUC Score for Questions [37, 19, 26, 6, 16, 32, 11] ----- 0.45781091768336785\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19143\n",
            "The AUC Score for Questions [7, 28, 26, 14, 0, 25, 9] ----- 0.59919668547363\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19144\n",
            "The AUC Score for Questions [0, 28, 34, 26, 30, 3, 20] ----- 0.5659951616273649\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19145\n",
            "The AUC Score for Questions [38, 26, 27, 14, 40, 24, 16] ----- 0.6856966613621385\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19146\n",
            "The AUC Score for Questions [15, 36, 31, 32, 30, 40, 20] ----- 0.37012947870955293\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19147\n",
            "The AUC Score for Questions [27, 21, 23, 28, 39, 29, 25] ----- 0.6341824596936234\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19148\n",
            "The AUC Score for Questions [17, 26, 1, 13, 27, 19, 33] ----- 0.5973179984247159\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19149\n",
            "The AUC Score for Questions [32, 24, 34, 17, 12, 0, 13] ----- 0.4862785520245616\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19150\n",
            "The AUC Score for Questions [7, 1, 5, 19, 35, 31, 27] ----- 0.5346723248300139\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19151\n",
            "The AUC Score for Questions [14, 26, 15, 21, 23, 2, 3] ----- 0.5631680892446673\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19152\n",
            "The AUC Score for Questions [12, 29, 11, 13, 9, 6, 34] ----- 0.46670604876951016\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19153\n",
            "The AUC Score for Questions [24, 5, 33, 11, 9, 18, 0] ----- 0.6013004131102215\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19154\n",
            "The AUC Score for Questions [19, 40, 18, 5, 35, 3, 27] ----- 0.3429698927842343\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19155\n",
            "The AUC Score for Questions [36, 30, 13, 33, 1, 5, 11] ----- 0.49920833936120623\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19156\n",
            "The AUC Score for Questions [38, 34, 12, 4, 24, 32, 8] ----- 0.4430908521001109\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19157\n",
            "The AUC Score for Questions [39, 23, 11, 25, 27, 13, 21] ----- 0.550656234427995\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19158\n",
            "The AUC Score for Questions [10, 13, 7, 11, 4, 21, 1] ----- 0.5645183327707318\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19159\n",
            "The AUC Score for Questions [1, 27, 38, 32, 26, 10, 33] ----- 0.4989471315362235\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19160\n",
            "The AUC Score for Questions [7, 10, 12, 23, 9, 19, 2] ----- 0.534182057835431\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19161\n",
            "The AUC Score for Questions [2, 36, 33, 32, 17, 14, 0] ----- 0.4783619456366237\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19162\n",
            "The AUC Score for Questions [28, 29, 18, 21, 4, 6, 1] ----- 0.6035950233881469\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19163\n",
            "The AUC Score for Questions [15, 3, 19, 13, 29, 37, 9] ----- 0.6245237980421467\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19164\n",
            "The AUC Score for Questions [25, 10, 14, 7, 8, 9, 33] ----- 0.5978283583289128\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19165\n",
            "The AUC Score for Questions [4, 35, 8, 12, 18, 15, 37] ----- 0.3983901560817218\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19166\n",
            "The AUC Score for Questions [7, 16, 33, 0, 18, 4, 39] ----- 0.5083465946536787\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19167\n",
            "The AUC Score for Questions [23, 31, 40, 25, 21, 35, 19] ----- 0.41186847985083025\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19168\n",
            "The AUC Score for Questions [6, 16, 1, 2, 18, 12, 30] ----- 0.47051164585041233\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19169\n",
            "The AUC Score for Questions [35, 32, 34, 5, 2, 24, 19] ----- 0.38281614183986745\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19170\n",
            "The AUC Score for Questions [36, 24, 34, 10, 35, 8, 30] ----- 0.5211819453151373\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19171\n",
            "The AUC Score for Questions [31, 37, 24, 2, 29, 17, 6] ----- 0.49528821269550405\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19172\n",
            "The AUC Score for Questions [34, 17, 21, 29, 27, 35, 18] ----- 0.5950113324010222\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19173\n",
            "The AUC Score for Questions [37, 13, 24, 14, 9, 33, 31] ----- 0.5862387680635257\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19174\n",
            "The AUC Score for Questions [28, 15, 6, 16, 13, 27, 24] ----- 0.631168523251515\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19175\n",
            "The AUC Score for Questions [40, 24, 11, 29, 14, 12, 10] ----- 0.6282429956117086\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19176\n",
            "The AUC Score for Questions [20, 7, 40, 21, 31, 38, 18] ----- 0.42224244908456704\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19177\n",
            "The AUC Score for Questions [0, 34, 36, 30, 25, 32, 12] ----- 0.5202797736734661\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19178\n",
            "The AUC Score for Questions [37, 0, 29, 14, 2, 34, 17] ----- 0.5048162704344891\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19179\n",
            "The AUC Score for Questions [8, 24, 5, 21, 36, 2, 4] ----- 0.6022307148253525\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19180\n",
            "The AUC Score for Questions [36, 20, 22, 34, 3, 23, 27] ----- 0.560793107328286\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19181\n",
            "The AUC Score for Questions [5, 28, 7, 40, 27, 24, 12] ----- 0.5960380800823005\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19182\n",
            "The AUC Score for Questions [32, 7, 13, 39, 35, 10, 15] ----- 0.43969715966629697\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19183\n",
            "The AUC Score for Questions [36, 0, 32, 39, 10, 22, 11] ----- 0.48936884152320337\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19184\n",
            "The AUC Score for Questions [16, 8, 19, 31, 34, 25, 5] ----- 0.6277185706707816\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19185\n",
            "The AUC Score for Questions [13, 4, 10, 8, 32, 40, 34] ----- 0.4113782128562473\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19186\n",
            "The AUC Score for Questions [31, 30, 17, 24, 29, 25, 1] ----- 0.7213756409638166\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19187\n",
            "The AUC Score for Questions [9, 6, 2, 5, 36, 8, 30] ----- 0.42295775666682733\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19188\n",
            "The AUC Score for Questions [25, 16, 33, 1, 28, 3, 4] ----- 0.48677082831010593\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19189\n",
            "The AUC Score for Questions [40, 35, 9, 4, 32, 23, 31] ----- 0.45784306633875044\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19190\n",
            "The AUC Score for Questions [33, 30, 29, 26, 37, 12, 0] ----- 0.44289796016781596\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19191\n",
            "The AUC Score for Questions [2, 3, 36, 19, 21, 37, 29] ----- 0.5808860169423413\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19192\n",
            "The AUC Score for Questions [16, 25, 39, 12, 13, 19, 30] ----- 0.36904245229943256\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19193\n",
            "The AUC Score for Questions [15, 37, 30, 36, 18, 34, 8] ----- 0.48572398771921366\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19194\n",
            "The AUC Score for Questions [17, 29, 20, 30, 15, 23, 38] ----- 0.5944788702962499\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19195\n",
            "The AUC Score for Questions [22, 26, 40, 29, 28, 9, 7] ----- 0.6419965922425295\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19196\n",
            "The AUC Score for Questions [6, 19, 31, 15, 8, 22, 25] ----- 0.5437884779219109\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19197\n",
            "The AUC Score for Questions [26, 7, 29, 23, 12, 35, 20] ----- 0.5584904598865152\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19198\n",
            "The AUC Score for Questions [3, 32, 27, 16, 24, 1, 25] ----- 0.5959999035540339\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19199\n",
            "The AUC Score for Questions [14, 36, 34, 7, 19, 1, 2] ----- 0.5916317050039381\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19200\n",
            "The AUC Score for Questions [11, 32, 34, 30, 37, 21, 17] ----- 0.5070003697095369\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19201\n",
            "The AUC Score for Questions [31, 39, 20, 36, 32, 13, 17] ----- 0.4085210011091286\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19202\n",
            "The AUC Score for Questions [23, 15, 18, 11, 26, 9, 22] ----- 0.5972898683512562\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19203\n",
            "The AUC Score for Questions [8, 38, 2, 19, 35, 39, 13] ----- 0.39196444358714694\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19204\n",
            "The AUC Score for Questions [21, 36, 17, 15, 39, 38, 4] ----- 0.475345999903554\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19205\n",
            "The AUC Score for Questions [4, 35, 33, 10, 11, 31, 29] ----- 0.5357914998955169\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19206\n",
            "The AUC Score for Questions [12, 23, 19, 13, 7, 20, 38] ----- 0.3896617961453762\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19207\n",
            "The AUC Score for Questions [6, 15, 39, 18, 26, 31, 30] ----- 0.49084366108887495\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19208\n",
            "The AUC Score for Questions [23, 4, 19, 28, 3, 25, 13] ----- 0.403365160502162\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19209\n",
            "The AUC Score for Questions [7, 17, 14, 6, 21, 36, 15] ----- 0.5443912652103325\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19210\n",
            "The AUC Score for Questions [27, 16, 26, 31, 23, 2, 13] ----- 0.5435473630065423\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19211\n",
            "The AUC Score for Questions [18, 38, 13, 36, 7, 39, 11] ----- 0.41689773512722833\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19212\n",
            "The AUC Score for Questions [38, 5, 9, 33, 14, 28, 37] ----- 0.4311817845718603\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19213\n",
            "The AUC Score for Questions [24, 9, 26, 18, 8, 15, 6] ----- 0.5386145536962917\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19214\n",
            "The AUC Score for Questions [30, 6, 2, 31, 38, 8, 11] ----- 0.420136712157014\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19215\n",
            "The AUC Score for Questions [15, 6, 12, 31, 17, 20, 18] ----- 0.551453922939673\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19216\n",
            "The AUC Score for Questions [20, 24, 19, 37, 29, 0, 9] ----- 0.6149856938483549\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19217\n",
            "The AUC Score for Questions [12, 24, 2, 6, 23, 26, 30] ----- 0.5586270916718907\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19218\n",
            "The AUC Score for Questions [18, 19, 13, 9, 25, 35, 17] ----- 0.5245012939833791\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19219\n",
            "The AUC Score for Questions [12, 19, 35, 40, 28, 7, 20] ----- 0.40901528668563436\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19220\n",
            "The AUC Score for Questions [35, 6, 15, 40, 18, 0, 20] ----- 0.4275128192763337\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19221\n",
            "The AUC Score for Questions [31, 34, 6, 20, 11, 29, 23] ----- 0.5556613782128562\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19222\n",
            "The AUC Score for Questions [18, 19, 16, 37, 33, 29, 22] ----- 0.6020016556557521\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19223\n",
            "The AUC Score for Questions [2, 9, 27, 17, 21, 18, 32] ----- 0.5013080484158751\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19224\n",
            "The AUC Score for Questions [22, 26, 8, 0, 4, 9, 14] ----- 0.5802571088714215\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19225\n",
            "The AUC Score for Questions [5, 28, 25, 20, 30, 4, 40] ----- 0.3297286653485718\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19226\n",
            "The AUC Score for Questions [4, 11, 6, 8, 36, 20, 40] ----- 0.45184734210991623\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19227\n",
            "The AUC Score for Questions [14, 37, 33, 3, 25, 36, 11] ----- 0.5008860973139798\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19228\n",
            "The AUC Score for Questions [0, 19, 26, 16, 3, 14, 4] ----- 0.5250257189243059\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19229\n",
            "The AUC Score for Questions [20, 34, 22, 4, 18, 3, 24] ----- 0.42460537525518\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19230\n",
            "The AUC Score for Questions [1, 35, 33, 13, 27, 17, 22] ----- 0.45005304528138107\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19231\n",
            "The AUC Score for Questions [30, 11, 10, 16, 7, 6, 18] ----- 0.4771302502772822\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19232\n",
            "The AUC Score for Questions [33, 12, 29, 18, 14, 28, 19] ----- 0.5567162559675942\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19233\n",
            "The AUC Score for Questions [27, 35, 23, 32, 10, 11, 25] ----- 0.36299649579656335\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19234\n",
            "The AUC Score for Questions [21, 36, 25, 0, 17, 18, 32] ----- 0.5123410650849528\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19235\n",
            "The AUC Score for Questions [18, 40, 11, 12, 17, 34, 20] ----- 0.4515258555560914\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19236\n",
            "The AUC Score for Questions [13, 34, 28, 26, 11, 5, 8] ----- 0.5384337175097651\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19237\n",
            "The AUC Score for Questions [14, 5, 4, 17, 16, 29, 22] ----- 0.5964841426757326\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19238\n",
            "The AUC Score for Questions [30, 24, 27, 19, 15, 16, 4] ----- 0.636262075838678\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19239\n",
            "The AUC Score for Questions [25, 1, 38, 7, 15, 3, 22] ----- 0.5323455658967065\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19240\n",
            "The AUC Score for Questions [34, 1, 31, 11, 2, 7, 13] ----- 0.5137073829387085\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19241\n",
            "The AUC Score for Questions [27, 29, 22, 37, 10, 15, 31] ----- 0.5252467409300605\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19242\n",
            "The AUC Score for Questions [31, 3, 36, 25, 15, 4, 26] ----- 0.5811612898040539\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19243\n",
            "The AUC Score for Questions [12, 9, 29, 0, 28, 6, 30] ----- 0.49240086158396423\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19244\n",
            "The AUC Score for Questions [32, 23, 35, 12, 39, 11, 5] ----- 0.326831267782225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19245\n",
            "The AUC Score for Questions [22, 11, 3, 39, 24, 30, 9] ----- 0.6341282088376654\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19246\n",
            "The AUC Score for Questions [20, 1, 18, 14, 17, 2, 40] ----- 0.5109667100673514\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19247\n",
            "The AUC Score for Questions [37, 21, 9, 31, 22, 38, 8] ----- 0.48098206105029656\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19248\n",
            "The AUC Score for Questions [29, 12, 33, 21, 39, 5, 7] ----- 0.493692835672148\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19249\n",
            "The AUC Score for Questions [0, 34, 17, 39, 12, 22, 18] ----- 0.4833289128932182\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19250\n",
            "The AUC Score for Questions [32, 28, 2, 8, 6, 39, 30] ----- 0.4229356544662519\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19251\n",
            "The AUC Score for Questions [17, 9, 20, 29, 6, 33, 28] ----- 0.6366960826863417\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19252\n",
            "The AUC Score for Questions [33, 16, 20, 5, 7, 36, 37] ----- 0.520739901303628\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19253\n",
            "The AUC Score for Questions [13, 24, 39, 36, 34, 11, 28] ----- 0.6408111105753003\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19254\n",
            "The AUC Score for Questions [21, 0, 4, 40, 29, 6, 12] ----- 0.48680297696548835\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19255\n",
            "The AUC Score for Questions [15, 39, 17, 12, 13, 1, 7] ----- 0.4118925913423671\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19256\n",
            "The AUC Score for Questions [35, 37, 24, 6, 9, 15, 36] ----- 0.5334868431627847\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19257\n",
            "The AUC Score for Questions [22, 5, 39, 1, 10, 27, 31] ----- 0.38316374917619067\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19258\n",
            "The AUC Score for Questions [28, 21, 33, 17, 6, 39, 18] ----- 0.3536392277892977\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19259\n",
            "The AUC Score for Questions [37, 33, 12, 35, 23, 20, 38] ----- 0.33100657440002573\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19260\n",
            "The AUC Score for Questions [5, 25, 35, 15, 11, 18, 29] ----- 0.5729171689894069\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19261\n",
            "The AUC Score for Questions [19, 2, 14, 3, 4, 5, 26] ----- 0.373860732024883\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19262\n",
            "The AUC Score for Questions [29, 27, 38, 26, 6, 23, 34] ----- 0.5576043625725353\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19263\n",
            "The AUC Score for Questions [18, 3, 14, 22, 15, 20, 24] ----- 0.6683062480911737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19264\n",
            "The AUC Score for Questions [38, 15, 24, 32, 21, 9, 35] ----- 0.5718361704521708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19265\n",
            "The AUC Score for Questions [16, 14, 25, 23, 8, 10, 6] ----- 0.4605174326083812\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19266\n",
            "The AUC Score for Questions [2, 34, 14, 20, 5, 19, 18] ----- 0.4801421774284291\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19267\n",
            "The AUC Score for Questions [4, 14, 38, 16, 31, 26, 5] ----- 0.4533944961501985\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19268\n",
            "The AUC Score for Questions [18, 3, 1, 11, 24, 38, 35] ----- 0.5804761215862146\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19269\n",
            "The AUC Score for Questions [1, 40, 24, 3, 22, 19, 28] ----- 0.6704119850187266\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19270\n",
            "The AUC Score for Questions [9, 14, 40, 28, 16, 22, 4] ----- 0.580894054106187\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19271\n",
            "The AUC Score for Questions [24, 22, 2, 40, 25, 4, 21] ----- 0.49817757309800514\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19272\n",
            "The AUC Score for Questions [24, 17, 39, 37, 2, 35, 23] ----- 0.39473123724100234\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19273\n",
            "The AUC Score for Questions [14, 28, 26, 30, 36, 15, 2] ----- 0.5664954750767549\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19274\n",
            "The AUC Score for Questions [31, 35, 24, 23, 34, 1, 33] ----- 0.4907411872498433\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19275\n",
            "The AUC Score for Questions [36, 8, 23, 38, 29, 13, 20] ----- 0.45914508688174116\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19276\n",
            "The AUC Score for Questions [8, 24, 26, 3, 13, 20, 18] ----- 0.6102357300155921\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19277\n",
            "The AUC Score for Questions [37, 27, 24, 12, 31, 9, 6] ----- 0.5297736734661073\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19278\n",
            "The AUC Score for Questions [17, 31, 28, 39, 26, 32, 7] ----- 0.45358939737345483\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19279\n",
            "The AUC Score for Questions [27, 1, 23, 5, 8, 19, 10] ----- 0.5266974490041954\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19280\n",
            "The AUC Score for Questions [11, 24, 35, 1, 26, 33, 20] ----- 0.5206193438459437\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19281\n",
            "The AUC Score for Questions [3, 11, 26, 38, 10, 9, 7] ----- 0.5345135908440629\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19282\n",
            "The AUC Score for Questions [28, 32, 22, 26, 24, 35, 13] ----- 0.5386246001510986\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19283\n",
            "The AUC Score for Questions [3, 4, 20, 11, 21, 39, 25] ----- 0.522632653389272\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19284\n",
            "The AUC Score for Questions [18, 13, 1, 35, 9, 38, 31] ----- 0.46726061307485817\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19285\n",
            "The AUC Score for Questions [35, 32, 37, 16, 34, 31, 6] ----- 0.4926459950812557\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19286\n",
            "The AUC Score for Questions [21, 36, 27, 1, 34, 40, 8] ----- 0.5364646123675878\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19287\n",
            "The AUC Score for Questions [27, 13, 23, 20, 29, 14, 17] ----- 0.6382532831814309\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19288\n",
            "The AUC Score for Questions [37, 20, 1, 15, 26, 13, 34] ----- 0.5227813409204161\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19289\n",
            "The AUC Score for Questions [23, 36, 17, 14, 7, 27, 5] ----- 0.625817781421292\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19290\n",
            "The AUC Score for Questions [30, 15, 16, 20, 2, 11, 5] ----- 0.4969961100126987\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19291\n",
            "The AUC Score for Questions [31, 7, 26, 4, 34, 16, 23] ----- 0.5684243943997043\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19292\n",
            "The AUC Score for Questions [36, 17, 4, 22, 33, 39, 14] ----- 0.5369026377971742\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19293\n",
            "The AUC Score for Questions [30, 0, 9, 37, 27, 33, 40] ----- 0.6092572053173876\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19294\n",
            "The AUC Score for Questions [40, 27, 36, 26, 8, 24, 38] ----- 0.6657484206973043\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19295\n",
            "The AUC Score for Questions [25, 35, 38, 18, 16, 24, 10] ----- 0.4736099725128996\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19296\n",
            "The AUC Score for Questions [4, 7, 3, 29, 22, 23, 27] ----- 0.6184858787031232\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19297\n",
            "The AUC Score for Questions [17, 38, 39, 11, 15, 23, 9] ----- 0.5320180514699973\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19298\n",
            "The AUC Score for Questions [22, 12, 31, 9, 25, 5, 33] ----- 0.4667241323881629\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19299\n",
            "The AUC Score for Questions [5, 26, 9, 16, 4, 40, 1] ----- 0.6048729324396007\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19300\n",
            "The AUC Score for Questions [18, 6, 38, 2, 8, 28, 29] ----- 0.41911599234862\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19301\n",
            "The AUC Score for Questions [24, 37, 3, 7, 13, 39, 15] ----- 0.5461935992027134\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19302\n",
            "The AUC Score for Questions [20, 18, 37, 25, 14, 3, 11] ----- 0.4411780071048529\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19303\n",
            "The AUC Score for Questions [18, 6, 3, 16, 26, 13, 9] ----- 0.5445319155776309\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19304\n",
            "The AUC Score for Questions [20, 3, 37, 0, 17, 1, 39] ----- 0.5328961116201315\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19305\n",
            "The AUC Score for Questions [0, 25, 36, 3, 16, 31, 10] ----- 0.5642048833807526\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19306\n",
            "The AUC Score for Questions [31, 39, 28, 10, 16, 26, 35] ----- 0.4614698365240874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19307\n",
            "The AUC Score for Questions [39, 6, 16, 14, 37, 32, 12] ----- 0.3741360048865956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19308\n",
            "The AUC Score for Questions [32, 27, 6, 15, 31, 18, 25] ----- 0.595559868833486\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19309\n",
            "The AUC Score for Questions [10, 22, 30, 19, 31, 36, 9] ----- 0.5382689556509299\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19310\n",
            "The AUC Score for Questions [29, 31, 11, 34, 39, 24, 6] ----- 0.5608292745655914\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19311\n",
            "The AUC Score for Questions [16, 30, 32, 23, 31, 37, 5] ----- 0.4352847567150504\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19312\n",
            "The AUC Score for Questions [22, 15, 31, 32, 20, 24, 5] ----- 0.4338501229686068\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19313\n",
            "The AUC Score for Questions [25, 30, 9, 35, 31, 38, 27] ----- 0.48696773882432365\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19314\n",
            "The AUC Score for Questions [40, 35, 23, 3, 24, 18, 14] ----- 0.5197051164585041\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19315\n",
            "The AUC Score for Questions [35, 12, 19, 31, 14, 25, 40] ----- 0.34961662728456383\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19316\n",
            "The AUC Score for Questions [25, 14, 35, 29, 2, 5, 10] ----- 0.440717879474691\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19317\n",
            "The AUC Score for Questions [22, 23, 6, 29, 40, 8, 5] ----- 0.5479296265933677\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19318\n",
            "The AUC Score for Questions [30, 8, 17, 14, 40, 31, 4] ----- 0.5615767308032342\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19319\n",
            "The AUC Score for Questions [3, 36, 5, 27, 2, 15, 40] ----- 0.530937052932761\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19320\n",
            "The AUC Score for Questions [20, 40, 2, 31, 4, 0, 26] ----- 0.4371453601453119\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19321\n",
            "The AUC Score for Questions [5, 2, 33, 39, 32, 38, 29] ----- 0.363342093841925\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19322\n",
            "The AUC Score for Questions [12, 8, 6, 32, 36, 16, 33] ----- 0.5702166819372779\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19323\n",
            "The AUC Score for Questions [23, 34, 8, 38, 17, 22, 33] ----- 0.5640642330134542\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19324\n",
            "The AUC Score for Questions [35, 16, 26, 17, 39, 4, 24] ----- 0.558687370400733\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19325\n",
            "The AUC Score for Questions [39, 33, 21, 29, 38, 13, 16] ----- 0.419423413865715\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19326\n",
            "The AUC Score for Questions [34, 27, 35, 29, 22, 0, 38] ----- 0.6134164376074971\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19327\n",
            "The AUC Score for Questions [40, 25, 23, 14, 35, 18, 19] ----- 0.41964242658050827\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19328\n",
            "The AUC Score for Questions [26, 30, 34, 18, 14, 3, 21] ----- 0.5727262863480735\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19329\n",
            "The AUC Score for Questions [19, 5, 26, 23, 32, 24, 28] ----- 0.40785592580090335\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19330\n",
            "The AUC Score for Questions [37, 18, 33, 17, 12, 34, 19] ----- 0.5218329555866326\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19331\n",
            "The AUC Score for Questions [20, 37, 15, 14, 34, 13, 22] ----- 0.49358835254215494\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19332\n",
            "The AUC Score for Questions [38, 2, 4, 18, 16, 29, 30] ----- 0.49149467136037034\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19333\n",
            "The AUC Score for Questions [29, 16, 34, 7, 39, 37, 38] ----- 0.5012638440147241\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19334\n",
            "The AUC Score for Questions [3, 32, 35, 31, 25, 27, 28] ----- 0.3416799279870119\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19335\n",
            "The AUC Score for Questions [7, 33, 18, 22, 20, 10, 0] ----- 0.5400371316969668\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19336\n",
            "The AUC Score for Questions [6, 39, 13, 29, 27, 23, 32] ----- 0.5140750831846458\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19337\n",
            "The AUC Score for Questions [5, 25, 17, 37, 18, 6, 3] ----- 0.36450949189050164\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19338\n",
            "The AUC Score for Questions [15, 17, 11, 24, 9, 12, 27] ----- 0.6039526771792769\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19339\n",
            "The AUC Score for Questions [33, 0, 37, 34, 36, 5, 13] ----- 0.5040688141968462\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19340\n",
            "The AUC Score for Questions [38, 6, 29, 9, 25, 21, 16] ----- 0.5166007619231326\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19341\n",
            "The AUC Score for Questions [37, 24, 15, 1, 27, 14, 12] ----- 0.6073564160678979\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19342\n",
            "The AUC Score for Questions [33, 22, 8, 27, 7, 31, 32] ----- 0.49030316182025685\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19343\n",
            "The AUC Score for Questions [27, 1, 17, 40, 11, 20, 15] ----- 0.5719446721640867\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19344\n",
            "The AUC Score for Questions [32, 3, 14, 34, 4, 36, 20] ----- 0.5226748484994614\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19345\n",
            "The AUC Score for Questions [25, 29, 19, 37, 38, 28, 30] ----- 0.5344211634598383\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19346\n",
            "The AUC Score for Questions [23, 15, 7, 33, 36, 13, 28] ----- 0.5608393210203984\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19347\n",
            "The AUC Score for Questions [2, 1, 23, 31, 14, 13, 12] ----- 0.40774541479802606\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19348\n",
            "The AUC Score for Questions [39, 20, 17, 7, 40, 11, 8] ----- 0.562878751346225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19349\n",
            "The AUC Score for Questions [16, 37, 9, 38, 30, 32, 17] ----- 0.5305151018308659\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19350\n",
            "The AUC Score for Questions [38, 34, 21, 25, 4, 22, 16] ----- 0.4358594139300124\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19351\n",
            "The AUC Score for Questions [7, 35, 0, 16, 22, 1, 11] ----- 0.5386145536962916\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19352\n",
            "The AUC Score for Questions [8, 31, 9, 14, 33, 2, 40] ----- 0.49347382295735476\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19353\n",
            "The AUC Score for Questions [30, 16, 37, 34, 6, 27, 21] ----- 0.5047379080869943\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19354\n",
            "The AUC Score for Questions [37, 26, 36, 14, 35, 4, 29] ----- 0.5214511903039655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19355\n",
            "The AUC Score for Questions [23, 19, 37, 28, 35, 2, 29] ----- 0.4808775779203035\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19356\n",
            "The AUC Score for Questions [13, 1, 38, 34, 36, 17, 15] ----- 0.4500892125186864\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19357\n",
            "The AUC Score for Questions [1, 36, 39, 16, 17, 18, 25] ----- 0.49125154715404035\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19358\n",
            "The AUC Score for Questions [9, 21, 13, 29, 25, 36, 26] ----- 0.6061026185079809\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19359\n",
            "The AUC Score for Questions [23, 8, 31, 27, 15, 40, 5] ----- 0.5529227146324605\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19360\n",
            "The AUC Score for Questions [19, 12, 21, 31, 29, 9, 40] ----- 0.6228982816543698\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19361\n",
            "The AUC Score for Questions [29, 23, 14, 28, 6, 25, 8] ----- 0.5050975711690859\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19362\n",
            "The AUC Score for Questions [14, 11, 31, 16, 26, 40, 27] ----- 0.5559346417836074\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19363\n",
            "The AUC Score for Questions [21, 39, 7, 10, 17, 4, 14] ----- 0.5268923502274517\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19364\n",
            "The AUC Score for Questions [26, 18, 31, 38, 36, 21, 7] ----- 0.5128152577518446\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19365\n",
            "The AUC Score for Questions [5, 6, 7, 10, 8, 11, 27] ----- 0.4701901592965874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19366\n",
            "The AUC Score for Questions [33, 13, 40, 32, 8, 27, 4] ----- 0.4138114642105094\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19367\n",
            "The AUC Score for Questions [36, 26, 40, 38, 10, 25, 5] ----- 0.46649105463663987\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19368\n",
            "The AUC Score for Questions [37, 8, 20, 16, 30, 6, 1] ----- 0.5248267991191269\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19369\n",
            "The AUC Score for Questions [9, 2, 13, 23, 25, 27, 34] ----- 0.5260745688061597\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19370\n",
            "The AUC Score for Questions [28, 13, 21, 25, 33, 6, 14] ----- 0.49987743325135425\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19371\n",
            "The AUC Score for Questions [40, 3, 6, 11, 12, 15, 22] ----- 0.46994703509025737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19372\n",
            "The AUC Score for Questions [18, 6, 12, 9, 36, 23, 21] ----- 0.550190078924949\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19373\n",
            "The AUC Score for Questions [37, 11, 36, 32, 7, 39, 38] ----- 0.4221339473726511\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19374\n",
            "The AUC Score for Questions [20, 31, 36, 35, 15, 4, 8] ----- 0.5023347960971533\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19375\n",
            "The AUC Score for Questions [14, 19, 8, 12, 40, 22, 23] ----- 0.4854065197473116\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19376\n",
            "The AUC Score for Questions [25, 15, 0, 6, 28, 12, 26] ----- 0.4574110687820482\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19377\n",
            "The AUC Score for Questions [35, 12, 36, 32, 8, 5, 38] ----- 0.5424201507771937\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19378\n",
            "The AUC Score for Questions [2, 38, 30, 20, 24, 4, 28] ----- 0.4187060969924933\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19379\n",
            "The AUC Score for Questions [34, 13, 7, 36, 26, 15, 12] ----- 0.483248541254762\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19380\n",
            "The AUC Score for Questions [37, 23, 17, 11, 35, 12, 19] ----- 0.4472038706981081\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19381\n",
            "The AUC Score for Questions [0, 16, 27, 15, 37, 14, 2] ----- 0.5146879169278745\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19382\n",
            "The AUC Score for Questions [38, 18, 21, 8, 16, 19, 1] ----- 0.5187346289241453\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19383\n",
            "The AUC Score for Questions [21, 19, 2, 24, 0, 6, 22] ----- 0.6008141646975615\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19384\n",
            "The AUC Score for Questions [8, 22, 9, 12, 1, 36, 21] ----- 0.5651050457314624\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19385\n",
            "The AUC Score for Questions [6, 25, 37, 2, 16, 29, 4] ----- 0.4045184935140088\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19386\n",
            "The AUC Score for Questions [39, 23, 27, 33, 10, 30, 19] ----- 0.46821904486344856\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19387\n",
            "The AUC Score for Questions [16, 6, 9, 11, 28, 25, 37] ----- 0.4704071627204192\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19388\n",
            "The AUC Score for Questions [34, 21, 20, 35, 11, 14, 26] ----- 0.5124415296330231\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19389\n",
            "The AUC Score for Questions [19, 15, 17, 30, 4, 25, 32] ----- 0.5373245888990693\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19390\n",
            "The AUC Score for Questions [34, 27, 20, 23, 2, 0, 15] ----- 0.5827868061918311\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19391\n",
            "The AUC Score for Questions [26, 1, 4, 0, 25, 10, 23] ----- 0.4410634775200527\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19392\n",
            "The AUC Score for Questions [2, 7, 16, 34, 21, 15, 24] ----- 0.5986923534423174\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19393\n",
            "The AUC Score for Questions [33, 2, 5, 3, 17, 38, 13] ----- 0.32742601790680104\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19394\n",
            "The AUC Score for Questions [37, 32, 0, 28, 17, 18, 10] ----- 0.4414974843677163\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19395\n",
            "The AUC Score for Questions [35, 18, 39, 3, 24, 9, 33] ----- 0.4592756907942326\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19396\n",
            "The AUC Score for Questions [25, 0, 31, 9, 38, 2, 36] ----- 0.47745776470399126\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19397\n",
            "The AUC Score for Questions [16, 1, 36, 13, 25, 4, 30] ----- 0.44226905209689604\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19398\n",
            "The AUC Score for Questions [28, 10, 20, 6, 37, 24, 36] ----- 0.3615940107055023\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19399\n",
            "The AUC Score for Questions [28, 8, 14, 13, 23, 33, 32] ----- 0.3918378582565784\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19400\n",
            "The AUC Score for Questions [22, 10, 34, 23, 15, 24, 17] ----- 0.5851858995997492\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19401\n",
            "The AUC Score for Questions [22, 32, 29, 23, 0, 26, 2] ----- 0.4834554982237868\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19402\n",
            "The AUC Score for Questions [33, 14, 40, 26, 9, 24, 8] ----- 0.6004424458697015\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19403\n",
            "The AUC Score for Questions [12, 26, 37, 24, 35, 34, 27] ----- 0.5541865586471846\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19404\n",
            "The AUC Score for Questions [22, 3, 26, 2, 24, 15, 13] ----- 0.6104105383292343\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19405\n",
            "The AUC Score for Questions [9, 34, 26, 39, 6, 24, 2] ----- 0.5787079455401778\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19406\n",
            "The AUC Score for Questions [19, 1, 5, 26, 21, 16, 38] ----- 0.5023066660236936\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19407\n",
            "The AUC Score for Questions [2, 26, 12, 35, 4, 21, 16] ----- 0.4433259391425953\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19408\n",
            "The AUC Score for Questions [35, 1, 31, 22, 18, 27, 28] ----- 0.4236951664496632\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19409\n",
            "The AUC Score for Questions [27, 6, 8, 40, 16, 22, 9] ----- 0.5109265242481232\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19410\n",
            "The AUC Score for Questions [10, 32, 34, 8, 20, 11, 40] ----- 0.42042002218257224\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19411\n",
            "The AUC Score for Questions [23, 34, 30, 40, 28, 0, 26] ----- 0.5846032052209417\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19412\n",
            "The AUC Score for Questions [36, 1, 15, 12, 31, 38, 26] ----- 0.4873896899262188\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19413\n",
            "The AUC Score for Questions [34, 11, 24, 23, 18, 36, 20] ----- 0.6429590426130427\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19414\n",
            "The AUC Score for Questions [2, 33, 20, 13, 19, 27, 6] ----- 0.42922071659352856\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19415\n",
            "The AUC Score for Questions [30, 36, 27, 28, 4, 1, 9] ----- 0.6040571603092699\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19416\n",
            "The AUC Score for Questions [6, 0, 25, 38, 40, 37, 34] ----- 0.3981470318753918\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19417\n",
            "The AUC Score for Questions [0, 5, 18, 22, 19, 16, 34] ----- 0.5478231341724132\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19418\n",
            "The AUC Score for Questions [17, 30, 39, 5, 25, 24, 21] ----- 0.5538650720933597\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19419\n",
            "The AUC Score for Questions [27, 17, 8, 30, 13, 23, 9] ----- 0.5885695455787562\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19420\n",
            "The AUC Score for Questions [11, 13, 25, 33, 40, 5, 4] ----- 0.4377461381427722\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19421\n",
            "The AUC Score for Questions [6, 16, 40, 32, 27, 14, 3] ----- 0.5120075227853595\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19422\n",
            "The AUC Score for Questions [4, 7, 18, 21, 13, 17, 3] ----- 0.5258495282184822\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19423\n",
            "The AUC Score for Questions [26, 34, 27, 14, 3, 29, 0] ----- 0.6011858835254216\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19424\n",
            "The AUC Score for Questions [32, 25, 40, 7, 6, 16, 15] ----- 0.5348732539261546\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19425\n",
            "The AUC Score for Questions [27, 21, 25, 6, 38, 19, 37] ----- 0.44578330198839433\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19426\n",
            "The AUC Score for Questions [23, 20, 25, 1, 21, 3, 28] ----- 0.6545245213868929\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19427\n",
            "The AUC Score for Questions [22, 31, 37, 10, 9, 7, 14] ----- 0.5606042339779138\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19428\n",
            "The AUC Score for Questions [5, 30, 23, 31, 3, 12, 1] ----- 0.39864734532478174\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19429\n",
            "The AUC Score for Questions [13, 15, 24, 40, 30, 39, 0] ----- 0.5719386442912024\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19430\n",
            "The AUC Score for Questions [34, 15, 40, 25, 38, 28, 9] ----- 0.5399647972223561\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19431\n",
            "The AUC Score for Questions [21, 18, 17, 24, 37, 38, 36] ----- 0.5255762646477311\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19432\n",
            "The AUC Score for Questions [3, 2, 24, 4, 19, 31, 5] ----- 0.27755943482663836\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19433\n",
            "The AUC Score for Questions [31, 5, 16, 25, 9, 34, 3] ----- 0.5799416501904808\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19434\n",
            "The AUC Score for Questions [32, 20, 30, 40, 14, 5, 11] ----- 0.4320497982671874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19435\n",
            "The AUC Score for Questions [7, 36, 27, 23, 30, 35, 2] ----- 0.5347285849769333\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19436\n",
            "The AUC Score for Questions [32, 12, 31, 21, 18, 28, 23] ----- 0.5017822410827668\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19437\n",
            "The AUC Score for Questions [36, 15, 28, 9, 14, 34, 1] ----- 0.584659465367861\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19438\n",
            "The AUC Score for Questions [24, 26, 5, 10, 17, 2, 36] ----- 0.6170150777193744\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19439\n",
            "The AUC Score for Questions [22, 19, 33, 21, 28, 38, 15] ----- 0.5581508897140377\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19440\n",
            "The AUC Score for Questions [15, 22, 9, 19, 7, 12, 38] ----- 0.5115453858642363\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19441\n",
            "The AUC Score for Questions [40, 29, 11, 31, 21, 17, 18] ----- 0.5958110302036618\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19442\n",
            "The AUC Score for Questions [22, 39, 35, 36, 24, 10, 0] ----- 0.5895179309125396\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19443\n",
            "The AUC Score for Questions [17, 11, 5, 25, 16, 20, 14] ----- 0.5469732040957387\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19444\n",
            "The AUC Score for Questions [12, 32, 35, 17, 2, 13, 25] ----- 0.31818729806625834\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19445\n",
            "The AUC Score for Questions [33, 31, 6, 39, 4, 1, 21] ----- 0.4946633232065068\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19446\n",
            "The AUC Score for Questions [22, 9, 38, 19, 2, 6, 29] ----- 0.6529713394737265\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19447\n",
            "The AUC Score for Questions [5, 19, 24, 3, 26, 6, 22] ----- 0.34658058864188007\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19448\n",
            "The AUC Score for Questions [18, 23, 7, 19, 0, 33, 39] ----- 0.49910787481313595\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19449\n",
            "The AUC Score for Questions [20, 39, 26, 0, 36, 21, 35] ----- 0.48004774075324297\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19450\n",
            "The AUC Score for Questions [6, 30, 0, 40, 9, 37, 23] ----- 0.5254818279725451\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19451\n",
            "The AUC Score for Questions [40, 2, 28, 36, 25, 15, 11] ----- 0.5065141212968768\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19452\n",
            "The AUC Score for Questions [25, 0, 4, 14, 39, 23, 21] ----- 0.6353317741235474\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19453\n",
            "The AUC Score for Questions [17, 12, 5, 28, 8, 35, 32] ----- 0.4465568790085355\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19454\n",
            "The AUC Score for Questions [36, 27, 4, 26, 34, 13, 2] ----- 0.5438809053061356\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19455\n",
            "The AUC Score for Questions [20, 17, 30, 0, 27, 29, 21] ----- 0.656129944865056\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19456\n",
            "The AUC Score for Questions [14, 10, 31, 4, 2, 17, 18] ----- 0.43035797527768394\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19457\n",
            "The AUC Score for Questions [12, 17, 9, 0, 18, 1, 38] ----- 0.4132669463599685\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19458\n",
            "The AUC Score for Questions [31, 3, 21, 20, 38, 0, 4] ----- 0.4664408223626047\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19459\n",
            "The AUC Score for Questions [7, 25, 5, 26, 34, 32, 27] ----- 0.5422935654466252\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19460\n",
            "The AUC Score for Questions [39, 16, 34, 3, 40, 26, 11] ----- 0.4797081705807655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19461\n",
            "The AUC Score for Questions [17, 11, 10, 26, 34, 25, 15] ----- 0.5751997235215638\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19462\n",
            "The AUC Score for Questions [0, 18, 25, 5, 30, 9, 2] ----- 0.5813260516628892\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19463\n",
            "The AUC Score for Questions [13, 4, 0, 18, 38, 11, 30] ----- 0.4568665509315073\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19464\n",
            "The AUC Score for Questions [3, 33, 30, 26, 1, 17, 16] ----- 0.6032775554162446\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19465\n",
            "The AUC Score for Questions [31, 6, 27, 0, 4, 22, 15] ----- 0.5541704843194935\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19466\n",
            "The AUC Score for Questions [31, 19, 16, 35, 0, 34, 36] ----- 0.5771085499348989\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19467\n",
            "The AUC Score for Questions [22, 32, 30, 36, 20, 34, 29] ----- 0.5303885165002974\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19468\n",
            "The AUC Score for Questions [10, 39, 19, 0, 15, 32, 8] ----- 0.4864111652280143\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19469\n",
            "The AUC Score for Questions [32, 1, 10, 6, 38, 39, 21] ----- 0.44862644869878315\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19470\n",
            "The AUC Score for Questions [28, 8, 11, 17, 40, 27, 20] ----- 0.5857625661056727\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19471\n",
            "The AUC Score for Questions [35, 29, 2, 39, 13, 22, 11] ----- 0.535013904293453\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19472\n",
            "The AUC Score for Questions [2, 36, 16, 33, 18, 39, 23] ----- 0.3794566073523975\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19473\n",
            "The AUC Score for Questions [8, 36, 14, 16, 40, 34, 26] ----- 0.5388416035749305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19474\n",
            "The AUC Score for Questions [9, 3, 28, 2, 20, 31, 39] ----- 0.5287891208950185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19475\n",
            "The AUC Score for Questions [10, 29, 4, 40, 31, 16, 7] ----- 0.5963314365626657\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19476\n",
            "The AUC Score for Questions [32, 0, 1, 36, 3, 8, 16] ----- 0.5726117567632734\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19477\n",
            "The AUC Score for Questions [15, 23, 17, 27, 40, 6, 21] ----- 0.561293420777676\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19478\n",
            "The AUC Score for Questions [14, 39, 40, 2, 24, 27, 17] ----- 0.6705385703492951\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19479\n",
            "The AUC Score for Questions [12, 24, 28, 34, 11, 37, 19] ----- 0.512847406407227\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19480\n",
            "The AUC Score for Questions [23, 32, 4, 3, 11, 15, 14] ----- 0.476549565189436\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19481\n",
            "The AUC Score for Questions [7, 24, 23, 27, 3, 34, 36] ----- 0.6568110945009725\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19482\n",
            "The AUC Score for Questions [2, 34, 3, 12, 28, 4, 21] ----- 0.521260307662632\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19483\n",
            "The AUC Score for Questions [4, 15, 21, 2, 38, 33, 30] ----- 0.5127308675314655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19484\n",
            "The AUC Score for Questions [20, 7, 27, 12, 29, 19, 9] ----- 0.627596003922136\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19485\n",
            "The AUC Score for Questions [3, 39, 19, 12, 22, 9, 10] ----- 0.48553913295076434\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19486\n",
            "The AUC Score for Questions [26, 0, 3, 1, 12, 9, 29] ----- 0.4994293613669608\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19487\n",
            "The AUC Score for Questions [1, 24, 14, 7, 4, 36, 35] ----- 0.6256289080709199\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19488\n",
            "The AUC Score for Questions [22, 23, 14, 29, 10, 27, 7] ----- 0.6828715982704023\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19489\n",
            "The AUC Score for Questions [10, 8, 9, 4, 39, 23, 35] ----- 0.48886450949189053\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19490\n",
            "The AUC Score for Questions [22, 3, 31, 30, 32, 28, 2] ----- 0.3336970149973477\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19491\n",
            "The AUC Score for Questions [24, 23, 8, 30, 9, 21, 12] ----- 0.5876975133015062\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19492\n",
            "The AUC Score for Questions [5, 15, 25, 35, 12, 21, 36] ----- 0.5114529584800116\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19493\n",
            "The AUC Score for Questions [2, 18, 21, 25, 3, 5, 8] ----- 0.4122180964781148\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19494\n",
            "The AUC Score for Questions [24, 22, 33, 35, 29, 7, 31] ----- 0.6233463535387632\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19495\n",
            "The AUC Score for Questions [27, 18, 8, 10, 7, 20, 0] ----- 0.6701186285383613\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19496\n",
            "The AUC Score for Questions [17, 31, 33, 28, 6, 24, 20] ----- 0.5189375673112472\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19497\n",
            "The AUC Score for Questions [10, 15, 27, 34, 20, 37, 36] ----- 0.5463623796434713\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19498\n",
            "The AUC Score for Questions [2, 7, 11, 19, 0, 5, 10] ----- 0.4484074359839899\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19499\n",
            "The AUC Score for Questions [7, 31, 10, 17, 21, 11, 12] ----- 0.4793625725354037\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19500\n",
            "The AUC Score for Questions [7, 29, 3, 17, 30, 8, 38] ----- 0.5399065277844755\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19501\n",
            "The AUC Score for Questions [28, 3, 10, 12, 8, 37, 24] ----- 0.4341696002314704\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19502\n",
            "The AUC Score for Questions [23, 1, 11, 13, 36, 28, 25] ----- 0.6029560688624198\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19503\n",
            "The AUC Score for Questions [37, 9, 2, 31, 35, 28, 7] ----- 0.46143768786870487\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19504\n",
            "The AUC Score for Questions [8, 30, 26, 22, 20, 25, 19] ----- 0.5513755605921782\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19505\n",
            "The AUC Score for Questions [33, 0, 34, 10, 4, 19, 25] ----- 0.5405354358553953\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19506\n",
            "The AUC Score for Questions [23, 5, 26, 40, 9, 14, 2] ----- 0.5819629968976547\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19507\n",
            "The AUC Score for Questions [35, 21, 4, 26, 29, 14, 39] ----- 0.5432118114159875\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19508\n",
            "The AUC Score for Questions [35, 23, 0, 24, 19, 31, 25] ----- 0.5639175547732717\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19509\n",
            "The AUC Score for Questions [5, 30, 19, 1, 28, 12, 38] ----- 0.3599845686454164\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19510\n",
            "The AUC Score for Questions [4, 28, 35, 32, 7, 26, 3] ----- 0.42210782659015283\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19511\n",
            "The AUC Score for Questions [18, 0, 14, 38, 32, 33, 11] ----- 0.416073925833052\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19512\n",
            "The AUC Score for Questions [0, 23, 25, 37, 4, 17, 34] ----- 0.527314301329347\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19513\n",
            "The AUC Score for Questions [3, 24, 12, 17, 38, 13, 10] ----- 0.4672365015833213\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19514\n",
            "The AUC Score for Questions [40, 35, 23, 34, 20, 39, 4] ----- 0.3906985902814615\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19515\n",
            "The AUC Score for Questions [11, 24, 29, 6, 27, 17, 25] ----- 0.6451813184163572\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19516\n",
            "The AUC Score for Questions [29, 14, 35, 37, 7, 40, 6] ----- 0.43036199385960683\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19517\n",
            "The AUC Score for Questions [18, 28, 33, 14, 24, 3, 39] ----- 0.5257068685602225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19518\n",
            "The AUC Score for Questions [15, 13, 5, 30, 12, 6, 8] ----- 0.38013172911542975\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19519\n",
            "The AUC Score for Questions [30, 33, 17, 31, 2, 12, 26] ----- 0.46303708347398365\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19520\n",
            "The AUC Score for Questions [17, 23, 26, 8, 38, 6, 24] ----- 0.4564445998296121\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19521\n",
            "The AUC Score for Questions [27, 6, 1, 9, 32, 30, 12] ----- 0.5079045506421693\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19522\n",
            "The AUC Score for Questions [14, 31, 34, 8, 32, 25, 20] ----- 0.48438579993891756\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19523\n",
            "The AUC Score for Questions [18, 26, 37, 21, 28, 13, 23] ----- 0.5244852196556878\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19524\n",
            "The AUC Score for Questions [39, 38, 31, 21, 19, 27, 32] ----- 0.4307457684332352\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19525\n",
            "The AUC Score for Questions [10, 7, 17, 21, 28, 4, 0] ----- 0.5501961067978332\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19526\n",
            "The AUC Score for Questions [19, 18, 8, 23, 32, 33, 14] ----- 0.4002266480204465\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19527\n",
            "The AUC Score for Questions [30, 26, 39, 7, 16, 1, 38] ----- 0.4807108067705068\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19528\n",
            "The AUC Score for Questions [40, 7, 26, 16, 39, 29, 23] ----- 0.5942980341097233\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19529\n",
            "The AUC Score for Questions [28, 4, 14, 29, 26, 16, 0] ----- 0.587661346064201\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19530\n",
            "The AUC Score for Questions [30, 2, 31, 29, 16, 17, 39] ----- 0.5662623973252319\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19531\n",
            "The AUC Score for Questions [16, 31, 33, 4, 21, 14, 28] ----- 0.5112359550561798\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19532\n",
            "The AUC Score for Questions [33, 6, 4, 24, 32, 3, 34] ----- 0.38040700197714233\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19533\n",
            "The AUC Score for Questions [12, 2, 27, 14, 33, 28, 37] ----- 0.4667582903345068\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19534\n",
            "The AUC Score for Questions [17, 40, 22, 38, 1, 11, 29] ----- 0.5316262397325232\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19535\n",
            "The AUC Score for Questions [16, 3, 17, 22, 28, 32, 7] ----- 0.5000120557457683\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19536\n",
            "The AUC Score for Questions [26, 11, 38, 23, 37, 13, 8] ----- 0.43970318753918114\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19537\n",
            "The AUC Score for Questions [1, 34, 10, 40, 32, 7, 30] ----- 0.5770241597145199\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19538\n",
            "The AUC Score for Questions [35, 16, 24, 9, 14, 25, 1] ----- 0.6156748806481169\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19539\n",
            "The AUC Score for Questions [27, 31, 23, 17, 9, 35, 7] ----- 0.5375335551590554\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19540\n",
            "The AUC Score for Questions [2, 31, 17, 9, 16, 1, 4] ----- 0.5506502065551109\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19541\n",
            "The AUC Score for Questions [9, 31, 37, 15, 27, 3, 12] ----- 0.46248854704152\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19542\n",
            "The AUC Score for Questions [37, 8, 6, 40, 30, 25, 12] ----- 0.36302462587002304\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19543\n",
            "The AUC Score for Questions [37, 14, 16, 32, 4, 20, 24] ----- 0.4640055617173812\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19544\n",
            "The AUC Score for Questions [24, 17, 28, 37, 16, 5, 9] ----- 0.5310897590458279\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19545\n",
            "The AUC Score for Questions [31, 26, 35, 22, 16, 12, 0] ----- 0.4207616016460112\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19546\n",
            "The AUC Score for Questions [20, 38, 0, 34, 35, 10, 24] ----- 0.5320080050151902\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19547\n",
            "The AUC Score for Questions [0, 19, 22, 12, 31, 24, 30] ----- 0.5931507289707608\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19548\n",
            "The AUC Score for Questions [18, 36, 16, 34, 10, 11, 8] ----- 0.5231691340759672\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19549\n",
            "The AUC Score for Questions [17, 4, 14, 26, 2, 22, 18] ----- 0.5074383951391233\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19550\n",
            "The AUC Score for Questions [32, 12, 34, 7, 2, 1, 28] ----- 0.4795494365948144\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19551\n",
            "The AUC Score for Questions [27, 19, 31, 36, 24, 37, 28] ----- 0.6242224043979361\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19552\n",
            "The AUC Score for Questions [29, 25, 37, 40, 8, 5, 4] ----- 0.43562231759656656\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19553\n",
            "The AUC Score for Questions [8, 16, 33, 31, 5, 10, 21] ----- 0.4883742424973076\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19554\n",
            "The AUC Score for Questions [29, 27, 25, 40, 20, 21, 1] ----- 0.6127252415167737\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19555\n",
            "The AUC Score for Questions [7, 27, 23, 18, 15, 4, 39] ----- 0.5662202022150423\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19556\n",
            "The AUC Score for Questions [28, 34, 14, 16, 40, 11, 9] ----- 0.5586893796916944\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19557\n",
            "The AUC Score for Questions [17, 7, 11, 14, 8, 3, 12] ----- 0.5237056147626625\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19558\n",
            "The AUC Score for Questions [36, 7, 37, 26, 25, 18, 38] ----- 0.4962687466846699\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19559\n",
            "The AUC Score for Questions [9, 17, 25, 23, 15, 5, 3] ----- 0.6238205462056549\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19560\n",
            "The AUC Score for Questions [6, 25, 12, 18, 35, 32, 29] ----- 0.45930783944961506\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19561\n",
            "The AUC Score for Questions [14, 21, 20, 4, 1, 9, 2] ----- 0.5772331259745062\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19562\n",
            "The AUC Score for Questions [8, 27, 36, 26, 29, 10, 11] ----- 0.6212667373937086\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19563\n",
            "The AUC Score for Questions [40, 14, 23, 28, 6, 11, 35] ----- 0.3592330938258507\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19564\n",
            "The AUC Score for Questions [36, 23, 26, 25, 18, 17, 6] ----- 0.5227471829740721\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19565\n",
            "The AUC Score for Questions [3, 15, 30, 13, 6, 24, 32] ----- 0.5395468647023839\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19566\n",
            "The AUC Score for Questions [14, 5, 0, 24, 13, 38, 29] ----- 0.6169306874989954\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19567\n",
            "The AUC Score for Questions [2, 26, 9, 5, 0, 20, 18] ----- 0.5496736911478678\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19568\n",
            "The AUC Score for Questions [16, 37, 21, 33, 35, 0, 5] ----- 0.4669833309221842\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19569\n",
            "The AUC Score for Questions [20, 22, 26, 38, 13, 35, 34] ----- 0.4670235167414123\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19570\n",
            "The AUC Score for Questions [29, 16, 7, 17, 32, 36, 37] ----- 0.5549179405571363\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19571\n",
            "The AUC Score for Questions [3, 26, 25, 40, 35, 33, 0] ----- 0.385647232804488\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19572\n",
            "The AUC Score for Questions [22, 14, 18, 1, 5, 17, 16] ----- 0.577747504460626\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19573\n",
            "The AUC Score for Questions [32, 15, 9, 14, 26, 18, 5] ----- 0.5285399688158042\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19574\n",
            "The AUC Score for Questions [30, 0, 21, 31, 20, 2, 39] ----- 0.4561934384594365\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19575\n",
            "The AUC Score for Questions [11, 28, 30, 5, 27, 14, 7] ----- 0.5590430149009018\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19576\n",
            "The AUC Score for Questions [33, 20, 2, 23, 22, 5, 4] ----- 0.26266657022070056\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19577\n",
            "The AUC Score for Questions [22, 0, 8, 39, 28, 36, 26] ----- 0.5382830206876598\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19578\n",
            "The AUC Score for Questions [38, 10, 7, 26, 14, 22, 33] ----- 0.48097000530452816\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19579\n",
            "The AUC Score for Questions [12, 3, 33, 28, 20, 36, 23] ----- 0.5463242031152047\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19580\n",
            "The AUC Score for Questions [7, 22, 16, 37, 24, 34, 29] ----- 0.6217087814052178\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19581\n",
            "The AUC Score for Questions [35, 27, 23, 1, 28, 30, 26] ----- 0.5531738760026362\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19582\n",
            "The AUC Score for Questions [31, 23, 27, 11, 33, 3, 5] ----- 0.4605294883541496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19583\n",
            "The AUC Score for Questions [16, 27, 31, 10, 34, 38, 39] ----- 0.4353731655173523\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19584\n",
            "The AUC Score for Questions [19, 17, 3, 36, 21, 4, 20] ----- 0.5311178891192876\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19585\n",
            "The AUC Score for Questions [1, 21, 36, 40, 3, 30, 18] ----- 0.5516588706177364\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19586\n",
            "The AUC Score for Questions [6, 21, 24, 3, 15, 38, 33] ----- 0.5611688447380688\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19587\n",
            "The AUC Score for Questions [22, 11, 27, 39, 8, 10, 40] ----- 0.4254171288035878\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19588\n",
            "The AUC Score for Questions [13, 9, 21, 23, 5, 36, 1] ----- 0.5880109626914855\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19589\n",
            "The AUC Score for Questions [16, 24, 19, 11, 6, 30, 38] ----- 0.5605419459581102\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19590\n",
            "The AUC Score for Questions [33, 35, 8, 12, 29, 15, 36] ----- 0.5392535082220186\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19591\n",
            "The AUC Score for Questions [31, 6, 18, 22, 26, 34, 4] ----- 0.4709697641896128\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19592\n",
            "The AUC Score for Questions [4, 15, 38, 28, 27, 24, 25] ----- 0.5856379900660655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19593\n",
            "The AUC Score for Questions [13, 37, 5, 0, 7, 15, 24] ----- 0.5516689170725435\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19594\n",
            "The AUC Score for Questions [16, 13, 8, 28, 3, 32, 2] ----- 0.3767360273906544\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19595\n",
            "The AUC Score for Questions [20, 26, 9, 16, 13, 34, 17] ----- 0.5980433524617832\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19596\n",
            "The AUC Score for Questions [15, 34, 12, 31, 13, 39, 24] ----- 0.44344247801835684\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19597\n",
            "The AUC Score for Questions [6, 17, 34, 27, 7, 38, 29] ----- 0.5484701258619858\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19598\n",
            "The AUC Score for Questions [26, 22, 30, 14, 24, 37, 15] ----- 0.5923188825127389\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19599\n",
            "The AUC Score for Questions [5, 40, 33, 9, 29, 12, 38] ----- 0.5216621658549132\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19600\n",
            "The AUC Score for Questions [39, 11, 18, 2, 14, 4, 21] ----- 0.5256506084133031\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19601\n",
            "The AUC Score for Questions [3, 11, 30, 33, 22, 6, 39] ----- 0.3920428059346418\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19602\n",
            "The AUC Score for Questions [23, 27, 10, 22, 30, 15, 12] ----- 0.5445660735239748\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19603\n",
            "The AUC Score for Questions [35, 18, 27, 16, 15, 1, 4] ----- 0.4949365867772581\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19604\n",
            "The AUC Score for Questions [4, 7, 9, 27, 21, 20, 17] ----- 0.5739800839079906\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19605\n",
            "The AUC Score for Questions [14, 38, 6, 30, 16, 17, 2] ----- 0.4551144492131617\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19606\n",
            "The AUC Score for Questions [2, 18, 35, 20, 40, 1, 31] ----- 0.3515334908617447\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19607\n",
            "The AUC Score for Questions [22, 11, 20, 5, 6, 38, 8] ----- 0.35735641606789803\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19608\n",
            "The AUC Score for Questions [2, 29, 38, 21, 26, 34, 30] ----- 0.5699474369484496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19609\n",
            "The AUC Score for Questions [20, 17, 2, 4, 18, 37, 26] ----- 0.4405209689604732\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19610\n",
            "The AUC Score for Questions [0, 8, 27, 31, 20, 4, 15] ----- 0.689162688270563\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19611\n",
            "The AUC Score for Questions [26, 19, 18, 28, 39, 37, 5] ----- 0.4473907347575187\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19612\n",
            "The AUC Score for Questions [27, 7, 26, 29, 5, 2, 15] ----- 0.6356653164231406\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19613\n",
            "The AUC Score for Questions [7, 2, 38, 20, 25, 15, 14] ----- 0.4828326180257511\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19614\n",
            "The AUC Score for Questions [38, 17, 26, 39, 24, 34, 3] ----- 0.5438608123965214\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19615\n",
            "The AUC Score for Questions [1, 3, 13, 17, 0, 31, 12] ----- 0.3940500876050859\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19616\n",
            "The AUC Score for Questions [8, 1, 9, 29, 7, 31, 23] ----- 0.7200575460931345\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19617\n",
            "The AUC Score for Questions [36, 16, 1, 6, 15, 32, 17] ----- 0.598507498673868\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19618\n",
            "The AUC Score for Questions [37, 23, 13, 5, 32, 30, 3] ----- 0.42228062561283375\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19619\n",
            "The AUC Score for Questions [37, 33, 6, 29, 4, 31, 26] ----- 0.45307100030541225\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19620\n",
            "The AUC Score for Questions [9, 12, 20, 17, 36, 16, 19] ----- 0.5785954252463391\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19621\n",
            "The AUC Score for Questions [21, 18, 33, 31, 34, 26, 11] ----- 0.5008439022037904\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19622\n",
            "The AUC Score for Questions [20, 4, 32, 30, 26, 0, 11] ----- 0.4548974457893299\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19623\n",
            "The AUC Score for Questions [14, 21, 15, 30, 39, 16, 40] ----- 0.48874797061612896\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19624\n",
            "The AUC Score for Questions [26, 24, 21, 19, 7, 36, 16] ----- 0.6590836025783222\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19625\n",
            "The AUC Score for Questions [19, 36, 3, 31, 11, 14, 0] ----- 0.5614843034190095\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19626\n",
            "The AUC Score for Questions [38, 17, 16, 35, 8, 14, 28] ----- 0.5553559659867227\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19627\n",
            "The AUC Score for Questions [6, 32, 4, 39, 13, 20, 2] ----- 0.3200740222790182\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19628\n",
            "The AUC Score for Questions [35, 16, 27, 11, 30, 23, 8] ----- 0.4897566346787545\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19629\n",
            "The AUC Score for Questions [31, 3, 25, 33, 10, 40, 2] ----- 0.3318464580218932\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19630\n",
            "The AUC Score for Questions [31, 29, 28, 8, 33, 6, 37] ----- 0.49191059458938124\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19631\n",
            "The AUC Score for Questions [38, 20, 22, 2, 39, 3, 10] ----- 0.33983338959348025\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19632\n",
            "The AUC Score for Questions [39, 20, 7, 1, 12, 4, 15] ----- 0.49694185915674083\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19633\n",
            "The AUC Score for Questions [7, 19, 36, 27, 14, 13, 3] ----- 0.5891964443587147\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19634\n",
            "The AUC Score for Questions [35, 40, 20, 5, 15, 7, 34] ----- 0.47518927520856435\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19635\n",
            "The AUC Score for Questions [25, 38, 2, 20, 4, 27, 1] ----- 0.4290800662262301\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19636\n",
            "The AUC Score for Questions [30, 35, 1, 23, 16, 26, 3] ----- 0.5586270916718908\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19637\n",
            "The AUC Score for Questions [28, 29, 8, 27, 21, 23, 36] ----- 0.6799179405571362\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19638\n",
            "The AUC Score for Questions [17, 38, 31, 6, 39, 2, 20] ----- 0.3708568420375818\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19639\n",
            "The AUC Score for Questions [38, 31, 7, 40, 3, 39, 9] ----- 0.45816656218353663\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19640\n",
            "The AUC Score for Questions [28, 11, 6, 29, 15, 3, 8] ----- 0.5893190111073604\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19641\n",
            "The AUC Score for Questions [17, 39, 3, 36, 14, 28, 18] ----- 0.6109008053238173\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19642\n",
            "The AUC Score for Questions [3, 30, 0, 9, 25, 13, 23] ----- 0.6027732233849319\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19643\n",
            "The AUC Score for Questions [35, 16, 32, 24, 12, 17, 13] ----- 0.42313658356239253\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19644\n",
            "The AUC Score for Questions [1, 7, 23, 19, 36, 22, 29] ----- 0.6987871919756956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19645\n",
            "The AUC Score for Questions [38, 33, 29, 21, 35, 37, 4] ----- 0.4782313417241324\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19646\n",
            "The AUC Score for Questions [15, 31, 10, 30, 16, 39, 35] ----- 0.47221552458568417\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19647\n",
            "The AUC Score for Questions [3, 14, 17, 11, 34, 16, 35] ----- 0.49717895549018665\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19648\n",
            "The AUC Score for Questions [37, 30, 10, 11, 5, 0, 8] ----- 0.4803089485782257\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19649\n",
            "The AUC Score for Questions [38, 36, 5, 35, 10, 16, 18] ----- 0.3785785472022633\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19650\n",
            "The AUC Score for Questions [19, 7, 16, 40, 14, 11, 0] ----- 0.5728769831701789\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19651\n",
            "The AUC Score for Questions [15, 25, 3, 7, 37, 0, 5] ----- 0.4949205124495668\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19652\n",
            "The AUC Score for Questions [13, 36, 39, 15, 21, 40, 19] ----- 0.46502025365289096\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19653\n",
            "The AUC Score for Questions [26, 23, 8, 34, 17, 29, 39] ----- 0.6007840253331405\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19654\n",
            "The AUC Score for Questions [20, 0, 25, 14, 23, 29, 32] ----- 0.5409212197199853\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19655\n",
            "The AUC Score for Questions [18, 29, 39, 36, 2, 8, 32] ----- 0.4381881821542814\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19656\n",
            "The AUC Score for Questions [30, 20, 21, 40, 5, 27, 14] ----- 0.5868294996061789\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19657\n",
            "The AUC Score for Questions [33, 10, 0, 40, 22, 16, 28] ----- 0.5401034382986931\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19658\n",
            "The AUC Score for Questions [4, 27, 24, 17, 1, 18, 40] ----- 0.670701322917169\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19659\n",
            "The AUC Score for Questions [17, 9, 37, 32, 18, 3, 1] ----- 0.5482149459098874\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19660\n",
            "The AUC Score for Questions [22, 25, 9, 3, 5, 12, 30] ----- 0.45383854945266916\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19661\n",
            "The AUC Score for Questions [20, 14, 11, 30, 5, 23, 13] ----- 0.5025899760492517\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19662\n",
            "The AUC Score for Questions [5, 7, 17, 9, 31, 15, 30] ----- 0.6059358473581842\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19663\n",
            "The AUC Score for Questions [40, 30, 5, 38, 18, 33, 24] ----- 0.3818597193422385\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19664\n",
            "The AUC Score for Questions [25, 2, 17, 38, 11, 31, 40] ----- 0.3807465721496199\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19665\n",
            "The AUC Score for Questions [4, 32, 23, 31, 25, 9, 28] ----- 0.4050871228560865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19666\n",
            "The AUC Score for Questions [19, 35, 25, 5, 30, 16, 29] ----- 0.5104804616546913\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19667\n",
            "The AUC Score for Questions [1, 32, 9, 30, 37, 39, 19] ----- 0.5676287151789876\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19668\n",
            "The AUC Score for Questions [40, 18, 20, 10, 0, 15, 16] ----- 0.5518176046036875\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19669\n",
            "The AUC Score for Questions [23, 9, 10, 21, 27, 16, 17] ----- 0.5346924177396281\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19670\n",
            "The AUC Score for Questions [21, 4, 32, 26, 17, 36, 8] ----- 0.5105769076208387\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19671\n",
            "The AUC Score for Questions [7, 0, 4, 18, 21, 33, 2] ----- 0.5181800646187973\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19672\n",
            "The AUC Score for Questions [38, 4, 15, 2, 7, 16, 23] ----- 0.5194479272154442\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19673\n",
            "The AUC Score for Questions [35, 7, 26, 36, 39, 34, 16] ----- 0.5186422015399206\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19674\n",
            "The AUC Score for Questions [11, 18, 9, 39, 22, 35, 26] ----- 0.49361849190657603\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19675\n",
            "The AUC Score for Questions [40, 8, 9, 1, 28, 20, 24] ----- 0.6572953336226712\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19676\n",
            "The AUC Score for Questions [37, 10, 17, 35, 21, 9, 24] ----- 0.4741163138351739\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19677\n",
            "The AUC Score for Questions [18, 29, 6, 10, 37, 31, 7] ----- 0.5165806690135185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19678\n",
            "The AUC Score for Questions [22, 38, 39, 9, 8, 3, 7] ----- 0.4822659979746347\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19679\n",
            "The AUC Score for Questions [14, 33, 15, 26, 32, 25, 13] ----- 0.48043955249071707\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19680\n",
            "The AUC Score for Questions [24, 9, 5, 16, 38, 23, 4] ----- 0.5540438989889248\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19681\n",
            "The AUC Score for Questions [23, 2, 38, 34, 12, 35, 18] ----- 0.42745655912941444\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19682\n",
            "The AUC Score for Questions [29, 19, 25, 28, 10, 14, 5] ----- 0.6324484415939303\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19683\n",
            "The AUC Score for Questions [19, 30, 39, 34, 18, 22, 31] ----- 0.5470877336805389\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19684\n",
            "The AUC Score for Questions [5, 14, 40, 37, 22, 13, 38] ----- 0.3630105608332932\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19685\n",
            "The AUC Score for Questions [15, 30, 11, 32, 20, 21, 6] ----- 0.5776430213306328\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19686\n",
            "The AUC Score for Questions [8, 3, 39, 26, 10, 6, 17] ----- 0.37486135892366307\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19687\n",
            "The AUC Score for Questions [20, 4, 21, 31, 22, 30, 12] ----- 0.4132508720322773\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19688\n",
            "The AUC Score for Questions [4, 13, 5, 38, 12, 28, 21] ----- 0.34659867226053265\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19689\n",
            "The AUC Score for Questions [27, 30, 39, 19, 15, 8, 29] ----- 0.6269891980517914\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19690\n",
            "The AUC Score for Questions [29, 36, 40, 12, 16, 3, 17] ----- 0.5100022504058768\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19691\n",
            "The AUC Score for Questions [27, 3, 14, 7, 0, 36, 10] ----- 0.6222131134365305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19692\n",
            "The AUC Score for Questions [19, 12, 36, 0, 17, 33, 3] ----- 0.5868536110977158\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19693\n",
            "The AUC Score for Questions [15, 34, 5, 10, 21, 14, 7] ----- 0.557379321984858\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19694\n",
            "The AUC Score for Questions [7, 29, 9, 10, 37, 32, 23] ----- 0.5654506437768241\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19695\n",
            "The AUC Score for Questions [9, 36, 30, 26, 5, 19, 38] ----- 0.5281240455867934\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19696\n",
            "The AUC Score for Questions [4, 15, 11, 29, 25, 31, 35] ----- 0.5962450370513253\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19697\n",
            "The AUC Score for Questions [11, 1, 7, 12, 10, 5, 33] ----- 0.4593118580315378\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19698\n",
            "The AUC Score for Questions [18, 29, 40, 37, 7, 36, 35] ----- 0.5164400186462201\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19699\n",
            "The AUC Score for Questions [16, 14, 26, 9, 36, 27, 38] ----- 0.528811223095594\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19700\n",
            "The AUC Score for Questions [37, 28, 12, 36, 21, 16, 29] ----- 0.497735529086496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19701\n",
            "The AUC Score for Questions [25, 11, 34, 22, 38, 12, 23] ----- 0.42307831412451175\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19702\n",
            "The AUC Score for Questions [2, 29, 19, 15, 36, 34, 35] ----- 0.5604434907010014\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19703\n",
            "The AUC Score for Questions [20, 32, 21, 26, 13, 8, 9] ----- 0.5688342897558311\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19704\n",
            "The AUC Score for Questions [13, 10, 31, 40, 9, 12, 14] ----- 0.446227355290865\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19705\n",
            "The AUC Score for Questions [26, 40, 16, 6, 24, 17, 39] ----- 0.5109285335390847\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19706\n",
            "The AUC Score for Questions [22, 7, 36, 26, 31, 1, 35] ----- 0.5088850846313353\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19707\n",
            "The AUC Score for Questions [6, 22, 19, 2, 12, 1, 33] ----- 0.40706627445307103\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19708\n",
            "The AUC Score for Questions [6, 15, 35, 7, 34, 10, 16] ----- 0.4847856488402372\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19709\n",
            "The AUC Score for Questions [4, 34, 14, 27, 5, 25, 16] ----- 0.5370231952548584\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19710\n",
            "The AUC Score for Questions [13, 6, 37, 33, 10, 22, 14] ----- 0.42154321582999793\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19711\n",
            "The AUC Score for Questions [11, 40, 31, 26, 24, 7, 10] ----- 0.601961469836524\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19712\n",
            "The AUC Score for Questions [37, 27, 7, 36, 6, 14, 23] ----- 0.5403425439231004\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19713\n",
            "The AUC Score for Questions [21, 23, 10, 4, 24, 5, 35] ----- 0.48222782144636794\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19714\n",
            "The AUC Score for Questions [36, 30, 32, 37, 2, 18, 13] ----- 0.36185923711240775\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19715\n",
            "The AUC Score for Questions [25, 24, 14, 5, 18, 6, 35] ----- 0.3464519940203501\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19716\n",
            "The AUC Score for Questions [26, 18, 36, 28, 4, 20, 27] ----- 0.633656025461735\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19717\n",
            "The AUC Score for Questions [9, 30, 22, 12, 10, 40, 6] ----- 0.4772146404976612\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19718\n",
            "The AUC Score for Questions [21, 36, 8, 9, 34, 24, 10] ----- 0.665955377666329\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19719\n",
            "The AUC Score for Questions [7, 26, 27, 10, 37, 32, 35] ----- 0.4672083715098616\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19720\n",
            "The AUC Score for Questions [8, 39, 17, 37, 10, 20, 3] ----- 0.39399583674912797\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19721\n",
            "The AUC Score for Questions [4, 23, 31, 25, 35, 19, 13] ----- 0.45646871132114897\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19722\n",
            "The AUC Score for Questions [29, 16, 28, 8, 10, 12, 1] ----- 0.5347607336323158\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19723\n",
            "The AUC Score for Questions [24, 19, 17, 38, 28, 8, 22] ----- 0.5748259954027424\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19724\n",
            "The AUC Score for Questions [14, 7, 19, 4, 31, 20, 36] ----- 0.6335676166594333\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19725\n",
            "The AUC Score for Questions [18, 25, 29, 36, 4, 8, 39] ----- 0.5248267991191269\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19726\n",
            "The AUC Score for Questions [35, 40, 2, 12, 0, 17, 30] ----- 0.4237514265965826\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19727\n",
            "The AUC Score for Questions [29, 40, 2, 37, 7, 19, 36] ----- 0.5643093665107457\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19728\n",
            "The AUC Score for Questions [28, 15, 13, 22, 10, 37, 23] ----- 0.42899969458777387\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19729\n",
            "The AUC Score for Questions [17, 7, 18, 6, 16, 26, 12] ----- 0.5012337046503029\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19730\n",
            "The AUC Score for Questions [16, 6, 7, 17, 13, 23, 21] ----- 0.4762923759463761\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19731\n",
            "The AUC Score for Questions [26, 0, 22, 1, 34, 15, 31] ----- 0.5500273263570751\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19732\n",
            "The AUC Score for Questions [17, 9, 8, 38, 33, 22, 24] ----- 0.5190119110768192\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19733\n",
            "The AUC Score for Questions [25, 9, 20, 36, 40, 37, 4] ----- 0.37466846699136813\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19734\n",
            "The AUC Score for Questions [8, 23, 9, 28, 26, 38, 24] ----- 0.622721464049766\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19735\n",
            "The AUC Score for Questions [12, 15, 29, 28, 21, 7, 2] ----- 0.5664452428027198\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19736\n",
            "The AUC Score for Questions [7, 39, 35, 0, 1, 28, 30] ----- 0.5020575139444793\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19737\n",
            "The AUC Score for Questions [17, 15, 3, 20, 35, 8, 22] ----- 0.5960079407178795\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19738\n",
            "The AUC Score for Questions [4, 9, 20, 19, 12, 7, 17] ----- 0.5238985066949575\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19739\n",
            "The AUC Score for Questions [24, 40, 4, 39, 31, 19, 17] ----- 0.5789791998199675\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19740\n",
            "The AUC Score for Questions [3, 27, 17, 25, 31, 14, 10] ----- 0.5923289289675459\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19741\n",
            "The AUC Score for Questions [25, 24, 28, 32, 5, 19, 29] ----- 0.4948341129382263\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19742\n",
            "The AUC Score for Questions [24, 9, 27, 13, 15, 26, 14] ----- 0.6680189194836926\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19743\n",
            "The AUC Score for Questions [25, 6, 22, 10, 23, 2, 5] ----- 0.25672509684782435\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19744\n",
            "The AUC Score for Questions [30, 2, 15, 24, 14, 13, 11] ----- 0.5700378550417129\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19745\n",
            "The AUC Score for Questions [33, 16, 29, 25, 1, 27, 28] ----- 0.5870183729565511\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19746\n",
            "The AUC Score for Questions [9, 23, 33, 27, 18, 11, 7] ----- 0.5885594991239491\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19747\n",
            "The AUC Score for Questions [23, 8, 33, 37, 40, 14, 27] ----- 0.4968333574448248\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19748\n",
            "The AUC Score for Questions [16, 8, 36, 2, 18, 13, 9] ----- 0.4385337801996432\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19749\n",
            "The AUC Score for Questions [19, 11, 30, 2, 5, 13, 1] ----- 0.5037533555159055\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19750\n",
            "The AUC Score for Questions [25, 29, 28, 6, 37, 4, 11] ----- 0.5522817508157721\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19751\n",
            "The AUC Score for Questions [1, 5, 22, 14, 20, 6, 10] ----- 0.36658709874459505\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19752\n",
            "The AUC Score for Questions [15, 8, 35, 21, 27, 10, 23] ----- 0.5672971821703557\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19753\n",
            "The AUC Score for Questions [24, 30, 26, 22, 14, 12, 19] ----- 0.6009708893925512\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19754\n",
            "The AUC Score for Questions [26, 30, 6, 17, 3, 40, 38] ----- 0.43879096944270307\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19755\n",
            "The AUC Score for Questions [35, 20, 29, 3, 34, 31, 24] ----- 0.5883746443554998\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19756\n",
            "The AUC Score for Questions [16, 14, 9, 21, 6, 13, 30] ----- 0.4890493642603398\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19757\n",
            "The AUC Score for Questions [35, 8, 38, 16, 34, 9, 37] ----- 0.5469490926042018\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19758\n",
            "The AUC Score for Questions [2, 30, 11, 36, 24, 19, 25] ----- 0.6471926186687242\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19759\n",
            "The AUC Score for Questions [34, 37, 4, 22, 35, 16, 15] ----- 0.4693984986577937\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19760\n",
            "The AUC Score for Questions [0, 4, 33, 26, 17, 29, 22] ----- 0.5356468309462956\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19761\n",
            "The AUC Score for Questions [34, 15, 9, 5, 0, 40, 33] ----- 0.5524605777113372\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19762\n",
            "The AUC Score for Questions [22, 18, 7, 26, 40, 5, 28] ----- 0.5775325103277555\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19763\n",
            "The AUC Score for Questions [10, 30, 11, 21, 28, 27, 39] ----- 0.5346321390107859\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19764\n",
            "The AUC Score for Questions [16, 13, 37, 4, 26, 25, 33] ----- 0.5062689877995853\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19765\n",
            "The AUC Score for Questions [16, 15, 23, 10, 1, 20, 33] ----- 0.5768955650929899\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19766\n",
            "The AUC Score for Questions [11, 14, 31, 29, 39, 40, 20] ----- 0.5691537670186945\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19767\n",
            "The AUC Score for Questions [9, 0, 34, 5, 35, 25, 12] ----- 0.4827080419861439\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19768\n",
            "The AUC Score for Questions [23, 20, 11, 16, 4, 40, 21] ----- 0.5429787336644645\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19769\n",
            "The AUC Score for Questions [15, 23, 38, 33, 7, 25, 24] ----- 0.5782638922377072\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19770\n",
            "The AUC Score for Questions [16, 38, 4, 14, 7, 21, 32] ----- 0.4620404751571266\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19771\n",
            "The AUC Score for Questions [35, 37, 7, 40, 18, 24, 2] ----- 0.39999758885084635\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19772\n",
            "The AUC Score for Questions [28, 9, 5, 24, 2, 32, 35] ----- 0.41733977913873754\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19773\n",
            "The AUC Score for Questions [6, 33, 35, 21, 23, 40, 13] ----- 0.3737361559852759\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19774\n",
            "The AUC Score for Questions [27, 4, 35, 23, 40, 1, 25] ----- 0.39237433894327367\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19775\n",
            "The AUC Score for Questions [27, 25, 37, 19, 6, 29, 22] ----- 0.4807228625162753\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19776\n",
            "The AUC Score for Questions [7, 18, 28, 34, 11, 39, 30] ----- 0.5419178280368423\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19777\n",
            "The AUC Score for Questions [22, 8, 0, 31, 25, 2, 1] ----- 0.46372827956470725\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19778\n",
            "The AUC Score for Questions [27, 19, 38, 32, 12, 0, 33] ----- 0.44892583305203265\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19779\n",
            "The AUC Score for Questions [37, 26, 38, 3, 30, 32, 13] ----- 0.345624166144251\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19780\n",
            "The AUC Score for Questions [27, 16, 12, 19, 33, 38, 5] ----- 0.48188825127389046\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19781\n",
            "The AUC Score for Questions [40, 3, 27, 25, 1, 13, 8] ----- 0.49455482149459096\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19782\n",
            "The AUC Score for Questions [25, 1, 9, 38, 36, 31, 21] ----- 0.5788968188905499\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19783\n",
            "The AUC Score for Questions [36, 29, 28, 38, 4, 0, 15] ----- 0.5634272877786887\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19784\n",
            "The AUC Score for Questions [23, 29, 36, 34, 11, 16, 37] ----- 0.5475538891835849\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19785\n",
            "The AUC Score for Questions [18, 10, 3, 2, 6, 19, 5] ----- 0.3164954750767549\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19786\n",
            "The AUC Score for Questions [10, 37, 29, 23, 33, 4, 27] ----- 0.49585282345565895\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19787\n",
            "The AUC Score for Questions [24, 25, 28, 27, 40, 1, 0] ----- 0.7457603960714343\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19788\n",
            "The AUC Score for Questions [20, 38, 37, 3, 15, 21, 22] ----- 0.4635534712510649\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19789\n",
            "The AUC Score for Questions [32, 30, 20, 40, 24, 9, 29] ----- 0.654172895468647\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19790\n",
            "The AUC Score for Questions [15, 30, 33, 17, 32, 3, 11] ----- 0.5585125620870907\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19791\n",
            "The AUC Score for Questions [19, 33, 4, 29, 13, 23, 39] ----- 0.5433283502917491\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19792\n",
            "The AUC Score for Questions [32, 17, 2, 35, 29, 23, 12] ----- 0.4401150921862693\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19793\n",
            "The AUC Score for Questions [26, 36, 31, 0, 40, 24, 16] ----- 0.6739222163283021\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19794\n",
            "The AUC Score for Questions [10, 15, 9, 25, 35, 7, 29] ----- 0.5896907299352204\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19795\n",
            "The AUC Score for Questions [21, 20, 16, 13, 24, 1, 5] ----- 0.6143688415232034\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19796\n",
            "The AUC Score for Questions [16, 35, 14, 8, 31, 10, 17] ----- 0.4790872996736912\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19797\n",
            "The AUC Score for Questions [9, 36, 22, 0, 25, 17, 34] ----- 0.6221468068348041\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19798\n",
            "The AUC Score for Questions [19, 13, 23, 4, 24, 18, 9] ----- 0.6333345389079101\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19799\n",
            "The AUC Score for Questions [5, 4, 26, 22, 12, 27, 13] ----- 0.45950073138190994\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19800\n",
            "The AUC Score for Questions [10, 30, 27, 38, 29, 2, 35] ----- 0.5213386700101268\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19801\n",
            "The AUC Score for Questions [19, 40, 36, 37, 18, 1, 33] ----- 0.5594830496214496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19802\n",
            "The AUC Score for Questions [29, 24, 20, 15, 37, 8, 27] ----- 0.5726137660542348\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19803\n",
            "The AUC Score for Questions [9, 33, 4, 29, 23, 0, 2] ----- 0.4677589172332867\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19804\n",
            "The AUC Score for Questions [7, 37, 6, 5, 10, 13, 16] ----- 0.4189954348909357\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19805\n",
            "The AUC Score for Questions [23, 4, 36, 37, 32, 28, 14] ----- 0.5055255501438652\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19806\n",
            "The AUC Score for Questions [31, 33, 15, 14, 18, 37, 24] ----- 0.5453215669254633\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19807\n",
            "The AUC Score for Questions [33, 38, 39, 26, 7, 28, 37] ----- 0.45341860764173536\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19808\n",
            "The AUC Score for Questions [3, 33, 15, 4, 25, 34, 30] ----- 0.4784784845123853\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19809\n",
            "The AUC Score for Questions [10, 35, 5, 21, 19, 13, 22] ----- 0.3324492453103149\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19810\n",
            "The AUC Score for Questions [32, 8, 22, 31, 33, 4, 20] ----- 0.4464483772966195\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19811\n",
            "The AUC Score for Questions [5, 28, 39, 34, 13, 3, 1] ----- 0.5726921284017296\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19812\n",
            "The AUC Score for Questions [31, 17, 10, 1, 18, 12, 32] ----- 0.4525083988362187\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19813\n",
            "The AUC Score for Questions [40, 35, 34, 13, 14, 10, 19] ----- 0.48372273392165377\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19814\n",
            "The AUC Score for Questions [12, 1, 35, 21, 10, 26, 13] ----- 0.3788879780103197\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19815\n",
            "The AUC Score for Questions [11, 0, 19, 9, 36, 4, 29] ----- 0.6590293517223642\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19816\n",
            "The AUC Score for Questions [19, 17, 32, 30, 13, 25, 4] ----- 0.48521764639693943\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19817\n",
            "The AUC Score for Questions [27, 5, 11, 8, 14, 30, 16] ----- 0.5684605616370095\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19818\n",
            "The AUC Score for Questions [36, 22, 23, 35, 15, 8, 19] ----- 0.6676833678931379\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19819\n",
            "The AUC Score for Questions [1, 37, 32, 30, 16, 33, 8] ----- 0.5162832939512305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19820\n",
            "The AUC Score for Questions [7, 21, 25, 35, 11, 28, 8] ----- 0.5247424088987478\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19821\n",
            "The AUC Score for Questions [3, 40, 12, 30, 29, 25, 8] ----- 0.4968213016990565\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19822\n",
            "The AUC Score for Questions [26, 37, 24, 1, 32, 6, 23] ----- 0.41220604073234635\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19823\n",
            "The AUC Score for Questions [30, 19, 20, 3, 12, 40, 39] ----- 0.35803555641285306\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19824\n",
            "The AUC Score for Questions [25, 30, 23, 3, 20, 1, 17] ----- 0.6385406117889119\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19825\n",
            "The AUC Score for Questions [19, 17, 39, 29, 30, 0, 4] ----- 0.6421533169375191\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19826\n",
            "The AUC Score for Questions [33, 13, 32, 26, 11, 5, 9] ----- 0.4982981305556895\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19827\n",
            "The AUC Score for Questions [16, 23, 39, 22, 38, 17, 24] ----- 0.49172172123900926\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19828\n",
            "The AUC Score for Questions [11, 21, 14, 4, 37, 3, 1] ----- 0.5361109771583803\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19829\n",
            "The AUC Score for Questions [8, 0, 30, 17, 2, 21, 37] ----- 0.4394158589317002\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19830\n",
            "The AUC Score for Questions [32, 40, 39, 31, 18, 21, 30] ----- 0.36375399848901313\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19831\n",
            "The AUC Score for Questions [31, 9, 12, 25, 11, 7, 13] ----- 0.43756731124720705\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19832\n",
            "The AUC Score for Questions [16, 35, 39, 31, 14, 2, 23] ----- 0.43730208484030153\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19833\n",
            "The AUC Score for Questions [34, 3, 33, 30, 32, 6, 13] ----- 0.4279166867595763\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19834\n",
            "The AUC Score for Questions [20, 4, 3, 27, 7, 37, 36] ----- 0.5697967401263442\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19835\n",
            "The AUC Score for Questions [28, 2, 18, 32, 29, 33, 9] ----- 0.5940609377762776\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19836\n",
            "The AUC Score for Questions [4, 9, 14, 25, 2, 24, 34] ----- 0.5892888717429393\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19837\n",
            "The AUC Score for Questions [15, 33, 29, 16, 26, 1, 31] ----- 0.5878743309061099\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19838\n",
            "The AUC Score for Questions [16, 37, 38, 4, 3, 21, 11] ----- 0.435654466251949\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19839\n",
            "The AUC Score for Questions [1, 6, 19, 12, 21, 15, 26] ----- 0.5396352735046857\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19840\n",
            "The AUC Score for Questions [4, 3, 24, 30, 26, 39, 35] ----- 0.5527499156097795\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19841\n",
            "The AUC Score for Questions [38, 21, 15, 14, 37, 33, 23] ----- 0.5381102216649788\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19842\n",
            "The AUC Score for Questions [18, 24, 32, 3, 6, 38, 8] ----- 0.39668627734645\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19843\n",
            "The AUC Score for Questions [40, 22, 25, 30, 13, 39, 5] ----- 0.4133111507611194\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19844\n",
            "The AUC Score for Questions [17, 2, 38, 18, 29, 39, 19] ----- 0.5784728584976933\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19845\n",
            "The AUC Score for Questions [26, 8, 14, 21, 1, 20, 27] ----- 0.6343934352445708\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19846\n",
            "The AUC Score for Questions [29, 16, 27, 7, 33, 14, 10] ----- 0.6118933950587517\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19847\n",
            "The AUC Score for Questions [32, 11, 20, 2, 3, 6, 40] ----- 0.41588505248267993\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19848\n",
            "The AUC Score for Questions [39, 19, 30, 20, 33, 18, 10] ----- 0.4514615582453264\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19849\n",
            "The AUC Score for Questions [32, 26, 40, 9, 35, 31, 17] ----- 0.53426644805581\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19850\n",
            "The AUC Score for Questions [18, 21, 26, 38, 3, 1, 13] ----- 0.5008238092941762\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19851\n",
            "The AUC Score for Questions [36, 11, 21, 10, 30, 37, 13] ----- 0.4652874893507579\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19852\n",
            "The AUC Score for Questions [20, 5, 32, 26, 35, 28, 2] ----- 0.34072953336226713\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19853\n",
            "The AUC Score for Questions [15, 1, 5, 27, 20, 7, 4] ----- 0.6025100062689878\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19854\n",
            "The AUC Score for Questions [29, 7, 4, 28, 12, 10, 37] ----- 0.5262775071932616\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19855\n",
            "The AUC Score for Questions [8, 13, 32, 14, 33, 0, 25] ----- 0.4713515294722799\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19856\n",
            "The AUC Score for Questions [1, 6, 34, 22, 18, 8, 23] ----- 0.5141855941875231\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19857\n",
            "The AUC Score for Questions [35, 20, 18, 27, 0, 23, 22] ----- 0.5635398080725273\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19858\n",
            "The AUC Score for Questions [6, 22, 24, 4, 21, 29, 9] ----- 0.6779649097426501\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19859\n",
            "The AUC Score for Questions [8, 40, 39, 1, 3, 21, 12] ----- 0.3808088601694234\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19860\n",
            "The AUC Score for Questions [33, 4, 35, 24, 36, 26, 19] ----- 0.6231735545160825\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19861\n",
            "The AUC Score for Questions [29, 28, 40, 15, 0, 2, 33] ----- 0.4851473212132903\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19862\n",
            "The AUC Score for Questions [26, 1, 21, 40, 23, 28, 25] ----- 0.5807212550835062\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19863\n",
            "The AUC Score for Questions [25, 32, 36, 16, 20, 10, 12] ----- 0.4673389754223529\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19864\n",
            "The AUC Score for Questions [19, 32, 8, 33, 0, 5, 9] ----- 0.5128433878253041\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19865\n",
            "The AUC Score for Questions [27, 25, 8, 18, 1, 31, 40] ----- 0.5766584687595442\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19866\n",
            "The AUC Score for Questions [3, 13, 8, 27, 20, 21, 5] ----- 0.4729006928035235\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19867\n",
            "The AUC Score for Questions [19, 7, 6, 8, 3, 30, 16] ----- 0.5207338734307437\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19868\n",
            "The AUC Score for Questions [22, 29, 8, 12, 2, 9, 37] ----- 0.5263779717413318\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19869\n",
            "The AUC Score for Questions [15, 39, 22, 20, 11, 29, 38] ----- 0.5128996479722235\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19870\n",
            "The AUC Score for Questions [7, 19, 0, 40, 17, 32, 12] ----- 0.47725281702592787\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19871\n",
            "The AUC Score for Questions [27, 28, 38, 16, 24, 8, 34] ----- 0.573471733294755\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19872\n",
            "The AUC Score for Questions [20, 27, 3, 38, 28, 22, 37] ----- 0.35622920383854945\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19873\n",
            "The AUC Score for Questions [15, 24, 39, 28, 18, 38, 33] ----- 0.49091197698156275\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19874\n",
            "The AUC Score for Questions [28, 18, 6, 19, 0, 24, 5] ----- 0.4091499091800485\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19875\n",
            "The AUC Score for Questions [4, 40, 0, 35, 36, 6, 1] ----- 0.4632179196605102\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19876\n",
            "The AUC Score for Questions [34, 2, 30, 29, 8, 10, 7] ----- 0.5878562472874572\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19877\n",
            "The AUC Score for Questions [2, 38, 28, 33, 17, 40, 39] ----- 0.38180948706820333\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19878\n",
            "The AUC Score for Questions [17, 6, 1, 27, 3, 18, 2] ----- 0.5119150954011349\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19879\n",
            "The AUC Score for Questions [35, 6, 5, 13, 40, 20, 25] ----- 0.3664926620694089\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19880\n",
            "The AUC Score for Questions [15, 10, 27, 17, 30, 0, 23] ----- 0.6444760572889039\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19881\n",
            "The AUC Score for Questions [22, 3, 12, 26, 14, 13, 0] ----- 0.4249811126649628\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19882\n",
            "The AUC Score for Questions [37, 13, 3, 28, 15, 35, 11] ----- 0.49396408995193775\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19883\n",
            "The AUC Score for Questions [13, 14, 25, 4, 20, 26, 6] ----- 0.48123322242047223\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19884\n",
            "The AUC Score for Questions [3, 16, 5, 1, 39, 10, 14] ----- 0.4609996624391185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19885\n",
            "The AUC Score for Questions [9, 8, 10, 37, 12, 15, 2] ----- 0.4917960650045812\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19886\n",
            "The AUC Score for Questions [30, 14, 31, 12, 40, 32, 23] ----- 0.47503054122261335\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19887\n",
            "The AUC Score for Questions [33, 2, 35, 40, 24, 9, 8] ----- 0.44481080516307403\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19888\n",
            "The AUC Score for Questions [29, 15, 0, 21, 39, 27, 32] ----- 0.614585844947035\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19889\n",
            "The AUC Score for Questions [19, 28, 34, 22, 18, 36, 8] ----- 0.5571382070694894\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19890\n",
            "The AUC Score for Questions [20, 17, 36, 14, 32, 40, 9] ----- 0.587285608654418\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19891\n",
            "The AUC Score for Questions [11, 27, 23, 26, 16, 25, 35] ----- 0.5258515375094437\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19892\n",
            "The AUC Score for Questions [15, 13, 27, 2, 35, 11, 34] ----- 0.4783920850010448\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19893\n",
            "The AUC Score for Questions [4, 11, 28, 9, 8, 23, 29] ----- 0.7105777113372234\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19894\n",
            "The AUC Score for Questions [0, 38, 39, 35, 30, 33, 20] ----- 0.47670026201154136\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19895\n",
            "The AUC Score for Questions [14, 13, 21, 16, 34, 11, 23] ----- 0.5475558984745463\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19896\n",
            "The AUC Score for Questions [33, 30, 36, 23, 26, 40, 27] ----- 0.5908701837295655\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19897\n",
            "The AUC Score for Questions [26, 0, 1, 24, 18, 3, 20] ----- 0.5962249441417112\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19898\n",
            "The AUC Score for Questions [4, 24, 12, 15, 16, 14, 28] ----- 0.6139006767291958\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19899\n",
            "The AUC Score for Questions [21, 25, 20, 0, 33, 6, 9] ----- 0.4885329764832586\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19900\n",
            "The AUC Score for Questions [7, 34, 14, 5, 23, 40, 39] ----- 0.5272560318914661\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19901\n",
            "The AUC Score for Questions [5, 19, 25, 6, 38, 11, 32] ----- 0.42061492340582857\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19902\n",
            "The AUC Score for Questions [26, 22, 35, 39, 21, 16, 3] ----- 0.48750622880198036\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19903\n",
            "The AUC Score for Questions [5, 6, 23, 19, 17, 36, 8] ----- 0.5471319380816897\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19904\n",
            "The AUC Score for Questions [4, 3, 35, 26, 7, 23, 33] ----- 0.48570992268248375\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19905\n",
            "The AUC Score for Questions [34, 9, 19, 16, 26, 33, 3] ----- 0.5808036360129237\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19906\n",
            "The AUC Score for Questions [9, 2, 4, 40, 36, 26, 10] ----- 0.536966935107939\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19907\n",
            "The AUC Score for Questions [40, 23, 14, 2, 18, 26, 17] ----- 0.5363340084550965\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19908\n",
            "The AUC Score for Questions [8, 24, 13, 2, 12, 32, 38] ----- 0.37258282297342915\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19909\n",
            "The AUC Score for Questions [40, 5, 11, 19, 30, 1, 3] ----- 0.6127292600986963\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19910\n",
            "The AUC Score for Questions [40, 31, 11, 39, 35, 22, 4] ----- 0.30337279580781534\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19911\n",
            "The AUC Score for Questions [31, 26, 36, 39, 17, 10, 5] ----- 0.5224417707479384\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19912\n",
            "The AUC Score for Questions [8, 18, 0, 25, 7, 19, 26] ----- 0.6483620260082622\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19913\n",
            "The AUC Score for Questions [33, 29, 1, 12, 35, 6, 21] ----- 0.4742248155470898\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19914\n",
            "The AUC Score for Questions [9, 39, 3, 36, 23, 8, 4] ----- 0.5404872128723216\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19915\n",
            "The AUC Score for Questions [25, 13, 34, 22, 26, 10, 16] ----- 0.5395890598125733\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19916\n",
            "The AUC Score for Questions [27, 35, 40, 39, 26, 6, 30] ----- 0.4459601195929981\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19917\n",
            "The AUC Score for Questions [36, 21, 2, 10, 16, 12, 15] ----- 0.4672646316567809\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19918\n",
            "The AUC Score for Questions [9, 37, 15, 23, 12, 17, 38] ----- 0.43215026281525776\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19919\n",
            "The AUC Score for Questions [32, 21, 15, 24, 34, 2, 40] ----- 0.5476865023870376\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19920\n",
            "The AUC Score for Questions [4, 36, 21, 20, 24, 7, 27] ----- 0.6638034270466637\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19921\n",
            "The AUC Score for Questions [40, 25, 36, 16, 4, 12, 1] ----- 0.4590868174438605\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19922\n",
            "The AUC Score for Questions [12, 31, 21, 33, 8, 30, 24] ----- 0.5598085547571973\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19923\n",
            "The AUC Score for Questions [7, 23, 24, 18, 15, 10, 36] ----- 0.6783948980083909\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19924\n",
            "The AUC Score for Questions [17, 26, 36, 15, 30, 7, 28] ----- 0.6330110430631238\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19925\n",
            "The AUC Score for Questions [16, 24, 2, 40, 30, 9, 11] ----- 0.5912137724839659\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19926\n",
            "The AUC Score for Questions [4, 29, 8, 0, 30, 38, 26] ----- 0.5465693366124962\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19927\n",
            "The AUC Score for Questions [12, 37, 6, 33, 20, 18, 27] ----- 0.44641221005931425\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19928\n",
            "The AUC Score for Questions [34, 4, 19, 36, 30, 11, 32] ----- 0.49698606355789166\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19929\n",
            "The AUC Score for Questions [35, 15, 29, 30, 40, 17, 2] ----- 0.5860298018035396\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19930\n",
            "The AUC Score for Questions [11, 8, 14, 6, 1, 0, 19] ----- 0.44644034013277395\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19931\n",
            "The AUC Score for Questions [18, 29, 22, 40, 16, 5, 28] ----- 0.5663407596727267\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19932\n",
            "The AUC Score for Questions [38, 10, 33, 27, 1, 31, 2] ----- 0.4657214961984215\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19933\n",
            "The AUC Score for Questions [6, 7, 28, 30, 20, 13, 5] ----- 0.4223027278134093\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19934\n",
            "The AUC Score for Questions [35, 0, 7, 38, 10, 14, 36] ----- 0.5280898876404494\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19935\n",
            "The AUC Score for Questions [5, 21, 25, 9, 15, 12, 4] ----- 0.4626050859172815\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19936\n",
            "The AUC Score for Questions [35, 39, 21, 2, 37, 36, 38] ----- 0.4664609152722188\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19937\n",
            "The AUC Score for Questions [5, 29, 25, 17, 2, 30, 37] ----- 0.46933420134702863\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19938\n",
            "The AUC Score for Questions [28, 4, 20, 34, 17, 23, 40] ----- 0.38591044992043205\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19939\n",
            "The AUC Score for Questions [4, 31, 28, 17, 26, 21, 2] ----- 0.4845847197440968\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19940\n",
            "The AUC Score for Questions [27, 15, 0, 25, 36, 10, 40] ----- 0.6236216264004758\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19941\n",
            "The AUC Score for Questions [8, 29, 17, 5, 6, 37, 24] ----- 0.4910425808940541\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19942\n",
            "The AUC Score for Questions [20, 2, 10, 30, 19, 16, 36] ----- 0.4337255469289997\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19943\n",
            "The AUC Score for Questions [5, 24, 38, 14, 7, 9, 23] ----- 0.5868857597530983\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19944\n",
            "The AUC Score for Questions [37, 31, 33, 2, 26, 28, 16] ----- 0.48466308209159153\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19945\n",
            "The AUC Score for Questions [0, 35, 1, 37, 9, 5, 12] ----- 0.35601420970567904\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19946\n",
            "The AUC Score for Questions [31, 9, 23, 37, 19, 4, 10] ----- 0.48719077012103973\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19947\n",
            "The AUC Score for Questions [8, 20, 33, 2, 23, 26, 6] ----- 0.3622008165758467\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19948\n",
            "The AUC Score for Questions [16, 11, 28, 37, 4, 15, 38] ----- 0.4545639034897365\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19949\n",
            "The AUC Score for Questions [40, 14, 0, 33, 4, 26, 9] ----- 0.5257068685602224\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19950\n",
            "The AUC Score for Questions [29, 36, 27, 11, 34, 6, 37] ----- 0.5435011493144299\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19951\n",
            "The AUC Score for Questions [9, 12, 33, 5, 24, 29, 6] ----- 0.4603205220941634\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19952\n",
            "The AUC Score for Questions [2, 34, 18, 26, 27, 6, 39] ----- 0.4758483226439054\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19953\n",
            "The AUC Score for Questions [3, 9, 19, 38, 11, 25, 4] ----- 0.5150194499365064\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19954\n",
            "The AUC Score for Questions [39, 32, 15, 35, 9, 37, 13] ----- 0.47350348009194504\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19955\n",
            "The AUC Score for Questions [33, 3, 30, 23, 21, 17, 14] ----- 0.6163218723376895\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19956\n",
            "The AUC Score for Questions [1, 37, 2, 0, 39, 31, 6] ----- 0.315068878494157\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19957\n",
            "The AUC Score for Questions [10, 27, 29, 36, 31, 22, 30] ----- 0.606910353474466\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19958\n",
            "The AUC Score for Questions [20, 19, 5, 1, 39, 35, 9] ----- 0.5398804070019771\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19959\n",
            "The AUC Score for Questions [30, 35, 26, 25, 6, 29, 28] ----- 0.46101171818488695\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19960\n",
            "The AUC Score for Questions [7, 3, 1, 9, 21, 28, 2] ----- 0.6194201990001769\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19961\n",
            "The AUC Score for Questions [30, 34, 20, 3, 32, 5, 24] ----- 0.4251860603430262\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19962\n",
            "The AUC Score for Questions [4, 7, 9, 1, 36, 39, 0] ----- 0.5981699377923518\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19963\n",
            "The AUC Score for Questions [38, 4, 7, 0, 33, 36, 10] ----- 0.5464929835559628\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19964\n",
            "The AUC Score for Questions [38, 2, 15, 10, 16, 18, 30] ----- 0.5435996045715389\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19965\n",
            "The AUC Score for Questions [26, 21, 19, 24, 0, 11, 14] ----- 0.6105511886965327\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19966\n",
            "The AUC Score for Questions [21, 26, 34, 12, 24, 19, 11] ----- 0.6111941618041825\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19967\n",
            "The AUC Score for Questions [26, 6, 5, 8, 3, 30, 16] ----- 0.5122104611724614\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19968\n",
            "The AUC Score for Questions [37, 8, 26, 17, 9, 4, 28] ----- 0.5624869396087508\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19969\n",
            "The AUC Score for Questions [8, 16, 3, 35, 32, 18, 34] ----- 0.5458037967562006\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19970\n",
            "The AUC Score for Questions [21, 5, 34, 0, 26, 24, 3] ----- 0.6105893652247995\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19971\n",
            "The AUC Score for Questions [15, 28, 12, 17, 10, 23, 38] ----- 0.47606934464966\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19972\n",
            "The AUC Score for Questions [12, 9, 3, 38, 36, 21, 40] ----- 0.5364183986754755\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19973\n",
            "The AUC Score for Questions [7, 14, 9, 25, 37, 11, 39] ----- 0.5238241629293854\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19974\n",
            "The AUC Score for Questions [6, 36, 3, 13, 24, 0, 15] ----- 0.644982398611178\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19975\n",
            "The AUC Score for Questions [33, 32, 8, 28, 21, 16, 23] ----- 0.4963310347044735\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19976\n",
            "The AUC Score for Questions [33, 24, 23, 37, 13, 20, 14] ----- 0.5813220330809663\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19977\n",
            "The AUC Score for Questions [19, 28, 26, 14, 10, 17, 13] ----- 0.5780107215765701\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19978\n",
            "The AUC Score for Questions [7, 24, 12, 17, 28, 11, 18] ----- 0.5824211152368552\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19979\n",
            "The AUC Score for Questions [3, 1, 4, 15, 10, 31, 16] ----- 0.574002186108566\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19980\n",
            "The AUC Score for Questions [25, 29, 15, 34, 40, 23, 12] ----- 0.5655149410875889\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19981\n",
            "The AUC Score for Questions [33, 29, 16, 11, 12, 0, 18] ----- 0.4984910224879844\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19982\n",
            "The AUC Score for Questions [10, 35, 7, 0, 19, 12, 39] ----- 0.4197730304929997\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19983\n",
            "The AUC Score for Questions [24, 4, 33, 12, 5, 6, 34] ----- 0.4600452492324509\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19984\n",
            "The AUC Score for Questions [2, 18, 21, 22, 9, 37, 23] ----- 0.5135908440629471\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19985\n",
            "The AUC Score for Questions [2, 17, 10, 26, 23, 5, 32] ----- 0.33612021989680285\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19986\n",
            "The AUC Score for Questions [4, 16, 39, 8, 12, 7, 31] ----- 0.4581344135281542\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19987\n",
            "The AUC Score for Questions [32, 31, 23, 9, 7, 1, 35] ----- 0.5962048512320971\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19988\n",
            "The AUC Score for Questions [16, 36, 15, 31, 28, 29, 23] ----- 0.617374740801466\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19989\n",
            "The AUC Score for Questions [33, 28, 3, 9, 31, 0, 15] ----- 0.5810809181655977\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19990\n",
            "The AUC Score for Questions [15, 2, 23, 27, 39, 24, 21] ----- 0.6145054733085789\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19991\n",
            "The AUC Score for Questions [17, 15, 19, 20, 37, 12, 23] ----- 0.5380258314445998\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19992\n",
            "The AUC Score for Questions [34, 0, 9, 38, 17, 37, 39] ----- 0.5040165726318496\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19993\n",
            "The AUC Score for Questions [8, 17, 13, 39, 28, 38, 27] ----- 0.4103293629743936\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19994\n",
            "The AUC Score for Questions [10, 28, 5, 30, 22, 26, 20] ----- 0.5341197698156275\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19995\n",
            "The AUC Score for Questions [19, 2, 35, 14, 26, 13, 20] ----- 0.4849323270804199\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19996\n",
            "The AUC Score for Questions [19, 30, 6, 16, 24, 2, 12] ----- 0.49385558824002185\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19997\n",
            "The AUC Score for Questions [33, 24, 30, 39, 15, 25, 2] ----- 0.46745350500715305\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19998\n",
            "The AUC Score for Questions [38, 7, 3, 14, 35, 19, 21] ----- 0.5100665477166417\n",
            "*****************************************************************************************************************************************\n",
            "[LibSVM]The comb tryout number: 19999\n",
            "The AUC Score for Questions [26, 22, 28, 1, 5, 38, 8] ----- 0.44165822764462875\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef175406-a300-44af-af71-5ac5f5752c9d\", \"DFmy_dict.csv\", 1076949)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "SVMOC.fit(principalcomponents)\n",
        "OCsvmresults = SVMOC.predict(principalcomponents)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "#micro = f1_score(GPA_Cat, OCsvmresults, average='micro')\n",
        "#macro = f1_score(GPA_Cat, OCsvmresults, average='macro')\n",
        "#none = f1_score(GPA_Cat, OCsvmresults, average=None)\n",
        "#weighted = f1_score(GPA_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscores = SVMOC.decision_function(principalcomponents)\n",
        "\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "fpr5,tpr5,thresholds = roc_curve(Bio_Cat,OCsvmscores)\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "print(f'The AUC Score for Questions Principal Components ----- {roc_auc5}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"Principal Components Nonscaled BioDeg\")\n",
        "my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ppgbMKATfZ4l",
        "outputId": "3bf5df7e-b9cc-4523-ea81-5aaec241c1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]The AUC Score for Questions Principal Components ----- 0.4535210814807671\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a2d0576-57ee-46fb-be33-bfdd798f134a\", \"DFmy_dict.csv\", 1077012)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "SVMOC = OneClassSVM(gamma='scale', nu=0.03, kernel = 'rbf', verbose=True)\n",
        "# if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        "# if gamma= â€˜autoâ€™, uses 1 / n_features.\n",
        "# print(SVMOC)\n",
        "\n",
        "SVMOC.fit(DF_biodeg_Scaled)\n",
        "OCsvmresults = SVMOC.predict(DF_biodeg_Scaled)\n",
        "\n",
        "#print('OCSVM returns -1 for anomalies, 1 for nominals')\n",
        "#print(f'Number of students predicted to be above threshold {TH} is .. {count(np.where(OCsvmresults == 1))}')\n",
        "#print(f'Number of students predicted to be below threshold {TH} is .. {count(np.where(OCsvmresults == -1))}')\n",
        "#print('********************************************************************************')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "#micro = f1_score(GPA_Cat, OCsvmresults, average='micro')\n",
        "#macro = f1_score(GPA_Cat, OCsvmresults, average='macro')\n",
        "#none = f1_score(GPA_Cat, OCsvmresults, average=None)\n",
        "#weighted = f1_score(GPA_Cat, OCsvmresults, average='weighted')\n",
        "#print(f'The comb tryout number: {i}')\n",
        "#print(f'F1 Score using micro avarage = {micro}')\n",
        "#print(f'F1 Score using macro avarage = {macro}')\n",
        "#print(f'F1 Score using no avarage = {none}')\n",
        "#print(f'F1 Score using weighted avarage = {weighted}')\n",
        "#print('********************************************************************************')\n",
        "#print(f'Number of instances that were predicted correctly {count(np.where(OCsvmresults * GPA_Cat == 1))}')\n",
        "#print(f'Number of instances that were not predicted correctly {count(np.where(OCsvmresults * GPA_Cat == -1))}')\n",
        "#print(f'Instances that are true negative {count(np.where(OCsvmresults + GPA_Cat == -2))}')\n",
        "#print(f'Instances that are true positive {count(np.where(OCsvmresults + GPA_Cat == 2))}')\n",
        "#print('********************************************************************************')\n",
        "#decision calculated to use in roc \n",
        "OCsvmscores = SVMOC.decision_function(DF_biodeg_Scaled)\n",
        "\n",
        "fpr5,tpr5,thresholds = roc_curve(Bio_Cat,OCsvmscores)\n",
        "roc_auc5 = metrics.auc(fpr5,tpr5)\n",
        "print(f'The AUC Score for Questions Principal Components ----- {roc_auc5}')\n",
        "print('*****************************************************************************************************************************************')\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(fpr5, tpr5, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver operating characteristic')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(OCsvmresults == -1)\n",
        "# #OCSVM returns -1 for anomalies, 1 for nominals\n",
        "# np.where(GPA_Cat == -1)\n",
        "########################################################################\n",
        "my_dict = {\"Combinations\":[],\"AUCScores\":[]};\n",
        "\n",
        "my_dict[\"Combinations\"].append(\"Biodeg Scaled ALL Features\")\n",
        "my_dict[\"AUCScores\"].append(roc_auc5)\n",
        "\n",
        "DFmy_dict = pd.DataFrame(my_dict)\n",
        "DFmy_dict = DFmy_dict.sort_values(by='AUCScores', ascending=False)\n",
        "\n",
        "DFmy_dict.to_csv('DFmy_dict.csv')\n",
        "from google.colab import files\n",
        "files.download(\"DFmy_dict.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4Q4Vk_QNDHer",
        "outputId": "6580b0da-201b-4fc1-c99b-4a9f83f77e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]The AUC Score for Questions Principal Components ----- 0.586978187137323\n",
            "*****************************************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b3756fed-42cb-483e-823e-78c0158360d2\", \"DFmy_dict.csv\", 71)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}